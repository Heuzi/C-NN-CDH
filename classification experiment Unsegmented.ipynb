{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification experiment Unsegmented.ipynb","provenance":[{"file_id":"1yjwjPQmk1No1tnV4QL1_D5cZtoXFfroo","timestamp":1600551961771}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1r7RQirN8WMUcK7y_L8K30EzGT7pMe3IT","authorship_tag":"ABX9TyMQwqmD3Aoq/uKThEwZmj34"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cFjI0gUhATvh"},"source":["Regression model code based upon https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n","\n","Majority of the code adapted from [artificial data experiment with case removal.ipynb](https://colab.research.google.com/drive/13eN2qzSAB_wRqzzukBVjqcvt2GayzDCl?authuser=1#scrollTo=pRXm-C2PuCWe) "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huTONQH8vRzp","executionInfo":{"status":"ok","timestamp":1611095228410,"user_tz":300,"elapsed":463,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"a362f81b-8c43-4c92-908c-3affd2102d56"},"source":["!cat /proc/cpuinfo"],"execution_count":24,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.134\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.26\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.134\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.26\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YbkaoIXvnm_","executionInfo":{"status":"ok","timestamp":1611095229003,"user_tz":300,"elapsed":1043,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"06817cb1-6bb8-4ea8-c8f3-4ece76d4ec86"},"source":["!cat /proc/meminfo"],"execution_count":25,"outputs":[{"output_type":"stream","text":["MemTotal:       13333596 kB\n","MemFree:         9321620 kB\n","MemAvailable:   12224724 kB\n","Buffers:          195244 kB\n","Cached:          2629064 kB\n","SwapCached:            0 kB\n","Active:          1143240 kB\n","Inactive:        2538784 kB\n","Active(anon):     643884 kB\n","Inactive(anon):      372 kB\n","Active(file):     499356 kB\n","Inactive(file):  2538412 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:               548 kB\n","Writeback:             0 kB\n","AnonPages:        857656 kB\n","Mapped:           407112 kB\n","Shmem:              1016 kB\n","Slab:             234580 kB\n","SReclaimable:     190472 kB\n","SUnreclaim:        44108 kB\n","KernelStack:        4672 kB\n","PageTables:         8380 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:     6666796 kB\n","Committed_AS:    3804208 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:           0 kB\n","VmallocChunk:          0 kB\n","Percpu:             1040 kB\n","AnonHugePages:     65536 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","Hugetlb:               0 kB\n","DirectMap4k:       99560 kB\n","DirectMap2M:     6191104 kB\n","DirectMap1G:     9437184 kB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SMAVpTE57we1"},"source":["# Data Preparation"]},{"cell_type":"code","metadata":{"id":"FIbGexe-dBVO","executionInfo":{"status":"ok","timestamp":1611095229003,"user_tz":300,"elapsed":1034,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["import keras\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","from sklearn.utils import shuffle\n"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EEnQ73M4CTas"},"source":["Code adapted from https://www.kaggle.com/jshih7/car-price-prediction\n","to read data file and handle nominal attributes\n","\n","also using a trick from https://stackoverflow.com/questions/18889588/create-dummies-from-column-with-multiple-values-in-pandas"]},{"cell_type":"markdown","metadata":{"id":"slI_LjfqGJFV"},"source":["Main Code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmasLLtoFFJF","executionInfo":{"status":"ok","timestamp":1611095247417,"user_tz":300,"elapsed":19439,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"ee4fe620-7fe3-4a1a-90eb-73d2ad69c392"},"source":["# Use some functions from tensorflow_docs\n","!pip install -q git+https://github.com/tensorflow/docs\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QTdnzi-dS5oT"},"source":["Model code adapted from https://machinelearningmastery.com/cost-sensitive-neural-network-for-imbalanced-classification/\r\n","\r\n","https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"]},{"cell_type":"code","metadata":{"id":"CiEDD8BKGN3a","executionInfo":{"status":"ok","timestamp":1611095247417,"user_tz":300,"elapsed":19431,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["from tensorflow.keras import layers\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","def build_DL_model(X_train):\n","  model = Sequential()\n","  model.add(Dense(128, input_dim=X_train.shape[1], kernel_initializer='he_uniform', activation='relu'))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(num_classes, activation='softmax'))\n","  # Compile model\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WLJiLN8vPiu1"},"source":["Adaptation ML-CDH models"]},{"cell_type":"markdown","metadata":{"id":"KiNtMOuQR4yN"},"source":["Style 2: source problem + problem difference => solution difference"]},{"cell_type":"code","metadata":{"id":"_5tpDt66cDDn","executionInfo":{"status":"ok","timestamp":1611095247418,"user_tz":300,"elapsed":19426,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["def build_adaptation_model(X_train_source_n_diff):\n","  model = Sequential()\n","  model.add(Dense(128, input_dim=len(X_train_source_n_diff[0]), kernel_initializer='he_uniform', activation='relu'))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(num_classes, activation='softmax'))\n","  # Compile model\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kvTqlsjk_aZj"},"source":["This provides a baseline"]},{"cell_type":"code","metadata":{"id":"NTweoe8WYCI-","executionInfo":{"status":"ok","timestamp":1611095247418,"user_tz":300,"elapsed":19422,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["# from keras.wrappers.scikit_learn import KerasClassifier\r\n","# from sklearn.model_selection import KFold\r\n","# from sklearn.model_selection import cross_val_score\r\n","\r\n","# estimator = KerasClassifier(build_fn=build_DL_model, epochs=200, batch_size=5, verbose=0)\r\n","# kfold = KFold(n_splits=10, shuffle=True)\r\n","# results = cross_val_score(estimator, X, y, cv=kfold)\r\n","# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAosr7tRk3AL"},"source":["The code above is commented out for efficiency\r\n","\r\n","Baseline executation result: \r\n","\r\n","Baseline: 82.69% (3.34%)"]},{"cell_type":"markdown","metadata":{"id":"5TS2xOq6py7V"},"source":["# Testing full test set without removal"]},{"cell_type":"code","metadata":{"id":"F0BInwbfp1yR","executionInfo":{"status":"ok","timestamp":1611095248052,"user_tz":300,"elapsed":20052,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import balanced_accuracy_score\n","import tensorflow_docs as tfdocs\n","import tensorflow_docs.plots\n","import tensorflow_docs.modeling\n","import matplotlib.pyplot as plt\n","\n","\n","def test_full_without_removal(EAC_adapt,pair_selection, pair_knowledge, verbose_param):\n","  #pure DL model\n","  dl_model = build_DL_model()\n","  # The patience parameter is the amount of epochs to check for improvement\n","  early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","  EPOCHS = 1000\n","  early_history = dl_model.fit(X_train, y_train, \n","                      epochs=EPOCHS, validation_data=(X_test, y_test), verbose=0, \n","                      callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","  \n","  # X_dl_train, X_dl_valid, y_dl_train, y_dl_valid = train_test_split(X_train_trim, y_train_trim, test_size=0.1, shuffle= True)\n","  # early_history = dl_model.fit(X_dl_train, y_dl_train, \n","  #                     epochs=EPOCHS, validation_data=(X_dl_valid, y_dl_valid), verbose=verbose_param, \n","  #                     callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","\n","  y_test_pred = dl_model.predict(X_test)\n","  y_test_pred = tf.one_hot(tf.argmax(y_test_pred, 1), y_test_pred.shape[1])\n","  dl_loss = accuracy_score(y_test, y_test_pred)\n","\n","  print(\"dl last loss: \",early_history.history['val_loss'][-1])\n","\n","  #pure knn\n","  knn = KNeighborsClassifier(n_neighbors=3)\n","  knn.fit(X_train, y_train)\n","  y_test_pred = knn.predict(X_test)  \n","  knn_loss = accuracy_score(y_test, y_test_pred)\n","\n","  #pure CBR retrieval (knn k=1), no need to retrain knn\n","  X_test_retrieved_index = knn.kneighbors(X_test, n_neighbors=1)[1]\n","  #we only select the best neighbor here!!!\n","  X_test_retrieved_index = X_test_retrieved_index[:,0]\n","  X_test_neighbors = X_train.iloc[X_test_retrieved_index]\n","  y_test_neighbors = y_train.iloc[X_test_retrieved_index]\n","  retrieval_loss = accuracy_score(y_test, y_test_neighbors)\n","\n","  if(EAC_adapt==1):\n","    #EAC retrieval\n","    X_test_EAC_retrieved_index = knn.kneighbors(X_test, n_neighbors=3)[1]\n","    # print(\"X_test_EAC_retrieved_index\")\n","    # print(X_test_EAC_retrieved_index)\n","    #bug fixing\n","    # X_test_EAC_neighbors = X_train.iloc[X_test_EAC_retrieved_index]\n","    # print(\"X_test_EAC_neighbors\")\n","    # print(X_test_EAC_neighbors)\n","\n","  #CBR adaptaion ML-CDH learning\n","  #pool for training pairs\n","  X_train_for_CDH = X_train\n","  y_train_for_CDH = y_train\n","\n","\n","  X_train_pairs_by_class = [[] for _ in range(num_classes)]\n","  y_train_pairs_by_class = [[] for _ in range(num_classes)]\n","\n","  def addToPairList(source_y, X_train_pair, target_y):\n","    for src_class in range(num_classes):\n","      if source_y[src_class] == 1:\n","        X_train_pairs_by_class[src_class].append(X_train_pair)\n","        y_train_pairs_by_class[src_class].append(target_y)\n","        break\n","\n","  #Assemble pairs\n","  if pair_selection == 1:#not updated\n","    \n","    knn_for_CDH = KNeighborsClassifier(n_neighbors=2)\n","    knn_for_CDH.fit(X_train_for_CDH, y_train_for_CDH)\n","    X_train_neighbors_index = knn_for_CDH.kneighbors(X_train_for_CDH)[1]\n","    #we only select the second best neighbor, the first best neighbor of a case will be itself\n","    X_train_neighbors_index = X_train_neighbors_index[:,1]\n","    X_train_neighbors = X_train_for_CDH[X_train_neighbors_index]\n","    #IMPORTANT NOTE: left side of difference should be target, right side is source (or the retrieved case)\n","    X_train_differences = X_train_for_CDH - X_train_neighbors\n","    y_train_neighbors = y_train_for_CDH[X_train_neighbors_index]\n","    y_train_differences = y_train_for_CDH - y_train_neighbors\n","    X_train_source_n_diff = np.concatenate((X_train_neighbors, X_train_differences),axis = 1)\n","  elif pair_selection == 2:#not updated\n","    X_train_for_CDH_index = [*range(len(X_train_for_CDH))]\n","    np.random.shuffle(X_train_for_CDH_index) #shuffle in place\n","    X_train_neighbors = X_train_for_CDH[X_train_for_CDH_index]\n","    y_train_neighbors = y_train_for_CDH[X_train_for_CDH_index]\n","    X_train_differences = X_train_for_CDH - X_train_neighbors\n","    y_train_differences = y_train_for_CDH - y_train_neighbors\n","    X_train_source_n_diff = np.concatenate((X_train_neighbors, X_train_differences),axis = 1)\n","  elif pair_selection == 12 or pair_selection==124:\n","    #1\n","    knn_for_CDH = KNeighborsClassifier(n_neighbors=2)\n","    knn_for_CDH.fit(X_train_for_CDH, y_train_for_CDH)\n","    X_train_neighbors_index = knn_for_CDH.kneighbors(X_train_for_CDH)[1]\n","    #we only select the second best neighbor, the first best neighbor of a case will be itself\n","    X_train_neighbors_index = X_train_neighbors_index[:,1]\n","    X_train_neighbors1 = X_train_for_CDH.iloc[X_train_neighbors_index]\n","    #IMPORTANT NOTE: left side of difference should be target, right side is source (or the retrieved case)\n","    y_train_neighbors = y_train_for_CDH.iloc[X_train_neighbors_index]\n","\n","    for i in range(len(X_train_for_CDH.index)):\n","      # print(X_train_for_CDH.shape)\n","      # print(pd.concat([X_train_for_CDH.iloc[[i]], X_train_neighbors1.iloc[[i]]],axis = 1).shape)\n","      # print(pd.concat([X_train_for_CDH.iloc[[i]], X_train_neighbors1.iloc[[i]]],axis = 1))\n","      # print(pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],axis = 0).shape)\n","      # print(pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],ignore_index=True))\n","      # print(pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],ignore_index=True).shape)\n","      #TODO, maybe use series version? \n","      # addToPairList(y_train_for_CDH.iloc[i], pd.concat([X_train_for_CDH.iloc[[i]], X_train_neighbors1.iloc[[i]]],axis = 1), y_train_neighbors.iloc[i])\n","      addToPairList(y_train_for_CDH.iloc[i], pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],ignore_index=True), y_train_neighbors.iloc[i])\n","    #2\n","    X_train_neighbors2_left = 0\n","    X_train_neighbors2_right = 0\n","    y_train_neighbors2_left = 0\n","    y_train_neighbors2_right = 0\n","    if pair_selection == 12:#not updated\n","      X_train_for_CDH_index = [*range(len(X_train_for_CDH))]\n","      np.random.shuffle(X_train_for_CDH_index) #shuffle in place\n","      X_train_neighbors2 = X_train_for_CDH[X_train_for_CDH_index]\n","      y_train_neighbors = y_train_for_CDH[X_train_for_CDH_index]\n","      X_train_differences2 = X_train_for_CDH - X_train_neighbors2\n","      y_train_differences2 = y_train_for_CDH - y_train_neighbors\n","    elif pair_selection ==124:\n","      left_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\n","      right_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\n","      X_train_neighbors2_left = X_train_for_CDH.iloc[left_index]\n","      y_train_neighbors2_left = y_train_for_CDH.iloc[left_index]\n","      X_train_neighbors2_right = X_train_for_CDH.iloc[right_index]\n","      y_train_neighbors2_right = y_train_for_CDH.iloc[right_index]\n","    for i in range(len(X_train_neighbors2_left.index)):\n","      addToPairList(y_train_neighbors2_left.iloc[i], pd.concat([X_train_neighbors2_left.iloc[i], X_train_neighbors2_right.iloc[i]],ignore_index=True),y_train_neighbors2_right.iloc[i])\n","    # X_train_pairs1 = np.concatenate((X_train_for_CDH, X_train_neighbors1), axis = 1)\n","    # X_train_pairs2 = np.concatenate((X_train_neighbors2_left, X_train_neighbors2_right), axis = 1)\n","    # X_train_pairs = np.concatenate((X_train_pairs1,X_train_pairs2), axis = 0)\n","    # y_train_pairs = np.concatenate((y_train_neighbors, y_train_neighbors2), axis= 0)\n","    \n","\n","  \n","  #converting pairs data to nparray\n","  for i in range(num_classes):\n","    X_train_pairs_by_class[i] = np.asarray(X_train_pairs_by_class[i]) \n","    y_train_pairs_by_class[i] = np.asarray(y_train_pairs_by_class[i])\n","  # print(\"test1vvfdi:\")\n","  # print(X_train_pairs_by_class[0][0])\n","  # print(\"shape\", X_train_pairs_by_class[0][0].shape)\n","  # print(y_train_pairs_by_class[0][0])\n","\n","  #training adapt models\n","  adapt_models = [None for _ in range(num_classes)]\n","  for i in range(num_classes):\n","    adapt_model = None\n","    #select training pairs\n","    X_train_pairs = X_train_pairs_by_class[i]\n","    y_train_pairs = y_train_pairs_by_class[i]\n","\n","    # print(\"Debug 389ngfv\")\n","    # print(len(X_train_pairs))\n","    # print(len(X_train_pairs[0]))\n","    # print(len(y_train_pairs))\n","    # print(\"length is\",len(X_train_pairs[0]))\n","    adapt_model = build_adaptation_model(X_train_pairs)\n","    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_param)\n","    EPOCHS = 1000\n","    X_adapt_train, X_adapt_valid, y_adapt_train, y_adapt_valid = train_test_split(X_train_pairs, y_train_pairs, test_size=0.05, shuffle= True)\n","    early_history = adapt_model.fit(X_adapt_train, y_adapt_train, \n","                        epochs=EPOCHS, validation_data=(X_adapt_valid, y_adapt_valid), verbose=verbose_param, \n","                        callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","    print(\"adapt model last loss: \",early_history.history['val_loss'][-1])\n","    adapt_models[i] = adapt_model\n","  #CBR retrieval + adaptation\n","  # X_test_differences = X_test - X_test_neighbors\n","  y_adapt_pred = []\n","\n","  for i in range(len(X_test_neighbors.index)):\n","    for src_class in range(num_classes):\n","      if y_test_neighbors.iloc[i][src_class] == 1: #column label might be an issue. TOOD\n","        queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\n","        y_pred = adapt_models[src_class].predict(queryForAdapt)\n","        y_adapt_pred.append(y_pred[0])\n","        continue\n","\n","  y_adapt_pred = np.asarray(y_adapt_pred)\n","  y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\n","\n","  retrieval_N_adapt_loss = accuracy_score(y_test, y_adapt_pred)\n","\n","  #EAC + CDH\n","  retrieval_N_EAC_adapt_loss = -1\n","  if(EAC_adapt==1):\n","    y_adapt_pred = []\n","    for i in range(len(X_test_EAC_retrieved_index)):\n","      #for one query\n","      # voting = [0 for _ in range(num_classes)]\n","      voting = np.zeros((num_classes,), dtype=int)\n","      for j in range(len(X_test_EAC_retrieved_index[i])):\n","        retrieved_index = X_test_EAC_retrieved_index[i][j]\n","        for src_class in range(num_classes):\n","          if(y_train.iloc[retrieved_index][src_class] == 1):\n","            queryForAdapt = np.asarray([pd.concat([X_train.iloc[retrieved_index], X_test.iloc[i]],ignore_index=True)])\n","            y_pred = adapt_models[src_class].predict(queryForAdapt)\n","            voting = np.add(voting, y_pred[0])\n","      y_adapt_pred.append(voting)\n","\n","    y_adapt_pred = np.asarray(y_adapt_pred)\n","    y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\n","\n","    retrieval_N_EAC_adapt_loss = accuracy_score(y_test, y_adapt_pred)\n","  #normal CDH\n","  cdh_knns = [KNeighborsClassifier(n_neighbors=1) for _ in range(num_classes)]\n","  # cdh_knn = KNeighborsClassifier(n_neighbors=1)\n","  # might need multiple knn here , one for each class.\n","  for class_index in range(num_classes):\n","    X_train_pairs = X_train_pairs_by_class[class_index]\n","    y_train_pairs = y_train_pairs_by_class[class_index]\n","    cdh_knns[class_index].fit(X_train_pairs, y_train_pairs)\n","  # y_diff_pred = knn.predict(pd.concat([X_test_neighbors, X_test],axis = 1))  \n","  y_diff_pred = []\n","  for i in range(len(X_test_neighbors.index)):\n","    for src_class in range(num_classes):\n","      if y_test_neighbors.iloc[i][src_class] == 1: #column label might be an issue. TOOD\n","        queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\n","        y_pred = cdh_knns[src_class].predict(queryForAdapt)\n","        y_diff_pred.append(y_pred[0])\n","        continue\n","  answer_pred_adapted =  y_diff_pred\n","  answer_pred_adapted = np.asarray(answer_pred_adapted)\n","  # print(\"normal Cdh\",answer_pred_adapted)\n","  normal_cdh_loss = accuracy_score(y_test, answer_pred_adapted)\n","\n","  #CBR retrieval + adaptation\n","  # X_test_differences = X_test - X_test_neighbors\n","  # y_adapt_pred = adapt_model.predict(X_test_differences)\n","  # y_test_pred = y_test_neighbors + y_adapt_pred\n","  print(\"\")\n","  print(\"dl_loss\", dl_loss)\n","  print(\"knn_loss\", knn_loss)\n","  print(\"retrieval_loss\", retrieval_loss)\n","  print(\"retrieval_N_adapt_loss\", retrieval_N_adapt_loss)\n","  print(\"CBR normal CDH loss\", normal_cdh_loss)\n","  if(EAC_adapt==1):\n","    print(\"retrieval_N_EAC_adapt_loss loss\", retrieval_N_EAC_adapt_loss)\n","  # return (dl_model, knn, adapt_model)\n","  return (dl_loss, knn_loss, retrieval_loss, retrieval_N_adapt_loss, normal_cdh_loss, retrieval_N_EAC_adapt_loss)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FA6YBs-DdZIV"},"source":["#Separate the training and testing\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"NBETJk4P9MfD","executionInfo":{"status":"ok","timestamp":1611095248054,"user_tz":300,"elapsed":20049,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["# from sklearn.neighbors import KNeighborsClassifier\n","# from sklearn.metrics import mean_squared_error\n","# import tensorflow_docs as tfdocs\n","# import tensorflow_docs.plots\n","# import tensorflow_docs.modeling\n","# import matplotlib.pyplot as plt\n","# from sklearn.model_selection import train_test_split\n","\n","# #revamped feature config\n","# #EAC_adapt:0, no EAC; 1 EAC; 2 C2C-EAC\n","# #pair_selection: 1, neighbor; 4, random pairs; 5, C2C pairs\n","# #C2C IS ONLY USABLE WHEN EAC_adapt contains 2 and pair_selection contains 5 \n","# def train_models(X_train,y_train, EAC_adapt,pair_selection, pair_knowledge, verbose_param):\n","#   #pure DL model\n","#   dl_model = build_DL_model(X_train)\n","#   # The patience parameter is the amount of epochs to check for improvement\n","#   early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","#   EPOCHS = 1000\n","#   X_dl_train, X_dl_valid, y_dl_train, y_dl_valid = train_test_split(X_train, y_train, test_size=0.1, shuffle= True)\n","#   early_history = dl_model.fit(X_dl_train, y_dl_train, \n","#                       epochs=EPOCHS, validation_data=(X_dl_valid, y_dl_valid), verbose=verbose_param, \n","#                       callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","#   # plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\n","#   # plt.ylabel('MAE')\n","#   print(\"dl last loss: \",early_history.history['val_loss'][-1])\n","\n","\n","#   #pure knn\n","#   knn = KNeighborsClassifier(n_neighbors=3)\n","#   knn.fit(X_train, y_train)\n","\n","#   #knn by class\n","#   X_train_by_class = [[] for _ in range(num_classes)]\n","#   y_train_by_class = [[] for _ in range(num_classes)]\n","#   knn_by_class= [0 for _ in range(num_classes) ]\n","#   if(\"2\" in EAC_adapt and \"5\" in pair_selection):\n","#     for i in range(len(y_train.index)):\n","#       for src_class in range(num_classes):\n","#         if y_train.iloc[i][src_class] == 1:\n","#           X_train_by_class[src_class].append(X_train.iloc[i])\n","#           y_train_by_class[src_class].append(y_train.iloc[i])\n","#           break\n","#     for src_class in range(num_classes):\n","#       classKnn = KNeighborsClassifier(n_neighbors=1)\n","#       classKnn.fit(X_train_by_class[src_class], y_train_by_class[src_class])\n","#       knn_by_class[src_class] = classKnn\n","\n","#   #CBR adaptaion ML-CDH learning\n","#   #pool for training pairs\n","#   X_train_for_CDH = X_train\n","#   y_train_for_CDH = y_train\n","#   random_pairs_count = 10 * len(X_train_for_CDH)\n","\n","#   X_train_pairs_by_class = [[] for _ in range(num_classes)]\n","#   y_train_pairs_by_class = [[] for _ in range(num_classes)]\n","\n","#   def addToPairList(source_y, X_train_pair, target_y):\n","#     for src_class in range(num_classes):\n","#       if source_y[src_class] == 1:\n","#         X_train_pairs_by_class[src_class].append(X_train_pair)\n","#         y_train_pairs_by_class[src_class].append(target_y)\n","#         break\n"," \n","#   #Assemble pairs\n","#   if \"1\" in pair_selection:\n","#     knn_for_CDH = KNeighborsClassifier(n_neighbors=2)\n","#     knn_for_CDH.fit(X_train_for_CDH, y_train_for_CDH)\n","#     X_train_neighbors_index = knn_for_CDH.kneighbors(X_train_for_CDH)[1]\n","#     #we only select the second best neighbor, the first best neighbor of a case will be itself\n","#     X_train_neighbors_index = X_train_neighbors_index[:,1]\n","#     X_train_neighbors1 = X_train_for_CDH.iloc[X_train_neighbors_index]\n","#     #IMPORTANT NOTE: left side of difference should be target, right side is source (or the retrieved case)\n","#     y_train_neighbors = y_train_for_CDH.iloc[X_train_neighbors_index]\n","\n","#     for i in range(len(X_train_for_CDH.index)):\n","#       addToPairList(y_train_for_CDH.iloc[i], pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],ignore_index=True), y_train_neighbors.iloc[i])\n","#   if \"2\" in pair_selection:#not updated\n","#     #2\n","#     X_train_neighbors2_left = 0\n","#     X_train_neighbors2_right = 0\n","#     y_train_neighbors2_left = 0\n","#     y_train_neighbors2_right = 0\n","#     if pair_selection == 12:#not updated\n","#       X_train_for_CDH_index = [*range(len(X_train_for_CDH))]\n","#       np.random.shuffle(X_train_for_CDH_index) #shuffle in place\n","#       X_train_neighbors2 = X_train_for_CDH[X_train_for_CDH_index]\n","#       y_train_neighbors = y_train_for_CDH[X_train_for_CDH_index]\n","#       X_train_differences2 = X_train_for_CDH - X_train_neighbors2\n","#       y_train_differences2 = y_train_for_CDH - y_train_neighbors\n","#   if \"4\" in pair_selection:\n","#     left_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\n","#     right_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\n","#     X_train_neighbors2_left = X_train_for_CDH.iloc[left_index]\n","#     y_train_neighbors2_left = y_train_for_CDH.iloc[left_index]\n","#     X_train_neighbors2_right = X_train_for_CDH.iloc[right_index]\n","#     y_train_neighbors2_right = y_train_for_CDH.iloc[right_index]\n","#     for i in range(len(X_train_neighbors2_left.index)):\n","#       addToPairList(y_train_neighbors2_left.iloc[i], pd.concat([X_train_neighbors2_left.iloc[i], X_train_neighbors2_right.iloc[i]],ignore_index=True),y_train_neighbors2_right.iloc[i])\n","#   if \"5\" in pair_selection:#select C2C neighbors\n","#     for src_class in range(num_classes):#src class\n","#       for i in range(len(y_train_by_class[src_class])):\n","#         X_train_neighbors5_left = (np.asarray(X_train_by_class[src_class][i])).reshape(1,-1)\n","#         y_train_neighbors5_left = y_train_by_class[src_class][i]\n","#         # y_train_neighbors5_left = np.asarray(y_train_by_class[src_class][i]).reshape(1, -1)\n","\n","#         for tgt_class in range(num_classes): #target classes\n","#           if(tgt_class == src_class):#skip\n","#             continue\n","#           #.reshape(1, -1)\n","#           X_test_retrieved_index = knn_by_class[tgt_class].kneighbors(X_train_neighbors5_left)[1]\n","#           X_test_retrieved_index = X_test_retrieved_index[:,0][0]\n","#           X_train_neighbors5_right = X_train_by_class[tgt_class][X_test_retrieved_index]\n","#           y_train_neighbors5_right = y_train_by_class[tgt_class][X_test_retrieved_index]\n","#           # print(X_train_neighbors5_left)\n","#           X_train_neighbors5_left_series = pd.Series(X_train_neighbors5_left[0])\n","#           # print(X_train_neighbors5_left)\n","#           # print(X_train_neighbors5_right)\n","          \n","#           addToPairList(y_train_neighbors5_left, \n","#                         pd.concat([X_train_neighbors5_left_series, X_train_neighbors5_right],ignore_index=True),y_train_neighbors5_right)\n","\n","  \n","#   #converting pairs data to nparray\n","#   for i in range(num_classes):\n","#     X_train_pairs_by_class[i] = np.asarray(X_train_pairs_by_class[i]) \n","#     y_train_pairs_by_class[i] = np.asarray(y_train_pairs_by_class[i])\n","#   # print(\"test1vvfdi:\")\n","#   # print(X_train_pairs_by_class[0][0])\n","#   # print(\"shape\", X_train_pairs_by_class[0][0].shape)\n","#   # print(y_train_pairs_by_class[0][0])\n","\n","#   #training adapt models\n","#   adapt_models = [None for _ in range(num_classes)]\n","#   for i in range(num_classes):\n","#     adapt_model = None\n","#     #select training pairs\n","#     X_train_pairs = X_train_pairs_by_class[i]\n","#     y_train_pairs = y_train_pairs_by_class[i]\n","\n","#     # print(\"Debug 389ngfv\")\n","#     # print(len(X_train_pairs))\n","#     # print(len(X_train_pairs[0]))\n","#     # print(len(y_train_pairs))\n","#     # print(\"length is\",len(X_train_pairs[0]))\n","#     adapt_model = build_adaptation_model(X_train_pairs)\n","#     early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_param)\n","#     EPOCHS = 1000\n","#     X_adapt_train, X_adapt_valid, y_adapt_train, y_adapt_valid = train_test_split(X_train_pairs, y_train_pairs, test_size=0.05, shuffle= True)\n","#     early_history = adapt_model.fit(X_adapt_train, y_adapt_train, \n","#                         epochs=EPOCHS, validation_data=(X_adapt_valid, y_adapt_valid), verbose=verbose_param, \n","#                         callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","#     print(\"adapt model last loss: \",early_history.history['val_loss'][-1])\n","#     adapt_models[i] = adapt_model\n","\n","#   #normal CDH\n","#   cdh_knns = [KNeighborsClassifier(n_neighbors=1) for _ in range(num_classes)]\n","#   # cdh_knn = KNeighborsClassifier(n_neighbors=1)\n","#   # might need multiple knn here , one for each class.\n","#   for class_index in range(num_classes):\n","#     X_train_pairs = X_train_pairs_by_class[class_index]\n","#     y_train_pairs = y_train_pairs_by_class[class_index]\n","#     cdh_knns[class_index].fit(X_train_pairs, y_train_pairs)\n","\n","    \n","#   return (dl_model, knn, adapt_models, cdh_knns, knn_by_class, X_train_by_class, y_train_by_class)"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvyjnvvftF1w"},"source":["testing part\r\n"]},{"cell_type":"code","metadata":{"id":"9p3IT5Wn-YgM","executionInfo":{"status":"ok","timestamp":1611095248055,"user_tz":300,"elapsed":20046,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["# def test_models(X_train,y_train,X_test,y_test, EAC_adapt, dl_model, knn, adapt_models, cdh_knns, knn_by_class,X_train_by_class, y_train_by_class):\r\n","#   y_test_pred = dl_model.predict(X_test)\r\n","#   y_test_pred = tf.one_hot(tf.argmax(y_test_pred, 1), y_test_pred.shape[1])\r\n","#   dl_loss = accuracy_score(y_test, y_test_pred)\r\n","#   bal_dl_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_test_pred, 1))\r\n","\r\n","#   y_test_pred = knn.predict(X_test)  \r\n","#   knn_loss = accuracy_score(y_test, y_test_pred)\r\n","#   bal_knn_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), np.argmax(y_test_pred,axis=1))\r\n","\r\n","#   #pure CBR retrieval (knn k=1), no need to retrain knn\r\n","#   X_test_retrieved_index = knn.kneighbors(X_test, n_neighbors=1)[1]\r\n","#   #we only select the best neighbor here!!!\r\n","#   X_test_retrieved_index = X_test_retrieved_index[:,0]\r\n","  \r\n","#   # print(\"debugging\")\r\n","#   # print(len(X_train))\r\n","#   # print(max(X_test_retrieved_index))\r\n","#   X_test_neighbors = X_train.iloc[X_test_retrieved_index]\r\n","#   y_test_neighbors = y_train.iloc[X_test_retrieved_index]\r\n","#   retrieval_loss = accuracy_score(y_test, y_test_neighbors)\r\n","#   bal_retrieval_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), y_test_neighbors.values.argmax(axis=1))\r\n","\r\n","#   #NN-CDH\r\n","#   y_adapt_pred = []\r\n","#   for i in range(len(X_test_neighbors.index)):\r\n","#     for src_class in range(num_classes):\r\n","#       if y_test_neighbors.iloc[i][src_class] == 1: #column label might be an issue. TOOD\r\n","#         queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\r\n","#         y_pred = adapt_models[src_class].predict(queryForAdapt)\r\n","#         y_adapt_pred.append(y_pred[0])\r\n","#         continue\r\n","#   y_adapt_pred = np.asarray(y_adapt_pred)\r\n","#   y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","#   retrieval_N_adapt_loss = accuracy_score(y_test, y_adapt_pred)\r\n","#   bal_retrieval_N_adapt_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","  \r\n","  \r\n","#   #EAC + NN-CDH\r\n","#   retrieval_N_EAC_adapt_loss = -1\r\n","#   if(\"1\" in EAC_adapt):\r\n","#     #EAC retrieval\r\n","#     y_adapt_pred = []\r\n","#     X_test_EAC_retrieved_index = knn.kneighbors(X_test, n_neighbors=3)[1]\r\n","#     for i in range(len(X_test_EAC_retrieved_index)):\r\n","#       #for one query\r\n","#       # voting = [0 for _ in range(num_classes)]\r\n","#       voting = np.zeros((num_classes,), dtype=int)\r\n","#       for j in range(len(X_test_EAC_retrieved_index[i])):\r\n","#         retrieved_index = X_test_EAC_retrieved_index[i][j]\r\n","#         for src_class in range(num_classes):\r\n","#           if(y_train.iloc[retrieved_index][src_class] == 1):\r\n","#             queryForAdapt = np.asarray([pd.concat([X_train.iloc[retrieved_index], X_test.iloc[i]],ignore_index=True)])\r\n","#             y_pred = adapt_models[src_class].predict(queryForAdapt)\r\n","#             voting = np.add(voting, y_pred[0])\r\n","#       y_adapt_pred.append(voting)\r\n","\r\n","#     y_adapt_pred = np.asarray(y_adapt_pred)\r\n","#     y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","\r\n","#     retrieval_N_EAC_adapt_loss = accuracy_score(y_test, y_adapt_pred)\r\n","#     bal_retrieval_N_EAC_adapt_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","  \r\n","#   #C2C-EAC + NN-CDH\r\n","#   C2C_EAC_NN_CDH_loss = -1\r\n","#   bal_C2C_EAC_NN_CDH_loss = -1\r\n","#   if(\"2\" in EAC_adapt):\r\n","#     y_adapt_pred = []\r\n","#     #retrieval part\r\n","#     X_test_EAC_retrieved_index_es = [[] for _ in range(num_classes)]\r\n","#     for src_class in range(num_classes):\r\n","#       X_test_EAC_retrieved_index_es[src_class] = knn_by_class[src_class].kneighbors(X_test, n_neighbors=1)[1]\r\n","#       #we only select the best neighbor here!!!\r\n","#       X_test_EAC_retrieved_index_es[src_class]  = X_test_EAC_retrieved_index_es[src_class][:,0]\r\n","#     for i in range(len(X_test)):\r\n","#       voting = np.zeros((num_classes,), dtype=int)\r\n","#       for src_class in range(num_classes):\r\n","#         retrieved_index = X_test_EAC_retrieved_index_es[src_class][i]\r\n","#         #this index is relative to the class, use X_train_by_class to find it.\r\n","#         retrieved_case = X_train_by_class[src_class][retrieved_index]\r\n","#         retrieved_sol  = y_train_by_class[src_class][retrieved_index]\r\n","#         queryForAdapt = np.asarray([pd.concat([retrieved_case, X_test.iloc[i]],ignore_index=True)])\r\n","#         y_pred = adapt_models[src_class].predict(queryForAdapt)\r\n","#         voting = np.add(voting, y_pred[0])\r\n","#       y_adapt_pred.append(voting)\r\n","    \r\n","#     y_adapt_pred = np.asarray(y_adapt_pred)\r\n","#     y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","\r\n","#     C2C_EAC_NN_CDH_loss = accuracy_score(y_test, y_adapt_pred)\r\n","#     bal_C2C_EAC_NN_CDH_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","#   #TODO\r\n","\r\n","#   #normal CDH\r\n","#   y_diff_pred = []\r\n","#   for i in range(len(X_test_neighbors.index)):\r\n","#     for src_class in range(num_classes):\r\n","#       if y_test_neighbors.iloc[i][src_class] == 1:\r\n","#         queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\r\n","#         y_pred = cdh_knns[src_class].predict(queryForAdapt)\r\n","#         y_diff_pred.append(y_pred[0])\r\n","#         continue\r\n","#   answer_pred_adapted =  y_diff_pred\r\n","#   answer_pred_adapted = np.asarray(answer_pred_adapted)\r\n","#   # print(\"normal Cdh\",answer_pred_adapted)\r\n","#   normal_cdh_loss = accuracy_score(y_test, answer_pred_adapted)\r\n","#   bal_normal_cdh_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(answer_pred_adapted, 1))\r\n","\r\n","#   print(\"\")\r\n","#   print(\"dl_loss\", dl_loss)\r\n","#   print(\"knn_loss\", knn_loss)\r\n","#   print(\"retrieval_loss\", retrieval_loss)\r\n","#   print(\"retrieval_N_adapt_loss\", retrieval_N_adapt_loss)\r\n","#   print(\"CBR normal CDH loss\", normal_cdh_loss)\r\n","#   if(\"1\" in EAC_adapt):\r\n","#     print(\"retrieval_N_EAC_adapt_loss loss\", retrieval_N_EAC_adapt_loss)\r\n","#   if(\"2\" in EAC_adapt):\r\n","#     print(\"C2C_EAC_NN_CDH_loss \", C2C_EAC_NN_CDH_loss)\r\n","#   return (dl_loss, knn_loss, retrieval_loss, retrieval_N_adapt_loss, normal_cdh_loss, retrieval_N_EAC_adapt_loss, C2C_EAC_NN_CDH_loss,\r\n","#           bal_dl_loss, bal_knn_loss, bal_retrieval_loss, bal_retrieval_N_adapt_loss, bal_normal_cdh_loss, bal_retrieval_N_EAC_adapt_loss, bal_C2C_EAC_NN_CDH_loss)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iBIzST6oy05Y"},"source":["## Special version for C2C rerun\r\n","\r\n","The following version is for rerun after my mistake with C2C. Do not use in normal circumstances"]},{"cell_type":"code","metadata":{"id":"0myO2KYPyfmK","executionInfo":{"status":"ok","timestamp":1611095248055,"user_tz":300,"elapsed":20042,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["# from sklearn.neighbors import KNeighborsClassifier\r\n","# from sklearn.metrics import mean_squared_error\r\n","# import tensorflow_docs as tfdocs\r\n","# import tensorflow_docs.plots\r\n","# import tensorflow_docs.modeling\r\n","# import matplotlib.pyplot as plt\r\n","# from sklearn.model_selection import train_test_split\r\n","\r\n","# #revamped feature config\r\n","# #EAC_adapt:0, no EAC; 1 EAC; 2 C2C-EAC\r\n","# #pair_selection: 1, neighbor; 4, random pairs; 5, C2C pairs\r\n","# #C2C IS ONLY USABLE WHEN EAC_adapt contains 2 and pair_selection contains 5 \r\n","# def train_models(X_train,y_train, EAC_adapt,pair_selection, pair_knowledge, verbose_param):\r\n","#   #pure DL model\r\n","#   dl_model = None\r\n","\r\n","#   #pure knn\r\n","#   knn = KNeighborsClassifier(n_neighbors=3)\r\n","#   knn.fit(X_train, y_train)\r\n","\r\n","#   #knn by class\r\n","#   X_train_by_class = [[] for _ in range(num_classes)]\r\n","#   y_train_by_class = [[] for _ in range(num_classes)]\r\n","#   knn_by_class= [0 for _ in range(num_classes) ]\r\n","#   if(\"2\" in EAC_adapt and \"5\" in pair_selection):\r\n","#     for i in range(len(y_train.index)):\r\n","#       for src_class in range(num_classes):\r\n","#         if y_train.iloc[i][src_class] == 1:\r\n","#           X_train_by_class[src_class].append(X_train.iloc[i])\r\n","#           y_train_by_class[src_class].append(y_train.iloc[i])\r\n","#           break\r\n","#     for src_class in range(num_classes):\r\n","#       classKnn = KNeighborsClassifier(n_neighbors=1)\r\n","#       classKnn.fit(X_train_by_class[src_class], y_train_by_class[src_class])\r\n","#       knn_by_class[src_class] = classKnn\r\n","\r\n","#   #CBR adaptaion ML-CDH learning\r\n","#   #pool for training pairs\r\n","#   X_train_for_CDH = X_train\r\n","#   y_train_for_CDH = y_train\r\n","#   random_pairs_count = 10 * len(X_train_for_CDH)\r\n","\r\n","#   X_train_pairs_by_class = [[] for _ in range(num_classes)]\r\n","#   y_train_pairs_by_class = [[] for _ in range(num_classes)]\r\n","\r\n","#   def addToPairList(source_y, X_train_pair, target_y):\r\n","#     for src_class in range(num_classes):\r\n","#       if source_y[src_class] == 1:\r\n","#         X_train_pairs_by_class[src_class].append(X_train_pair)\r\n","#         y_train_pairs_by_class[src_class].append(target_y)\r\n","#         break\r\n"," \r\n","#   #Assemble pairs\r\n","#   if \"1\" in pair_selection:\r\n","#     knn_for_CDH = KNeighborsClassifier(n_neighbors=2)\r\n","#     knn_for_CDH.fit(X_train_for_CDH, y_train_for_CDH)\r\n","#     X_train_neighbors_index = knn_for_CDH.kneighbors(X_train_for_CDH)[1]\r\n","#     #we only select the second best neighbor, the first best neighbor of a case will be itself\r\n","#     X_train_neighbors_index = X_train_neighbors_index[:,1]\r\n","#     X_train_neighbors1 = X_train_for_CDH.iloc[X_train_neighbors_index]\r\n","#     #IMPORTANT NOTE: left side of difference should be target, right side is source (or the retrieved case)\r\n","#     y_train_neighbors = y_train_for_CDH.iloc[X_train_neighbors_index]\r\n","\r\n","#     for i in range(len(X_train_for_CDH.index)):\r\n","#       addToPairList(y_train_for_CDH.iloc[i], pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],ignore_index=True), y_train_neighbors.iloc[i])\r\n","#   if \"2\" in pair_selection:#not updated\r\n","#     #2\r\n","#     X_train_neighbors2_left = 0\r\n","#     X_train_neighbors2_right = 0\r\n","#     y_train_neighbors2_left = 0\r\n","#     y_train_neighbors2_right = 0\r\n","#     if pair_selection == 12:#not updated\r\n","#       X_train_for_CDH_index = [*range(len(X_train_for_CDH))]\r\n","#       np.random.shuffle(X_train_for_CDH_index) #shuffle in place\r\n","#       X_train_neighbors2 = X_train_for_CDH[X_train_for_CDH_index]\r\n","#       y_train_neighbors = y_train_for_CDH[X_train_for_CDH_index]\r\n","#       X_train_differences2 = X_train_for_CDH - X_train_neighbors2\r\n","#       y_train_differences2 = y_train_for_CDH - y_train_neighbors\r\n","#   if \"4\" in pair_selection:\r\n","#     left_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\r\n","#     right_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\r\n","#     X_train_neighbors2_left = X_train_for_CDH.iloc[left_index]\r\n","#     y_train_neighbors2_left = y_train_for_CDH.iloc[left_index]\r\n","#     X_train_neighbors2_right = X_train_for_CDH.iloc[right_index]\r\n","#     y_train_neighbors2_right = y_train_for_CDH.iloc[right_index]\r\n","#     for i in range(len(X_train_neighbors2_left.index)):\r\n","#       addToPairList(y_train_neighbors2_left.iloc[i], pd.concat([X_train_neighbors2_left.iloc[i], X_train_neighbors2_right.iloc[i]],ignore_index=True),y_train_neighbors2_right.iloc[i])\r\n","#   if \"5\" in pair_selection:#select C2C neighbors\r\n","#     for src_class in range(num_classes):#src class\r\n","#       for i in range(len(y_train_by_class[src_class])):\r\n","#         X_train_neighbors5_left = (np.asarray(X_train_by_class[src_class][i])).reshape(1,-1)\r\n","#         y_train_neighbors5_left = y_train_by_class[src_class][i]\r\n","#         # y_train_neighbors5_left = np.asarray(y_train_by_class[src_class][i]).reshape(1, -1)\r\n","\r\n","#         for tgt_class in range(num_classes): #target classes\r\n","#           if(tgt_class == src_class):#skip\r\n","#             continue\r\n","#           #.reshape(1, -1)\r\n","#           X_test_retrieved_index = knn_by_class[tgt_class].kneighbors(X_train_neighbors5_left)[1]\r\n","#           X_test_retrieved_index = X_test_retrieved_index[:,0][0]\r\n","#           X_train_neighbors5_right = X_train_by_class[tgt_class][X_test_retrieved_index]\r\n","#           y_train_neighbors5_right = y_train_by_class[tgt_class][X_test_retrieved_index]\r\n","#           # print(X_train_neighbors5_left)\r\n","#           X_train_neighbors5_left_series = pd.Series(X_train_neighbors5_left[0])\r\n","#           # print(X_train_neighbors5_left)\r\n","#           # print(X_train_neighbors5_right)\r\n","          \r\n","#           addToPairList(y_train_neighbors5_left, \r\n","#                         pd.concat([X_train_neighbors5_left_series, X_train_neighbors5_right],ignore_index=True),y_train_neighbors5_right)\r\n","\r\n","  \r\n","#   #converting pairs data to nparray\r\n","#   for i in range(num_classes):\r\n","#     X_train_pairs_by_class[i] = np.asarray(X_train_pairs_by_class[i]) \r\n","#     y_train_pairs_by_class[i] = np.asarray(y_train_pairs_by_class[i])\r\n","#   # print(\"test1vvfdi:\")\r\n","#   # print(X_train_pairs_by_class[0][0])\r\n","#   # print(\"shape\", X_train_pairs_by_class[0][0].shape)\r\n","#   # print(y_train_pairs_by_class[0][0])\r\n","\r\n","#   #training adapt models\r\n","#   adapt_models = [None for _ in range(num_classes)]\r\n","#   for i in range(num_classes):\r\n","#     adapt_model = None\r\n","#     #select training pairs\r\n","#     X_train_pairs = X_train_pairs_by_class[i]\r\n","#     y_train_pairs = y_train_pairs_by_class[i]\r\n","\r\n","#     # print(\"Debug 389ngfv\")\r\n","#     # print(len(X_train_pairs))\r\n","#     # print(len(X_train_pairs[0]))\r\n","#     # print(len(y_train_pairs))\r\n","#     # print(\"length is\",len(X_train_pairs[0]))\r\n","#     adapt_model = build_adaptation_model(X_train_pairs)\r\n","#     early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_param)\r\n","#     EPOCHS = 1000\r\n","#     X_adapt_train, X_adapt_valid, y_adapt_train, y_adapt_valid = train_test_split(X_train_pairs, y_train_pairs, test_size=0.05, shuffle= True)\r\n","#     early_history = adapt_model.fit(X_adapt_train, y_adapt_train, \r\n","#                         epochs=EPOCHS, validation_data=(X_adapt_valid, y_adapt_valid), verbose=verbose_param, \r\n","#                         callbacks=[early_stop, tfdocs.modeling.EpochDots()])\r\n","\r\n","#     print(\"adapt model last loss: \",early_history.history['val_loss'][-1])\r\n","#     adapt_models[i] = adapt_model\r\n","\r\n","#   #normal CDH\r\n","#   cdh_knns = None\r\n","\r\n","    \r\n","#   return (dl_model, knn, adapt_models, cdh_knns, knn_by_class, X_train_by_class, y_train_by_class)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0tEL3S8zRZ1","executionInfo":{"status":"ok","timestamp":1611095248056,"user_tz":300,"elapsed":20038,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["# def test_models(X_train,y_train,X_test,y_test, EAC_adapt, dl_model, knn, adapt_models, cdh_knns, knn_by_class,X_train_by_class, y_train_by_class):\r\n","\r\n","#   dl_loss = 0\r\n","#   bal_dl_loss = 0\r\n","\r\n","#   knn_loss = 0\r\n","#   bal_knn_loss = 0\r\n","\r\n","#   #pure CBR retrieval (knn k=1), no need to retrain knn\r\n","#   # X_test_retrieved_index = knn.kneighbors(X_test, n_neighbors=1)[1]\r\n","#   # #we only select the best neighbor here!!!\r\n","#   # X_test_retrieved_index = X_test_retrieved_index[:,0]\r\n","  \r\n","#   # # print(\"debugging\")\r\n","#   # # print(len(X_train))\r\n","#   # # print(max(X_test_retrieved_index))\r\n","#   # X_test_neighbors = X_train.iloc[X_test_retrieved_index]\r\n","#   # y_test_neighbors = y_train.iloc[X_test_retrieved_index]\r\n","#   retrieval_loss = 0\r\n","#   bal_retrieval_loss = 0\r\n","\r\n","#   #NN-CDH\r\n","#   # y_adapt_pred = []\r\n","#   # for i in range(len(X_test_neighbors.index)):\r\n","#   #   for src_class in range(num_classes):\r\n","#   #     if y_test_neighbors.iloc[i][src_class] == 1: #column label might be an issue. TOOD\r\n","#   #       queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\r\n","#   #       y_pred = adapt_models[src_class].predict(queryForAdapt)\r\n","#   #       y_adapt_pred.append(y_pred[0])\r\n","#   #       continue\r\n","#   # y_adapt_pred = np.asarray(y_adapt_pred)\r\n","#   # y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","#   retrieval_N_adapt_loss = 0# accuracy_score(y_test, y_adapt_pred)\r\n","#   bal_retrieval_N_adapt_loss =0# balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","  \r\n","  \r\n","#   #EAC + NN-CDH\r\n","#   retrieval_N_EAC_adapt_loss = -1\r\n","#   if(\"1\" in EAC_adapt):\r\n","#     # #EAC retrieval\r\n","#     # y_adapt_pred = []\r\n","#     # X_test_EAC_retrieved_index = knn.kneighbors(X_test, n_neighbors=3)[1]\r\n","#     # for i in range(len(X_test_EAC_retrieved_index)):\r\n","#     #   #for one query\r\n","#     #   # voting = [0 for _ in range(num_classes)]\r\n","#     #   voting = np.zeros((num_classes,), dtype=int)\r\n","#     #   for j in range(len(X_test_EAC_retrieved_index[i])):\r\n","#     #     retrieved_index = X_test_EAC_retrieved_index[i][j]\r\n","#     #     for src_class in range(num_classes):\r\n","#     #       if(y_train.iloc[retrieved_index][src_class] == 1):\r\n","#     #         queryForAdapt = np.asarray([pd.concat([X_train.iloc[retrieved_index], X_test.iloc[i]],ignore_index=True)])\r\n","#     #         y_pred = adapt_models[src_class].predict(queryForAdapt)\r\n","#     #         voting = np.add(voting, y_pred[0])\r\n","#     #   y_adapt_pred.append(voting)\r\n","\r\n","#     # y_adapt_pred = np.asarray(y_adapt_pred)\r\n","#     # y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","\r\n","#     retrieval_N_EAC_adapt_loss = 0 #accuracy_score(y_test, y_adapt_pred)\r\n","#     bal_retrieval_N_EAC_adapt_loss = 0# balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","  \r\n","#   #C2C-EAC + NN-CDH\r\n","#   C2C_EAC_NN_CDH_loss = -1\r\n","#   bal_C2C_EAC_NN_CDH_loss = -1\r\n","#   if(\"2\" in EAC_adapt):\r\n","#     y_adapt_pred = []\r\n","#     #retrieval part\r\n","#     X_test_EAC_retrieved_index_es = [[] for _ in range(num_classes)]\r\n","#     for src_class in range(num_classes):\r\n","#       X_test_EAC_retrieved_index_es[src_class] = knn_by_class[src_class].kneighbors(X_test, n_neighbors=1)[1]\r\n","#       #we only select the best neighbor here!!!\r\n","#       X_test_EAC_retrieved_index_es[src_class]  = X_test_EAC_retrieved_index_es[src_class][:,0]\r\n","#     for i in range(len(X_test)):\r\n","#       voting = np.zeros((num_classes,), dtype=int)\r\n","#       for src_class in range(num_classes):\r\n","#         retrieved_index = X_test_EAC_retrieved_index_es[src_class][i]\r\n","#         #this index is relative to the class, use X_train_by_class to find it.\r\n","#         retrieved_case = X_train_by_class[src_class][retrieved_index]\r\n","#         retrieved_sol  = y_train_by_class[src_class][retrieved_index]\r\n","#         queryForAdapt = np.asarray([pd.concat([retrieved_case, X_test.iloc[i]],ignore_index=True)])\r\n","#         y_pred = adapt_models[src_class].predict(queryForAdapt)\r\n","#         voting = np.add(voting, y_pred[0])\r\n","#       y_adapt_pred.append(voting)\r\n","    \r\n","#     y_adapt_pred = np.asarray(y_adapt_pred)\r\n","#     y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","\r\n","#     C2C_EAC_NN_CDH_loss = accuracy_score(y_test, y_adapt_pred)\r\n","#     bal_C2C_EAC_NN_CDH_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","#   #TODO\r\n","\r\n","#   #normal CDH\r\n","#   # y_diff_pred = []\r\n","#   # for i in range(len(X_test_neighbors.index)):\r\n","#   #   for src_class in range(num_classes):\r\n","#   #     if y_test_neighbors.iloc[i][src_class] == 1:\r\n","#   #       queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\r\n","#   #       y_pred = cdh_knns[src_class].predict(queryForAdapt)\r\n","#   #       y_diff_pred.append(y_pred[0])\r\n","#   #       continue\r\n","#   # answer_pred_adapted =  y_diff_pred\r\n","#   # answer_pred_adapted = np.asarray(answer_pred_adapted)\r\n","#   # # print(\"normal Cdh\",answer_pred_adapted)\r\n","#   normal_cdh_loss = 0#accuracy_score(y_test, answer_pred_adapted)\r\n","#   bal_normal_cdh_loss =0# balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(answer_pred_adapted, 1))\r\n","\r\n","#   print(\"\")\r\n","#   print(\"dl_loss\", dl_loss)\r\n","#   print(\"knn_loss\", knn_loss)\r\n","#   print(\"retrieval_loss\", retrieval_loss)\r\n","#   print(\"retrieval_N_adapt_loss\", retrieval_N_adapt_loss)\r\n","#   print(\"CBR normal CDH loss\", normal_cdh_loss)\r\n","#   if(\"1\" in EAC_adapt):\r\n","#     print(\"retrieval_N_EAC_adapt_loss loss\", retrieval_N_EAC_adapt_loss)\r\n","#   if(\"2\" in EAC_adapt):\r\n","#     print(\"C2C_EAC_NN_CDH_loss \", C2C_EAC_NN_CDH_loss)\r\n","#   return (dl_loss, knn_loss, retrieval_loss, retrieval_N_adapt_loss, normal_cdh_loss, retrieval_N_EAC_adapt_loss, C2C_EAC_NN_CDH_loss,\r\n","#           bal_dl_loss, bal_knn_loss, bal_retrieval_loss, bal_retrieval_N_adapt_loss, bal_normal_cdh_loss, bal_retrieval_N_EAC_adapt_loss, bal_C2C_EAC_NN_CDH_loss)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hiWl4WfMLllx"},"source":["##Special version for not segmenting training examples\r\n","\r\n","The following is for testing a single adaptation model learning all adaptation examples, not segmented by their source solution. Do not use in normal circumstances."]},{"cell_type":"code","metadata":{"id":"vsLiYcK0L6It","executionInfo":{"status":"ok","timestamp":1611095248280,"user_tz":300,"elapsed":20258,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import mean_squared_error\n","import tensorflow_docs as tfdocs\n","import tensorflow_docs.plots\n","import tensorflow_docs.modeling\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","#revamped feature config\n","#EAC_adapt:0, no EAC; 1 EAC; 2 C2C-EAC\n","#pair_selection: 1, neighbor; 4, random pairs; 5, C2C pairs\n","#C2C IS ONLY USABLE WHEN EAC_adapt contains 2 and pair_selection contains 5 \n","def train_models(X_train,y_train, EAC_adapt,pair_selection, pair_knowledge, verbose_param):\n","\n","  #pure knn\n","  knn = KNeighborsClassifier(n_neighbors=3)\n","  knn.fit(X_train, y_train)\n","\n","  #knn by class\n","  X_train_by_class = [[] for _ in range(num_classes)]\n","  y_train_by_class = [[] for _ in range(num_classes)]\n","  knn_by_class= [0 for _ in range(num_classes) ]\n","  if(\"2\" in EAC_adapt and \"5\" in pair_selection):\n","    for i in range(len(y_train.index)):\n","      for src_class in range(num_classes):\n","        if y_train.iloc[i][src_class] == 1:\n","          X_train_by_class[src_class].append(X_train.iloc[i])\n","          y_train_by_class[src_class].append(y_train.iloc[i])\n","          break\n","    for src_class in range(num_classes):\n","      classKnn = KNeighborsClassifier(n_neighbors=1)\n","      classKnn.fit(X_train_by_class[src_class], y_train_by_class[src_class])\n","      knn_by_class[src_class] = classKnn\n","\n","  #CBR adaptaion ML-CDH learning\n","  #pool for training pairs\n","  X_train_for_CDH = X_train\n","  y_train_for_CDH = y_train\n","  random_pairs_count = 10 * len(X_train_for_CDH)\n","\n","  X_train_pairs = []\n","  y_train_pairs_source = []\n","  y_train_pairs_target = []\n","\n","  def addToPairList(source_y, X_train_pair, target_y):\n","    X_train_pairs.append(X_train_pair)\n","    y_train_pairs_source.append(source_y)\n","    y_train_pairs_target.append(target_y)\n","\n","  #Assemble pairs\n","  if \"1\" in pair_selection:\n","    knn_for_CDH = KNeighborsClassifier(n_neighbors=2)\n","    knn_for_CDH.fit(X_train_for_CDH, y_train_for_CDH)\n","    X_train_neighbors_index = knn_for_CDH.kneighbors(X_train_for_CDH)[1]\n","    #we only select the second best neighbor, the first best neighbor of a case will be itself\n","    X_train_neighbors_index = X_train_neighbors_index[:,1]\n","    X_train_neighbors1 = X_train_for_CDH.iloc[X_train_neighbors_index]\n","    #IMPORTANT NOTE: left side of difference should be target, right side is source (or the retrieved case)\n","    y_train_neighbors = y_train_for_CDH.iloc[X_train_neighbors_index]\n","\n","    for i in range(len(X_train_for_CDH.index)):\n","      addToPairList(y_train_for_CDH.iloc[i], pd.concat([X_train_for_CDH.iloc[i], X_train_neighbors1.iloc[i]],ignore_index=True), y_train_neighbors.iloc[i])\n","  if \"2\" in pair_selection:#not updated\n","    #2\n","    X_train_neighbors2_left = 0\n","    X_train_neighbors2_right = 0\n","    y_train_neighbors2_left = 0\n","    y_train_neighbors2_right = 0\n","    if pair_selection == 12:#not updated\n","      X_train_for_CDH_index = [*range(len(X_train_for_CDH))]\n","      np.random.shuffle(X_train_for_CDH_index) #shuffle in place\n","      X_train_neighbors2 = X_train_for_CDH[X_train_for_CDH_index]\n","      y_train_neighbors = y_train_for_CDH[X_train_for_CDH_index]\n","      X_train_differences2 = X_train_for_CDH - X_train_neighbors2\n","      y_train_differences2 = y_train_for_CDH - y_train_neighbors\n","  if \"4\" in pair_selection:\n","    left_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\n","    right_index = np.random.choice(len(X_train_for_CDH), random_pairs_count)\n","    X_train_neighbors2_left = X_train_for_CDH.iloc[left_index]\n","    y_train_neighbors2_left = y_train_for_CDH.iloc[left_index]\n","    X_train_neighbors2_right = X_train_for_CDH.iloc[right_index]\n","    y_train_neighbors2_right = y_train_for_CDH.iloc[right_index]\n","    for i in range(len(X_train_neighbors2_left.index)):\n","      addToPairList(y_train_neighbors2_left.iloc[i], pd.concat([X_train_neighbors2_left.iloc[i], X_train_neighbors2_right.iloc[i]],ignore_index=True),y_train_neighbors2_right.iloc[i])\n","  if \"5\" in pair_selection:#select C2C neighbors\n","    for src_class in range(num_classes):#src class\n","      for i in range(len(y_train_by_class[src_class])):\n","        X_train_neighbors5_left = (np.asarray(X_train_by_class[src_class][i])).reshape(1,-1)\n","        y_train_neighbors5_left = y_train_by_class[src_class][i]\n","        # y_train_neighbors5_left = np.asarray(y_train_by_class[src_class][i]).reshape(1, -1)\n","\n","        for tgt_class in range(num_classes): #target classes\n","          if(tgt_class == src_class):#skip\n","            continue\n","          #.reshape(1, -1)\n","          X_test_retrieved_index = knn_by_class[tgt_class].kneighbors(X_train_neighbors5_left)[1]\n","          X_test_retrieved_index = X_test_retrieved_index[:,0][0]\n","          X_train_neighbors5_right = X_train_by_class[tgt_class][X_test_retrieved_index]\n","          y_train_neighbors5_right = y_train_by_class[tgt_class][X_test_retrieved_index]\n","          # print(X_train_neighbors5_left)\n","          X_train_neighbors5_left_series = pd.Series(X_train_neighbors5_left[0])\n","          # print(X_train_neighbors5_left)\n","          # print(X_train_neighbors5_right)\n","          \n","          addToPairList(y_train_neighbors5_left, \n","                        pd.concat([X_train_neighbors5_left_series, X_train_neighbors5_right],ignore_index=True),y_train_neighbors5_right)\n","\n","  \n","  #converting pairs data to nparray\n","  \n","  X_train_pairs = np.asarray(X_train_pairs)\n","  y_train_pairs_source = np.asarray(y_train_pairs_source)\n","  y_train_pairs_target = np.asarray(y_train_pairs_target)\n","\n","  # print(\"test1vvfdi:\")\n","  # print(X_train_pairs_by_class[0][0])\n","  # print(\"shape\", X_train_pairs_by_class[0][0].shape)\n","  # print(y_train_pairs_by_class[0][0])\n","\n","  #training adapt models\n","  # adapt_models = [None for _ in range(num_classes)]\n","  adapt_model_without_source = None\n","\n","  adapt_model_without_source = build_adaptation_model(X_train_pairs)\n","  early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_param)\n","  EPOCHS = 1000\n","  X_adapt_train, X_adapt_valid, y_adapt_train, y_adapt_valid = train_test_split(X_train_pairs, y_train_pairs_target, test_size=0.05, shuffle= True)\n","  early_history = adapt_model_without_source.fit(X_adapt_train, y_adapt_train, \n","                    epochs=EPOCHS, validation_data=(X_adapt_valid, y_adapt_valid), verbose=verbose_param, \n","                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","  print(\"adapt model (without source) last loss: \",early_history.history['val_loss'][-1])\n","\n","  # for i in range(num_classes):\n","  #   adapt_model = None\n","  #   #select training pairs\n","  #   X_train_pairs = X_train_pairs_by_class[i]\n","  #   y_train_pairs = y_train_pairs_by_class[i]\n","\n","  #   # print(\"Debug 389ngfv\")\n","  #   # print(len(X_train_pairs))\n","  #   # print(len(X_train_pairs[0]))\n","  #   # print(len(y_train_pairs))\n","  #   # print(\"length is\",len(X_train_pairs[0]))\n","  #   adapt_model = build_adaptation_model(X_train_pairs)\n","  #   early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_param)\n","  #   EPOCHS = 1000\n","  #   X_adapt_train, X_adapt_valid, y_adapt_train, y_adapt_valid = train_test_split(X_train_pairs, y_train_pairs, test_size=0.05, shuffle= True)\n","  #   early_history = adapt_model.fit(X_adapt_train, y_adapt_train, \n","  #                       epochs=EPOCHS, validation_data=(X_adapt_valid, y_adapt_valid), verbose=verbose_param, \n","  #                       callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","  #   print(\"adapt model last loss: \",early_history.history['val_loss'][-1])\n","  #   adapt_models[i] = adapt_model\n","\n","  adapt_model_with_source = None\n","\n","  X_train_pairs = np.concatenate((X_train_pairs, y_train_pairs_source), axis=1)\n","  adapt_model_with_source = build_adaptation_model(X_train_pairs)\n","  early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=verbose_param)\n","  EPOCHS = 1000\n","  X_adapt_train, X_adapt_valid, y_adapt_train, y_adapt_valid = train_test_split(X_train_pairs, y_train_pairs_target, test_size=0.05, shuffle= True)\n","  early_history = adapt_model_with_source.fit(X_adapt_train, y_adapt_train, \n","                    epochs=EPOCHS, validation_data=(X_adapt_valid, y_adapt_valid), verbose=verbose_param, \n","                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n","\n","  print(\"adapt model (with source) last loss: \",early_history.history['val_loss'][-1])\n","\n","  return (knn, adapt_model_without_source, adapt_model_with_source)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cbMO2dpwL6Iy"},"source":["testing part\r\n"]},{"cell_type":"code","metadata":{"id":"0FT-kstaL6Iy","executionInfo":{"status":"ok","timestamp":1611095248281,"user_tz":300,"elapsed":20254,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["def test_models(X_train,y_train,X_test,y_test, EAC_adapt, knn, adapt_model_without_source, adapt_model_with_source):\r\n","\r\n","  y_test_pred = knn.predict(X_test)  \r\n","  knn_loss = accuracy_score(y_test, y_test_pred)\r\n","  bal_knn_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), np.argmax(y_test_pred,axis=1))\r\n","\r\n","  #pure CBR retrieval (knn k=1), no need to retrain knn\r\n","  X_test_retrieved_index = knn.kneighbors(X_test, n_neighbors=1)[1]\r\n","  #we only select the best neighbor here!!!\r\n","  X_test_retrieved_index = X_test_retrieved_index[:,0]\r\n","  \r\n","  # print(\"debugging\")\r\n","  # print(len(X_train))\r\n","  # print(max(X_test_retrieved_index))\r\n","  X_test_neighbors = X_train.iloc[X_test_retrieved_index]\r\n","  y_test_neighbors = y_train.iloc[X_test_retrieved_index]\r\n","  retrieval_loss = accuracy_score(y_test, y_test_neighbors)\r\n","  bal_retrieval_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), y_test_neighbors.values.argmax(axis=1))\r\n","\r\n","  #without source\r\n","  y_adapt_pred = []\r\n","  for i in range(len(X_test_neighbors.index)):\r\n","    queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i]],ignore_index=True)])\r\n","    y_pred = adapt_model_without_source.predict(queryForAdapt)\r\n","    y_adapt_pred.append(y_pred[0])\r\n","    continue\r\n","  y_adapt_pred = np.asarray(y_adapt_pred)\r\n","  y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","  without_source_loss = accuracy_score(y_test, y_adapt_pred)\r\n","  bal_without_source_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","  \r\n","  #with source\r\n","  y_adapt_pred = []\r\n","  for i in range(len(X_test_neighbors.index)):\r\n","    queryForAdapt = np.asarray([pd.concat([X_test_neighbors.iloc[i], X_test.iloc[i], y_test_neighbors.iloc[i]],ignore_index=True)])\r\n","    y_pred = adapt_model_with_source.predict(queryForAdapt)\r\n","    y_adapt_pred.append(y_pred[0])\r\n","    continue\r\n","  y_adapt_pred = np.asarray(y_adapt_pred)\r\n","  y_adapt_pred = tf.one_hot(tf.argmax(y_adapt_pred, 1), y_adapt_pred.shape[1])\r\n","  with_source_loss = accuracy_score(y_test, y_adapt_pred)\r\n","  bal_with_source_loss = balanced_accuracy_score(y_test.values.argmax(axis=1), tf.argmax(y_adapt_pred, 1))\r\n","  \r\n","\r\n","  print(\"\")\r\n","  print(\"knn_loss\", knn_loss)\r\n","  print(\"retrieval_loss\", retrieval_loss)\r\n","  print(\"adapt with source\", with_source_loss)\r\n","  print(\"adapt without source\", without_source_loss)\r\n","  return (knn_loss, retrieval_loss, without_source_loss, with_source_loss,\r\n","          bal_knn_loss, bal_retrieval_loss, bal_without_source_loss, bal_with_source_loss)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6JAsCumESaB"},"source":["# Graph and report"]},{"cell_type":"code","metadata":{"id":"L8QOB1gpEoWr","executionInfo":{"status":"ok","timestamp":1611095248281,"user_tz":300,"elapsed":20250,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["import seaborn as sns\n","def plotResults(arr_dl, arr_knn, arr_retrieval_loss, arr_retrieval_N_adapt_loss, arr_normal_cdh_loss):\n","  # kwargs = dict(alpha=0.5, bins=100)\n","  # plt.hist(arr_dl, **kwargs, color='g', label='dl')\n","  sns.distplot(arr_dl, hist = False, kde = True, color='g', label='NN',\n","                  kde_kws = {'linewidth': 3})\n","  # plt.hist(arr_knn, **kwargs, color='b', label='knn')\n","  sns.distplot(arr_knn, hist = False, kde = True, color='b', label='k-NN',\n","                  kde_kws = {'linewidth': 3})\n","  # plt.hist(arr_retrieval_loss, **kwargs, color='r', label='retrieval')\n","  sns.distplot(arr_retrieval_loss, hist = False, kde = True, color='r', label='retrieval',\n","                  kde_kws = {'linewidth': 3})\n","  # plt.hist(arr_retrieval_N_adapt_loss, **kwargs, color='c', label='retNadapt')\n","  sns.distplot(arr_retrieval_N_adapt_loss, hist = False, kde = True, color='c', label='CBR + DL-CDH',\n","                  kde_kws = {'linewidth': 3})\n","  sns.distplot(arr_normal_cdh_loss, hist = False, kde = True, color='y', label='CBR + normal CDH',\n","                  kde_kws = {'linewidth': 3})\n","  plt.gca().set(title='Density plot of loss', xlabel='accuracy')\n","  plt.xlim(0,1)\n","  plt.legend()"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iecplD7nV9cb"},"source":["Maybe distribution plot is biased. Maybe we should show how often CBR beats DL instead."]},{"cell_type":"code","metadata":{"id":"ygapw52_WDNB","executionInfo":{"status":"ok","timestamp":1611095248281,"user_tz":300,"elapsed":20245,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["def reportResults(X_test,arr_dl, arr_knn, arr_retrieval_loss, arr_retrieval_N_adapt_loss, arr_normal_cdh_loss):\n","  adapt_beats_DL = 0\n","  adapt_beats_DL_beats_ret = 0\n","  DL_beats_ret = 0\n","  testedRange = min(too_far, len(X_test))\n","  for i in range(testedRange):\n","    if arr_retrieval_N_adapt_loss[i] < arr_dl[i]:\n","      adapt_beats_DL += 1\n","      if arr_dl[i] < arr_retrieval_loss [i]:\n","        adapt_beats_DL_beats_ret += 1\n","    if arr_dl[i] < arr_retrieval_loss [i]:\n","      DL_beats_ret += 1\n","  print(\"num_cases_removed = \", num_cases_removed)\n","  print(\"total: \", testedRange)\n","  print(\"adapt_beats_DL: \", adapt_beats_DL)\n","  print(\"adapt_beats_DL_beats_ret: \", adapt_beats_DL_beats_ret)\n","  print(\"DL_beats_ret: \", DL_beats_ret)\n","\n","  print(\"np.mean(arr_dl) = \", np.mean(arr_dl))\n","  print(\"np.mean(arr_knn) = \", np.mean(arr_knn))\n","  print(\"np.mean(arr_retrieval_loss) = \", np.mean(arr_retrieval_loss))\n","  print(\"np.mean(arr_retrieval_N_adapt_loss) = \", np.mean(arr_retrieval_N_adapt_loss))\n","  print(\"np.mean(arr_normal_cdh_loss) = \", np.mean(arr_normal_cdh_loss))\n"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCFAxTLjbRVr","executionInfo":{"status":"ok","timestamp":1611095248282,"user_tz":300,"elapsed":20241,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["def reportResults_kFold(prompt, knn_loss_es, retrieval_loss_es, without_source_loss_es, with_source_loss_es):\r\n","  print(\"reporting k Folds\", prompt)\r\n","  print(\"np.mean(knn_loss_es) = \", np.mean(knn_loss_es))\r\n","  print(\"np.mean(retrieval_loss_es) = \", np.mean(retrieval_loss_es))\r\n","  print(\"np.mean(without_source_loss_es) = \", np.mean(without_source_loss_es))\r\n","  print(\"np.mean(with_source_loss_es) = \", np.mean(with_source_loss_es))\r\n","  print(\"\")\r\n","  print(\"reporting std\", prompt)\r\n","  print(\"np.std(knn_loss_es) = \", np.std(knn_loss_es))\r\n","  print(\"np.std(retrieval_loss_es) = \", np.std(retrieval_loss_es))\r\n","  print(\"np.std(without_source_loss_es) = \", np.std(without_source_loss_es))\r\n","  print(\"np.std(with_source_loss_es) = \", np.std(with_source_loss_es))"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqaAicE63QL6","executionInfo":{"status":"ok","timestamp":1611095248282,"user_tz":300,"elapsed":20237,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["def reportGoodBad(X_test,arr_dl, arr_knn, arr_retrieval_loss, arr_retrieval_N_adapt_loss, arr_normal_cdh_loss):\n","  ret = []\n","  testedRange = min(too_far, len(X_test))\n","  for i in range(testedRange):\n","    winner = None\n","    if arr_dl[i] < arr_knn[i] and arr_dl[i] < arr_retrieval_loss[i] and arr_dl[i] < arr_retrieval_N_adapt_loss[i]:\n","      winner = \"dl\"\n","    elif arr_knn[i] < arr_dl[i] and arr_knn[i] < arr_retrieval_loss[i] and arr_knn[i] < arr_retrieval_N_adapt_loss[i]:\n","      winner = \"knn\"\n","    elif arr_retrieval_loss[i] < arr_dl[i] and arr_retrieval_loss[i] < arr_knn[i] and arr_retrieval_loss[i] < arr_retrieval_N_adapt_loss[i]:\n","      winner = \"Retrieve\"\n","    elif arr_retrieval_N_adapt_loss[i] < arr_dl[i] and arr_retrieval_N_adapt_loss[i] < arr_knn[i] and arr_retrieval_N_adapt_loss[i] < arr_retrieval_loss[i]:\n","      winner = \"Adapt\"\n","    print(X_test[i], winner)\n","    ret.append((X_test[i], winner))\n","  return ret"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eC601EXsQH-N"},"source":["# Result: adapt model 2 + random/close pairs +extra pairs + partial. \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u27d8GlgQYN5","executionInfo":{"elapsed":413,"status":"ok","timestamp":1609196637322,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"411354fe-992a-4424-f6eb-b0afb759fb44"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(587, 46)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdiaGNqBcwx0","executionInfo":{"elapsed":28426,"status":"ok","timestamp":1608743783340,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"c73f0eed-256f-46d4-ad20-72a22722a9c3"},"source":["X_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(66, 46)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"49nw7ffnTy8j"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOnVi0IKSz3r","executionInfo":{"elapsed":47612,"status":"ok","timestamp":1608743802535,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"ba79c64d-36f0-4fe4-c34c-9cedf4d30032"},"source":["#ALL PARAMETERS HERE\n","#0, no EAC\n","#1, adapt from multiple neighbors\n","#2, adapt from multiple neighbors, each from a different class.\n","EAC_adapt = 1\n","#1, rules from nearest pairs\n","#2, rules from random pairs\n","#12, rules from both nearest pairs and random pairs\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\n","pair_selection = 124\n","random_pairs_count = 100\n","#1, pair from partial knowledge\n","#2, pair from full knowledge\n","pair_knowledge = 1\n","test_full_without_removal(EAC_adapt,pair_selection, pair_knowledge, 0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.6593,  loss:0.6405,  val_accuracy:0.9091,  val_loss:0.4241,  \n","..............dl last loss:  0.31456121802330017\n","\n","Epoch: 0, accuracy:0.6503,  loss:0.6393,  val_accuracy:0.5882,  val_loss:0.7942,  \n","...................adapt model last loss:  0.4176803231239319\n","\n","Epoch: 0, accuracy:0.7536,  loss:0.5035,  val_accuracy:0.6316,  val_loss:0.7814,  \n",".................................adapt model last loss:  0.23807433247566223\n","\n","dl_loss 0.8939393939393939\n","knn_loss 0.8484848484848485\n","retrieval_loss 0.7878787878787878\n","retrieval_N_adapt_loss 0.8787878787878788\n","CBR normal CDH loss 0.803030303030303\n","retrieval_N_EAC_adapt_loss loss 0.8787878787878788\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.8939393939393939,\n"," 0.8484848484848485,\n"," 0.7878787878787878,\n"," 0.8787878787878788,\n"," 0.803030303030303,\n"," 0.8787878787878788)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"xGdK03splWHO"},"source":["#Experiment after separation of training and testing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWTz0hiJltsV","executionInfo":{"elapsed":26155,"status":"ok","timestamp":1609207690833,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"c6931c81-20ce-406f-98b3-2ebc62db0798"},"source":["#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from C2C neighbors, requires pair_selection \"5\"\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#4, rules from random pairs, with designated number of random pairs\r\n","#5, rules from C2C pairs\r\n","pair_selection = \"145\"\r\n","random_pairs_count = 100\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","(dl_model, knn, adapt_models, cdh_knns, knn_by_class, X_train_by_class, y_train_by_class) = train_models(X_train,y_train,EAC_adapt,pair_selection, pair_knowledge, 0)\r\n","test_models(X_test,y_test, EAC_adapt, dl_model, knn, adapt_models, cdh_knns, knn_by_class, X_train_by_class, y_train_by_class)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.7257,  loss:0.5603,  val_accuracy:0.8333,  val_loss:0.4214,  \n","....................dl last loss:  0.42026832699775696\n","\n","Epoch: 0, accuracy:0.5939,  loss:0.7038,  val_accuracy:0.7857,  val_loss:0.5692,  \n","..........................................adapt model last loss:  0.1687643676996231\n","\n","Epoch: 0, accuracy:0.5739,  loss:0.6896,  val_accuracy:0.6389,  val_loss:0.5917,  \n",".................................adapt model last loss:  0.12306912988424301\n","debugging\n","587\n","561\n","WARNING:tensorflow:5 out of the last 397 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4dd5ddaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","\n","dl_loss 0.8787878787878788\n","knn_loss 0.8333333333333334\n","retrieval_loss 0.8484848484848485\n","retrieval_N_adapt_loss 0.7727272727272727\n","CBR normal CDH loss 0.7121212121212122\n","retrieval_N_EAC_adapt_loss loss 0.8636363636363636\n","C2C_EAC_NN_CDH_loss  0.8636363636363636\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(0.8787878787878788,\n"," 0.8333333333333334,\n"," 0.8484848484848485,\n"," 0.7727272727272727,\n"," 0.7121212121212122,\n"," 0.8636363636363636,\n"," 0.8636363636363636,\n"," 0.8820276497695853,\n"," 0.8373271889400922,\n"," 0.8534562211981567,\n"," 0.780184331797235,\n"," 0.7119815668202765,\n"," 0.8658986175115208,\n"," 0.8677419354838709)"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"NZfmraKvhMoQ"},"source":["# KFOLD CODE"]},{"cell_type":"code","metadata":{"id":"-9nH2sc5X46f","executionInfo":{"status":"ok","timestamp":1611095283923,"user_tz":300,"elapsed":445,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["from sklearn.model_selection import KFold\r\n","def kFoldExperiment(X,y, num_of_runs):\r\n","  # knn_loss, retrieval_loss, without_source_loss, with_source_loss\r\n","  knn_loss_es = [] \r\n","  retrieval_loss_es = []\r\n","  without_source_loss_es = []\r\n","  with_source_loss_es = []\r\n","\r\n","  bal_knn_loss_es = [] \r\n","  bal_retrieval_loss_es = []\r\n","  bal_without_source_loss_es = []\r\n","  bal_with_source_loss_es = []\r\n","\r\n","  for i in range(num_of_runs):\r\n","    kf = KFold(n_splits=10, shuffle=True)\r\n","    for train_index, test_index in kf.split(X):\r\n","        (X_train,X_test,y_train,y_test) = (None,None,None,None)\r\n","        (knn, adapt_model_without_source, adapt_model_with_source) = (None,None,None)\r\n","        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n","        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n","        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n","\r\n","        (knn, adapt_model_without_source, adapt_model_with_source) = train_models(X_train,y_train,EAC_adapt,pair_selection, pair_knowledge, 0)\r\n","\r\n","        print(\"weights\")\r\n","        print(adapt_model_without_source.get_weights())\r\n","        \r\n","        (knn_loss, retrieval_loss, without_source_loss, with_source_loss,bal_knn_loss, bal_retrieval_loss, bal_without_source_loss, \r\n","         bal_with_source_loss) = test_models(X_train,y_train,X_test,y_test, EAC_adapt, knn, adapt_model_without_source, adapt_model_with_source)\r\n","        \r\n","        # TODO\r\n","        knn_loss_es.append(knn_loss)\r\n","        retrieval_loss_es.append(retrieval_loss)\r\n","        without_source_loss_es.append(without_source_loss)\r\n","        with_source_loss_es.append(with_source_loss)\r\n","\r\n","        bal_knn_loss_es.append(bal_knn_loss)\r\n","        bal_retrieval_loss_es.append(bal_retrieval_loss)\r\n","        bal_without_source_loss_es.append(bal_without_source_loss)\r\n","        bal_with_source_loss_es.append(bal_with_source_loss)\r\n","  print(\"\")\r\n","  reportResults_kFold(\"average\", knn_loss_es, retrieval_loss_es, without_source_loss_es, with_source_loss_es)\r\n","  print(\"\")\r\n","  reportResults_kFold(\"balanced\", bal_knn_loss_es, bal_retrieval_loss_es, bal_without_source_loss_es, bal_with_source_loss_es)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gpL1C_GtE_U","executionInfo":{"status":"ok","timestamp":1611095286788,"user_tz":300,"elapsed":724,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}}},"source":["# demonstrate data standardization with sklearn\n","from sklearn.preprocessing import StandardScaler\n","def scaleX(X, numericCols):\n","  # create scaler\n","  Xscaler = StandardScaler()\n","  scaled_features = X.copy()\n","  features = scaled_features[numericCols]\n","  # fit scaler on data\n","  Xscaler.fit(features.values)\n","  # apply transform\n","  features = Xscaler.transform(features.values)\n","  scaled_features[numericCols] = features\n","  return scaled_features\n","\n","# X = scaleX(X,numericCols)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1c9FOOeIrw0d"},"source":["# Dataset loading: credit"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-hSehbqDY8o","executionInfo":{"status":"ok","timestamp":1611095290363,"user_tz":300,"elapsed":1320,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"0832058e-331e-4575-8fb2-238621ffa993"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/crx.data'\n","nominalCols = [0,3,4,5,6,8,9,11,12] \n","numericCols = [1,2,7,10,13,14]\n","def GetDataMatrix():\n","    \n","    # Data frame with make and model\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,));\n","\n","    y = pd.read_csv(filename,header=None, usecols=(15,));\n","\n","    #remove rows with ? values\n","    rows_with_na = (X.values == '?').any(1)\n","    X = X[~rows_with_na]\n","    y = y[~rows_with_na]\n","\n","    X, y = shuffle(X, y)\n","    print(X.head(0))\n","    # Turns categorical data into binary values across many columns\n","    #special one hot encoding with multiple values\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\n","    # X = pd.concat([X, market_category_dummies], axis=1)\n","    # X = X.drop(columns=['Market Category'])\n","    #normal one hot encoding\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\n","    y = pd.get_dummies(y, dummy_na=False)\n","    # Fill the null values with zeros\n","    # X.fillna(0, inplace=True);\n","    #there shouldn't be null, since it's already cleaned.\n","    print(X.isnull().sum())\n","\n","    X = scaleX(X,numericCols)\n","\n","    return (X, y)\n","\n","##########\n","\n","(X, y) = GetDataMatrix() #Gets the X,Y\n","num_classes = len(y.columns)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","Index: []\n","1       0\n","2       0\n","7       0\n","10      0\n","13      0\n","14      0\n","0_a     0\n","0_b     0\n","3_l     0\n","3_u     0\n","3_y     0\n","4_g     0\n","4_gg    0\n","4_p     0\n","5_aa    0\n","5_c     0\n","5_cc    0\n","5_d     0\n","5_e     0\n","5_ff    0\n","5_i     0\n","5_j     0\n","5_k     0\n","5_m     0\n","5_q     0\n","5_r     0\n","5_w     0\n","5_x     0\n","6_bb    0\n","6_dd    0\n","6_ff    0\n","6_h     0\n","6_j     0\n","6_n     0\n","6_o     0\n","6_v     0\n","6_z     0\n","8_f     0\n","8_t     0\n","9_f     0\n","9_t     0\n","11_f    0\n","11_t    0\n","12_g    0\n","12_p    0\n","12_s    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"zh9pyKQQaFCF","executionInfo":{"elapsed":456,"status":"ok","timestamp":1611010000522,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"8aa3d63e-a4cd-4e71-e838-2635a507d450"},"source":["X.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>7</th>\n","      <th>10</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>0_a</th>\n","      <th>0_b</th>\n","      <th>3_l</th>\n","      <th>3_u</th>\n","      <th>3_y</th>\n","      <th>4_g</th>\n","      <th>4_gg</th>\n","      <th>4_p</th>\n","      <th>5_aa</th>\n","      <th>5_c</th>\n","      <th>5_cc</th>\n","      <th>5_d</th>\n","      <th>5_e</th>\n","      <th>5_ff</th>\n","      <th>5_i</th>\n","      <th>5_j</th>\n","      <th>5_k</th>\n","      <th>5_m</th>\n","      <th>5_q</th>\n","      <th>5_r</th>\n","      <th>5_w</th>\n","      <th>5_x</th>\n","      <th>6_bb</th>\n","      <th>6_dd</th>\n","      <th>6_ff</th>\n","      <th>6_h</th>\n","      <th>6_j</th>\n","      <th>6_n</th>\n","      <th>6_o</th>\n","      <th>6_v</th>\n","      <th>6_z</th>\n","      <th>8_f</th>\n","      <th>8_t</th>\n","      <th>9_f</th>\n","      <th>9_t</th>\n","      <th>11_f</th>\n","      <th>11_t</th>\n","      <th>12_g</th>\n","      <th>12_p</th>\n","      <th>12_s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>378</th>\n","      <td>0.246524</td>\n","      <td>-0.695675</td>\n","      <td>-0.629144</td>\n","      <td>-0.504019</td>\n","      <td>1.543934</td>\n","      <td>0.664140</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>582</th>\n","      <td>1.436799</td>\n","      <td>-0.115371</td>\n","      <td>-0.629144</td>\n","      <td>-0.504019</td>\n","      <td>0.265450</td>\n","      <td>-0.193125</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>339</th>\n","      <td>-0.296200</td>\n","      <td>-0.364215</td>\n","      <td>-0.443604</td>\n","      <td>-0.504019</td>\n","      <td>0.711433</td>\n","      <td>-0.180361</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>-1.000390</td>\n","      <td>-0.886787</td>\n","      <td>-0.072523</td>\n","      <td>-0.101174</td>\n","      <td>-0.596784</td>\n","      <td>-0.193125</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>-0.845688</td>\n","      <td>0.233011</td>\n","      <td>0.075910</td>\n","      <td>0.100249</td>\n","      <td>-0.596784</td>\n","      <td>-0.018243</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            1         2         7        10  ...  11_t  12_g  12_p  12_s\n","378  0.246524 -0.695675 -0.629144 -0.504019  ...     1     1     0     0\n","582  1.436799 -0.115371 -0.629144 -0.504019  ...     1     1     0     0\n","339 -0.296200 -0.364215 -0.443604 -0.504019  ...     1     1     0     0\n","228 -1.000390 -0.886787 -0.072523 -0.101174  ...     1     1     0     0\n","597 -0.845688  0.233011  0.075910  0.100249  ...     0     1     0     0\n","\n","[5 rows x 46 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FruOaiXoG5Bu","executionInfo":{"elapsed":276,"status":"ok","timestamp":1609272647753,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"c0af8f33-8ad5-4196-ab03-7ef854fe6d4a"},"source":["X.isna().sum()\n","nullseries =  X.isna().sum()\n","print(nullseries[nullseries > 0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Series([], dtype: int64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhszClmyO2ea","executionInfo":{"elapsed":240,"status":"ok","timestamp":1611010002629,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"5d260021-9868-409e-b099-86d0150e3f06"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(653, 46)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQZgm4XiO3i5","executionInfo":{"elapsed":3503,"status":"ok","timestamp":1609248155825,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"e6fee6a0-111d-4fd3-9c30-abb908f60c25"},"source":["y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(653, 2)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWwQ9-HePJ-T","executionInfo":{"elapsed":3495,"status":"ok","timestamp":1609248155826,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"8d7268b2-83d4-48ac-80aa-efea36e8d338"},"source":["y.shape[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["653"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"-F5RIgNo1ctQ","executionInfo":{"elapsed":304,"status":"ok","timestamp":1610038371828,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"533d1bac-382f-4649-8f62-0ed46db6ab8d"},"source":["X[1:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>7</th>\n","      <th>10</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>0_a</th>\n","      <th>0_b</th>\n","      <th>3_l</th>\n","      <th>3_u</th>\n","      <th>3_y</th>\n","      <th>4_g</th>\n","      <th>4_gg</th>\n","      <th>4_p</th>\n","      <th>5_aa</th>\n","      <th>5_c</th>\n","      <th>5_cc</th>\n","      <th>5_d</th>\n","      <th>5_e</th>\n","      <th>5_ff</th>\n","      <th>5_i</th>\n","      <th>5_j</th>\n","      <th>5_k</th>\n","      <th>5_m</th>\n","      <th>5_q</th>\n","      <th>5_r</th>\n","      <th>5_w</th>\n","      <th>5_x</th>\n","      <th>6_bb</th>\n","      <th>6_dd</th>\n","      <th>6_ff</th>\n","      <th>6_h</th>\n","      <th>6_j</th>\n","      <th>6_n</th>\n","      <th>6_o</th>\n","      <th>6_v</th>\n","      <th>6_z</th>\n","      <th>8_f</th>\n","      <th>8_t</th>\n","      <th>9_f</th>\n","      <th>9_t</th>\n","      <th>11_f</th>\n","      <th>11_t</th>\n","      <th>12_g</th>\n","      <th>12_p</th>\n","      <th>12_s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>421</th>\n","      <td>20.42</td>\n","      <td>1.085</td>\n","      <td>1.500</td>\n","      <td>0</td>\n","      <td>00108</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>20.75</td>\n","      <td>10.335</td>\n","      <td>0.335</td>\n","      <td>1</td>\n","      <td>00080</td>\n","      <td>50</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>347</th>\n","      <td>26.75</td>\n","      <td>4.500</td>\n","      <td>2.500</td>\n","      <td>0</td>\n","      <td>00200</td>\n","      <td>1210</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>37.17</td>\n","      <td>4.000</td>\n","      <td>5.000</td>\n","      <td>0</td>\n","      <td>00280</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>29.83</td>\n","      <td>2.040</td>\n","      <td>0.040</td>\n","      <td>0</td>\n","      <td>00128</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>368</th>\n","      <td>23.58</td>\n","      <td>11.500</td>\n","      <td>3.000</td>\n","      <td>0</td>\n","      <td>00020</td>\n","      <td>16</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","      <td>36.58</td>\n","      <td>0.290</td>\n","      <td>0.000</td>\n","      <td>10</td>\n","      <td>00200</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>19.75</td>\n","      <td>0.750</td>\n","      <td>0.795</td>\n","      <td>5</td>\n","      <td>00140</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>401</th>\n","      <td>28.92</td>\n","      <td>0.375</td>\n","      <td>0.290</td>\n","      <td>0</td>\n","      <td>00220</td>\n","      <td>140</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         1       2      7  10     13    14  ...  9_t  11_f  11_t  12_g  12_p  12_s\n","421  20.42   1.085  1.500   0  00108     7  ...    0     1     0     1     0     0\n","119  20.75  10.335  0.335   1  00080    50  ...    1     0     1     1     0     0\n","347  26.75   4.500  2.500   0  00200  1210  ...    0     1     0     1     0     0\n","85   37.17   4.000  5.000   0  00280     0  ...    0     0     1     0     0     1\n","396  29.83   2.040  0.040   0  00128     1  ...    0     1     0     1     0     0\n","368  23.58  11.500  3.000   0  00020    16  ...    0     0     1     1     0     0\n","463  36.58   0.290  0.000  10  00200    18  ...    1     1     0     1     0     0\n","109  19.75   0.750  0.795   5  00140     5  ...    1     0     1     1     0     0\n","401  28.92   0.375  0.290   0  00220   140  ...    0     1     0     1     0     0\n","\n","[9 rows x 46 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"0xs_0B7a1etQ","executionInfo":{"elapsed":295,"status":"ok","timestamp":1611010005550,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"08da5abf-219f-4f8a-9ab7-46036f6a2cd4"},"source":["y[1:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>15_+</th>\n","      <th>15_-</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>582</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>339</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>267</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>480</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>667</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>544</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     15_+  15_-\n","582     1     0\n","339     0     1\n","228     1     0\n","597     1     0\n","267     0     1\n","480     0     1\n","14      1     0\n","667     0     1\n","544     0     1"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"MRoJjFuawgIU"},"source":["maybe we can preprocess numerical values: normalization and standardization\n","\n","Based on https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/\n","\n","According to: https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n","They used StandardScaler.\n","\n","IMPORTANT NOTE: Scaling is done on whole dataset instead of on train only. This might be a data leakage issue. However I intentionally do it for now because there is several outlier. If the outliers unluckily all fall in train or testing set, it is going to cause a problem, so I scale them together. \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"zXi9J_8KLu4l","executionInfo":{"elapsed":312,"status":"ok","timestamp":1610038378247,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"235f2566-406f-4877-f226-26c4932378cd"},"source":["X.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>7</th>\n","      <th>10</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>0_a</th>\n","      <th>0_b</th>\n","      <th>3_l</th>\n","      <th>3_u</th>\n","      <th>3_y</th>\n","      <th>4_g</th>\n","      <th>4_gg</th>\n","      <th>4_p</th>\n","      <th>5_aa</th>\n","      <th>5_c</th>\n","      <th>5_cc</th>\n","      <th>5_d</th>\n","      <th>5_e</th>\n","      <th>5_ff</th>\n","      <th>5_i</th>\n","      <th>5_j</th>\n","      <th>5_k</th>\n","      <th>5_m</th>\n","      <th>5_q</th>\n","      <th>5_r</th>\n","      <th>5_w</th>\n","      <th>5_x</th>\n","      <th>6_bb</th>\n","      <th>6_dd</th>\n","      <th>6_ff</th>\n","      <th>6_h</th>\n","      <th>6_j</th>\n","      <th>6_n</th>\n","      <th>6_o</th>\n","      <th>6_v</th>\n","      <th>6_z</th>\n","      <th>8_f</th>\n","      <th>8_t</th>\n","      <th>9_f</th>\n","      <th>9_t</th>\n","      <th>11_f</th>\n","      <th>11_t</th>\n","      <th>12_g</th>\n","      <th>12_p</th>\n","      <th>12_s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>525</th>\n","      <td>45.17</td>\n","      <td>1.500</td>\n","      <td>2.500</td>\n","      <td>0</td>\n","      <td>00140</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>421</th>\n","      <td>20.42</td>\n","      <td>1.085</td>\n","      <td>1.500</td>\n","      <td>0</td>\n","      <td>00108</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>20.75</td>\n","      <td>10.335</td>\n","      <td>0.335</td>\n","      <td>1</td>\n","      <td>00080</td>\n","      <td>50</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>347</th>\n","      <td>26.75</td>\n","      <td>4.500</td>\n","      <td>2.500</td>\n","      <td>0</td>\n","      <td>00200</td>\n","      <td>1210</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>37.17</td>\n","      <td>4.000</td>\n","      <td>5.000</td>\n","      <td>0</td>\n","      <td>00280</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>29.83</td>\n","      <td>2.040</td>\n","      <td>0.040</td>\n","      <td>0</td>\n","      <td>00128</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>368</th>\n","      <td>23.58</td>\n","      <td>11.500</td>\n","      <td>3.000</td>\n","      <td>0</td>\n","      <td>00020</td>\n","      <td>16</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","      <td>36.58</td>\n","      <td>0.290</td>\n","      <td>0.000</td>\n","      <td>10</td>\n","      <td>00200</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>19.75</td>\n","      <td>0.750</td>\n","      <td>0.795</td>\n","      <td>5</td>\n","      <td>00140</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>401</th>\n","      <td>28.92</td>\n","      <td>0.375</td>\n","      <td>0.290</td>\n","      <td>0</td>\n","      <td>00220</td>\n","      <td>140</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         1       2      7  10     13    14  ...  9_t  11_f  11_t  12_g  12_p  12_s\n","525  45.17   1.500  2.500   0  00140     0  ...    0     0     1     1     0     0\n","421  20.42   1.085  1.500   0  00108     7  ...    0     1     0     1     0     0\n","119  20.75  10.335  0.335   1  00080    50  ...    1     0     1     1     0     0\n","347  26.75   4.500  2.500   0  00200  1210  ...    0     1     0     1     0     0\n","85   37.17   4.000  5.000   0  00280     0  ...    0     0     1     0     0     1\n","396  29.83   2.040  0.040   0  00128     1  ...    0     1     0     1     0     0\n","368  23.58  11.500  3.000   0  00020    16  ...    0     0     1     1     0     0\n","463  36.58   0.290  0.000  10  00200    18  ...    1     1     0     1     0     0\n","109  19.75   0.750  0.795   5  00140     5  ...    1     0     1     1     0     0\n","401  28.92   0.375  0.290   0  00220   140  ...    0     1     0     1     0     0\n","\n","[10 rows x 46 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"8ZfzgFKkTqVs","executionInfo":{"elapsed":3904,"status":"ok","timestamp":1609248156281,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"c2720ad6-cc2c-4ff4-923d-7f76a7a712ab"},"source":["y.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>15_+</th>\n","      <th>15_-</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>277</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>451</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     15_+  15_-\n","277     0     1\n","75      0     1\n","137     1     0\n","100     0     1\n","451     0     1"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"dxHHJVm3WB3H"},"source":["Split to train and test. random_state involved, so it might produce different results if using default value.\n","\n","Not using cross validation here yet for simplicity. This is a todo for the future\n"]},{"cell_type":"code","metadata":{"id":"6xjCz6woWBdI"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state= None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rODc9zUEX24v"},"source":["#Trying 10 fold: Credit dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpEpUn9oDaoD","executionInfo":{"elapsed":254,"status":"ok","timestamp":1611010582427,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"4362dc3d-1475-472e-b6ae-6c56a7a4ec4d"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(653, 46)"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"w7vwWk9rDb-p","executionInfo":{"elapsed":291,"status":"error","timestamp":1609272663669,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"0252b3a4-0beb-44f2-ac18-9262b889c1b1"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-d2ba684acd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uEQC1CC9-Sm","executionInfo":{"status":"ok","timestamp":1611095661366,"user_tz":300,"elapsed":366924,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"ace2a9e8-d231-4f25-9f50-510402042925"},"source":["#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from C2C neighbors, requires pair_selection \"5\"\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#4, rules from random pairs, with designated number of random pairs\r\n","#5, rules from C2C pairs\r\n","pair_selection = \"145\"\r\n","random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","kFoldExperiment(X,y, 1)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.8127,  loss:0.4070,  val_accuracy:0.8470,  val_loss:0.3434,  \n",".................................................adapt model (without source) last loss:  0.011197518557310104\n","\n","Epoch: 0, accuracy:0.8183,  loss:0.4076,  val_accuracy:0.8357,  val_loss:0.3524,  \n",".......................................adapt model (with source) last loss:  0.06514552235603333\n","weights\n","[array([[-0.0323457 , -0.1978806 ,  0.14538842, ...,  0.00135315,\n","         0.0729453 ,  0.13299508],\n","       [-0.09498184,  0.10818917, -0.33748794, ...,  0.13599534,\n","         0.19592375,  0.08560415],\n","       [ 0.07109113,  0.09826579, -0.00847993, ..., -0.12038051,\n","         0.02418942, -0.08991976],\n","       ...,\n","       [ 0.05149938, -0.21317858, -0.09383097, ...,  0.17904241,\n","         0.12216742, -0.24503495],\n","       [ 0.07068133, -0.0587214 , -0.1838577 , ..., -0.17582016,\n","         0.36626557,  0.18430108],\n","       [ 0.25436744,  0.37027535,  0.26542777, ..., -0.393093  ,\n","        -0.34294367,  0.46151617]], dtype=float32), array([-0.00807626,  0.01861468,  0.00471704,  0.01923724,  0.02087837,\n","        0.01359664, -0.02616691, -0.02559715,  0.0230574 ,  0.02858858,\n","        0.02898621,  0.03852574, -0.04140528,  0.0039213 , -0.0397983 ,\n","       -0.021171  , -0.02503374,  0.03040705, -0.01481167,  0.01340158,\n","        0.04316183, -0.06282668, -0.06448475, -0.0010179 , -0.02636607,\n","        0.02905536, -0.03870503, -0.04898218, -0.05833581,  0.01525459,\n","        0.00319784,  0.00047731, -0.06100776,  0.0090075 ,  0.01363379,\n","        0.01342751, -0.00962055, -0.01709623,  0.02817791, -0.02831295,\n","        0.0237995 ,  0.02321074, -0.00302064, -0.00013936, -0.00119974,\n","       -0.0031029 ,  0.0304442 ,  0.03767965, -0.02808845, -0.01181062,\n","       -0.05820338, -0.02836684, -0.00028351,  0.01733023, -0.03184231,\n","       -0.00705029, -0.02802731, -0.0047311 , -0.00056673, -0.04590333,\n","        0.01776553, -0.042298  , -0.00407132, -0.00415477, -0.01459924,\n","        0.02914235, -0.00575531,  0.01734145,  0.00550974, -0.02623657,\n","        0.00271695, -0.066284  , -0.05231219, -0.00820108, -0.00911264,\n","       -0.03299044,  0.00560809, -0.01731129,  0.01024582, -0.0220537 ,\n","        0.01372453, -0.00095963,  0.04019994,  0.00410209, -0.02730159,\n","        0.00598915, -0.00209191, -0.00064722,  0.01403632,  0.03223731,\n","       -0.01109857, -0.01304143,  0.01960159,  0.00532194, -0.00326684,\n","       -0.01670528, -0.00636299, -0.01049956, -0.00256944, -0.03050705,\n","       -0.00899153, -0.00812996,  0.03482569,  0.0073575 , -0.09324055,\n","       -0.06232261, -0.03691397,  0.00411955, -0.02000537, -0.00085278,\n","       -0.04340016, -0.01604227, -0.03374049,  0.01013235,  0.00664505,\n","       -0.00929439,  0.00792411, -0.0246392 ,  0.02788297, -0.00365124,\n","        0.0088993 ,  0.00187715,  0.01483841, -0.00834846,  0.0154755 ,\n","       -0.02702047,  0.0022089 ,  0.04209413], dtype=float32), array([[-0.21357556, -0.4037243 , -0.46879697, ..., -0.35887194,\n","        -0.4693292 ,  0.11744875],\n","       [-0.16330814, -0.0291208 , -0.3033996 , ..., -0.36275965,\n","        -0.05083254, -0.17744549],\n","       [-0.15154849,  0.09854905, -0.17921926, ...,  0.01498637,\n","         0.09368563,  0.48800406],\n","       ...,\n","       [-0.17611799,  0.0233564 , -0.09291933, ...,  0.12765269,\n","        -0.25739256, -0.00497751],\n","       [ 0.13959369,  0.24015202,  0.11466446, ..., -0.01974402,\n","        -0.22241041,  0.01565449],\n","       [ 0.01389423,  0.22517392,  0.1857514 , ..., -0.11684532,\n","         0.21127532, -0.16088654]], dtype=float32), array([ 0.00361444, -0.00181901,  0.0459871 , -0.04286544,  0.01694013,\n","        0.0121495 ,  0.01637303,  0.07415372,  0.02101931,  0.03067381,\n","       -0.0169294 , -0.02931497, -0.03268288,  0.05931192, -0.02848207,\n","       -0.00419839,  0.05353256,  0.05030742, -0.00630745,  0.00526092,\n","        0.01055806,  0.0477518 , -0.11071577, -0.00064074, -0.01774302,\n","       -0.02278129,  0.02158637,  0.00937257,  0.00739227,  0.00324317,\n","       -0.01611383,  0.04037494, -0.0279724 ,  0.03886387, -0.00279426,\n","        0.01326921, -0.01440048,  0.02058178, -0.04894497,  0.04093699,\n","        0.02771222, -0.0156003 ,  0.03652075, -0.01133041, -0.08606198,\n","        0.00180557,  0.03927292, -0.01020066, -0.03150117,  0.04303904,\n","        0.04405563,  0.03267848,  0.0172916 ,  0.00124875,  0.02956428,\n","        0.07333092,  0.05301852,  0.01449006, -0.0935408 ,  0.07394493,\n","        0.03642993, -0.00795563,  0.04483551,  0.06767795], dtype=float32), array([[-0.3135177 ,  0.3973573 ],\n","       [-0.18609814,  0.21673517],\n","       [-0.11635213,  0.3956211 ],\n","       [ 0.6079065 , -0.41147563],\n","       [-0.8241658 ,  0.88340354],\n","       [-0.01420734, -0.3201667 ],\n","       [ 0.5189844 , -0.59388924],\n","       [-0.5214492 ,  0.5582607 ],\n","       [-0.37639558,  0.36552262],\n","       [-0.22437659,  0.13136598],\n","       [ 0.10953266, -0.4950928 ],\n","       [ 0.5740502 , -0.24198069],\n","       [ 0.01714422,  0.1621981 ],\n","       [-0.647622  ,  0.32638815],\n","       [ 0.28858036, -0.06936921],\n","       [ 0.21585935,  0.02307906],\n","       [ 0.760772  , -0.7570535 ],\n","       [-0.80532616,  0.8494948 ],\n","       [-0.27525318,  0.6264834 ],\n","       [-0.46845958,  0.53321207],\n","       [ 0.37020287, -0.25608715],\n","       [ 0.3164542 , -0.2553594 ],\n","       [-0.4925507 ,  0.5594693 ],\n","       [-0.21884395, -0.29792035],\n","       [ 0.8509473 , -0.97870296],\n","       [-0.17188469, -0.00858235],\n","       [-0.3903583 , -0.0719822 ],\n","       [-0.5058071 ,  0.534009  ],\n","       [ 0.70961446, -0.18387228],\n","       [-0.4642526 ,  0.46359706],\n","       [ 0.34773833, -0.347892  ],\n","       [ 0.10747198, -0.21850282],\n","       [ 0.32647827, -0.57467455],\n","       [-0.46770293,  0.5872464 ],\n","       [ 0.26898083, -0.30793107],\n","       [-0.02805139, -0.12720864],\n","       [ 0.05125603,  0.32964307],\n","       [-0.5710943 ,  0.6132782 ],\n","       [-0.31804636,  0.17166226],\n","       [-0.58905816,  0.19666895],\n","       [ 0.17562464, -0.50694096],\n","       [-0.2885452 ,  0.42226443],\n","       [ 0.21197908, -0.7849253 ],\n","       [ 0.36343774, -0.28060183],\n","       [ 0.46497205, -0.7594792 ],\n","       [ 0.34668526,  0.16433921],\n","       [-0.2656319 ,  0.40656057],\n","       [-0.16893566,  0.07327467],\n","       [ 0.23580343, -0.10600355],\n","       [ 0.23242147, -0.27081063],\n","       [-0.70037127,  0.6645799 ],\n","       [-0.18599069, -0.33222285],\n","       [ 0.06189417, -0.24277873],\n","       [-0.42887008,  0.44660154],\n","       [-0.52167934,  0.23651737],\n","       [ 0.6732041 , -0.2868716 ],\n","       [-0.38612276,  0.15693346],\n","       [ 0.26195136, -0.21580192],\n","       [-0.4674688 ,  0.68906057],\n","       [ 0.42741495, -0.80163306],\n","       [-0.70605415,  0.71337134],\n","       [-0.1387369 ,  0.19253969],\n","       [-0.5631598 ,  0.11418056],\n","       [ 0.87537044, -1.0439074 ]], dtype=float32), array([ 0.00645397, -0.00645444], dtype=float32)]\n","\n","knn_loss 0.8333333333333334\n","retrieval_loss 0.7727272727272727\n","adapt with source 0.8181818181818182\n","adapt without source 0.8333333333333334\n","\n","Epoch: 0, accuracy:0.8241,  loss:0.3982,  val_accuracy:0.8300,  val_loss:0.3832,  \n","..................................adapt model (without source) last loss:  0.08126077055931091\n","\n","Epoch: 0, accuracy:0.8136,  loss:0.4092,  val_accuracy:0.8555,  val_loss:0.3162,  \n","...................................................adapt model (with source) last loss:  0.04196978360414505\n","weights\n","[array([[-0.08438793,  0.10526988,  0.01076097, ...,  0.14336324,\n","         0.13489191, -0.04513113],\n","       [ 0.22561611, -0.00996761,  0.14547095, ..., -0.00639089,\n","        -0.0470756 ,  0.02752038],\n","       [-0.0848394 ,  0.01810191, -0.09842433, ...,  0.04327355,\n","        -0.12679742, -0.14625277],\n","       ...,\n","       [ 0.08672222, -0.14740211, -0.13562153, ...,  0.00210547,\n","        -0.19229423, -0.15932918],\n","       [ 0.01882007,  0.10107575, -0.13745326, ...,  0.01946073,\n","         0.37433246,  0.16321287],\n","       [-0.11975208,  0.3133942 ,  0.26707357, ...,  0.22000413,\n","         0.25224936,  0.13236788]], dtype=float32), array([-0.0123182 , -0.02463847, -0.00680195, -0.00451672, -0.03992451,\n","        0.03434703,  0.01412706,  0.02525199,  0.00427568, -0.03653618,\n","       -0.07234005, -0.01402428,  0.00730767, -0.0409587 , -0.01142085,\n","        0.0405268 , -0.01652981, -0.00750027, -0.01773696,  0.00683627,\n","       -0.01078621, -0.02081953,  0.0008756 ,  0.01407531,  0.00815867,\n","        0.00113344,  0.0201562 , -0.03273192, -0.01112611, -0.00987242,\n","        0.01818891, -0.01361235, -0.02611395, -0.00658721, -0.01706036,\n","       -0.02121464, -0.03084091, -0.01881834,  0.04663548, -0.01174462,\n","       -0.0528202 , -0.00748671, -0.04360719,  0.04527882, -0.04807803,\n","       -0.02455736,  0.02396875, -0.04048906,  0.00471123, -0.02118401,\n","        0.03296379, -0.02527428,  0.03754568, -0.01206176,  0.00666696,\n","       -0.00657408, -0.0048985 , -0.03100822, -0.00957588,  0.01867838,\n","        0.04764877, -0.01030452, -0.04610648,  0.00085608, -0.02284169,\n","       -0.0032513 , -0.00604188, -0.0398315 , -0.01451583, -0.00212867,\n","       -0.01263003,  0.02515646,  0.0128768 ,  0.03151871,  0.00824795,\n","       -0.05445662, -0.0308989 , -0.00171807,  0.02420024, -0.00280171,\n","        0.01561402, -0.0220054 , -0.03056203, -0.01038596, -0.03048996,\n","        0.00559449,  0.00413475, -0.04846318,  0.01771868, -0.01360272,\n","       -0.00759897, -0.02462881, -0.00309646,  0.04161617, -0.01382079,\n","       -0.04411538, -0.03202054,  0.01138984, -0.01647777,  0.02349892,\n","       -0.00440403, -0.01136774, -0.01204365,  0.01392495,  0.01679758,\n","        0.02766867, -0.01457755, -0.0207532 ,  0.01523295,  0.00273526,\n","        0.0134748 , -0.02003024, -0.01152124,  0.01065682, -0.00526403,\n","       -0.02582265,  0.02069153,  0.020297  , -0.0234798 , -0.01726152,\n","        0.01621939,  0.00782008,  0.00258668,  0.02730398,  0.00371213,\n","       -0.02039571, -0.01994527,  0.0272549 ], dtype=float32), array([[-0.03021402,  0.16199858,  0.16372095, ...,  0.19456135,\n","         0.20571457,  0.1610726 ],\n","       [-0.30632657, -0.49225432, -0.01722714, ..., -0.05059558,\n","         0.35976732, -0.27806005],\n","       [-0.10952414,  0.15484627, -0.19234148, ..., -0.05364187,\n","        -0.0589046 ,  0.20456474],\n","       ...,\n","       [-0.04499783,  0.07328089,  0.06721941, ...,  0.25790247,\n","        -0.03853739,  0.1496868 ],\n","       [ 0.12213109, -0.24807547,  0.06582953, ...,  0.03301757,\n","        -0.05208605, -0.10337167],\n","       [ 0.22965631,  0.12567323,  0.11585136, ...,  0.0457884 ,\n","         0.06946699,  0.16397455]], dtype=float32), array([ 2.89303227e-03,  6.54072538e-02,  3.05466205e-02,  4.09323014e-02,\n","        4.65813465e-02,  9.06141661e-03,  4.27649282e-02, -5.14549017e-02,\n","        3.22190933e-02,  2.44432781e-02, -4.76190895e-02, -2.15477329e-02,\n","       -1.72988535e-03, -9.79517121e-03,  7.90895356e-05,  2.67972518e-02,\n","        3.24170478e-02,  2.13203635e-02, -2.98822578e-02,  2.83703748e-02,\n","        2.16917917e-02,  3.20454128e-02,  2.87454445e-02,  4.18116972e-02,\n","       -1.45084811e-02, -1.65565580e-03,  2.84961406e-02, -1.78286731e-02,\n","        2.36621108e-02,  2.72479709e-02,  3.57327685e-02, -1.24177467e-02,\n","       -4.82306965e-02,  1.07713528e-02,  3.80231850e-02,  5.90920411e-02,\n","        4.37311537e-04,  1.39433192e-02,  2.60051601e-02,  4.78460267e-02,\n","        1.50962947e-02, -1.26231723e-02, -1.46543365e-02,  1.56899784e-02,\n","        3.38207074e-02,  2.19637770e-02, -9.91999730e-03,  8.55750870e-03,\n","        2.93936376e-02,  5.13093621e-02, -2.97830068e-02,  1.91180073e-02,\n","        5.23246303e-02,  3.04956026e-02, -1.26187000e-02, -3.26233823e-03,\n","        9.55186877e-03, -1.94382835e-02, -1.69086158e-02,  3.84976491e-02,\n","        2.57951953e-03,  8.57310742e-03, -3.06460378e-03,  1.89095885e-02],\n","      dtype=float32), array([[-0.10014959,  0.13756207],\n","       [-0.80104274,  0.43588555],\n","       [-0.36279902,  0.49209628],\n","       [-0.1021062 ,  0.40971985],\n","       [-0.48118013,  0.70182854],\n","       [-0.17883022,  0.10489967],\n","       [-0.35571542,  0.56596684],\n","       [ 0.6182982 , -0.5378221 ],\n","       [ 0.60111016, -0.76340073],\n","       [ 0.7494244 , -0.62420094],\n","       [ 0.0997939 , -0.21549681],\n","       [ 0.16414058, -0.07942807],\n","       [ 0.41916272, -0.08483429],\n","       [ 0.25577602, -0.4640952 ],\n","       [-0.5947843 ,  0.25692195],\n","       [ 0.30436376,  0.03968878],\n","       [ 0.47028282, -0.13494661],\n","       [ 0.44888148, -0.41908133],\n","       [-0.51814437,  0.39686328],\n","       [-0.42978245,  0.23133567],\n","       [ 0.7216514 , -0.1718231 ],\n","       [ 0.48015612, -0.56394523],\n","       [ 0.25066298, -0.069456  ],\n","       [ 0.45570058, -0.31897068],\n","       [ 0.5320275 , -0.60311806],\n","       [-0.15400422,  0.19912878],\n","       [ 0.25368226, -0.18216491],\n","       [-0.8619361 ,  0.53102195],\n","       [-0.48459467,  0.4758166 ],\n","       [ 0.36565006, -0.25961468],\n","       [-0.23348264,  0.542554  ],\n","       [ 0.49291247, -0.5479649 ],\n","       [-0.00336541, -0.17752047],\n","       [-0.41156188,  0.4390936 ],\n","       [-0.34888455,  0.00760157],\n","       [ 0.0813557 , -0.56651515],\n","       [ 0.18306541,  0.10288513],\n","       [-0.13704859,  0.3339177 ],\n","       [ 0.20535049, -0.45900163],\n","       [-0.48446685,  0.24868903],\n","       [-0.21369582,  0.01082783],\n","       [ 0.41316974, -0.45509842],\n","       [-0.26878336,  0.38028985],\n","       [ 0.20090997, -0.39078978],\n","       [-0.4801547 ,  0.22457094],\n","       [-0.1655168 ,  0.23017141],\n","       [-0.14992127,  0.66217804],\n","       [ 0.2562734 , -0.02789121],\n","       [ 0.00883995, -0.3724924 ],\n","       [-0.6555167 ,  0.7738879 ],\n","       [ 0.10378806,  0.16540435],\n","       [ 0.47028893, -0.52054054],\n","       [-0.6892034 ,  0.47729897],\n","       [ 0.6613743 , -0.60301316],\n","       [ 0.47847894, -0.5250939 ],\n","       [ 0.23193401, -0.24158925],\n","       [-0.41682684,  0.11512057],\n","       [-0.29300565,  0.21918374],\n","       [ 0.5574444 , -0.48507297],\n","       [-0.09089465,  0.13984373],\n","       [ 0.40148538, -0.38797536],\n","       [ 0.30761307, -0.17167066],\n","       [ 0.56568027, -0.52543724],\n","       [-0.3567846 ,  0.43259126]], dtype=float32), array([ 0.00873954, -0.00873977], dtype=float32)]\n","\n","knn_loss 0.8636363636363636\n","retrieval_loss 0.8333333333333334\n","adapt with source 0.8333333333333334\n","adapt without source 0.8484848484848485\n","\n","Epoch: 0, accuracy:0.8056,  loss:0.4268,  val_accuracy:0.8300,  val_loss:0.3912,  \n","................................adapt model (without source) last loss:  0.01607821136713028\n","\n","Epoch: 0, accuracy:0.8105,  loss:0.4258,  val_accuracy:0.8414,  val_loss:0.3723,  \n","..............................................................adapt model (with source) last loss:  0.05613825097680092\n","weights\n","[array([[ 0.03451141,  0.07271285, -0.04400346, ...,  0.09459466,\n","        -0.14950116,  0.14205354],\n","       [-0.09722956,  0.02059297,  0.03352569, ..., -0.01015478,\n","        -0.00838714,  0.23025553],\n","       [-0.15656431, -0.05017747,  0.01830893, ...,  0.09210144,\n","         0.10548235, -0.21894626],\n","       ...,\n","       [ 0.08377759, -0.23342788,  0.16269602, ..., -0.01520121,\n","        -0.20108993,  0.02949258],\n","       [ 0.09929339,  0.1056959 ,  0.06834496, ...,  0.10809618,\n","        -0.0201139 , -0.1316607 ],\n","       [ 0.10843591, -0.14422025, -0.5148711 , ..., -0.21546431,\n","        -0.25899905,  0.13399649]], dtype=float32), array([ 3.00491191e-02, -3.73588093e-02, -2.43691225e-02, -2.75460514e-03,\n","       -2.62269489e-02, -1.96736283e-03, -2.24042088e-02, -2.07863674e-02,\n","       -1.70802176e-02, -1.01679908e-02, -3.78047787e-02,  2.69007366e-02,\n","       -1.82630718e-02,  4.10612710e-02,  7.05629680e-03, -2.44860165e-02,\n","        2.11624596e-02, -9.12658288e-05, -2.10055616e-02,  1.03790183e-02,\n","       -3.08934804e-02,  3.68892355e-03,  1.75115131e-02,  1.55467093e-02,\n","       -1.82332415e-02, -1.19809201e-02, -1.55515121e-02,  3.26319039e-02,\n","       -3.03132646e-02, -2.76520737e-02,  2.47270241e-02, -7.11930962e-03,\n","        8.98052752e-03,  1.40943732e-02, -1.41296852e-02,  3.75588611e-02,\n","        1.10828774e-02,  3.75492610e-02,  7.87621457e-03, -2.30570845e-02,\n","        3.34041268e-02, -1.57094970e-02,  2.86754332e-02, -1.44367879e-02,\n","        1.64246354e-02, -2.27795802e-02,  3.35313566e-02, -4.10956470e-03,\n","       -3.52469385e-02, -3.70658748e-02,  1.33847268e-02,  2.79302094e-02,\n","       -1.24341547e-02, -1.14780329e-02, -4.64573018e-02, -4.02667299e-02,\n","       -3.30383852e-02, -8.55922792e-03,  2.25384291e-02, -4.48533297e-02,\n","        1.25374617e-02,  1.51970005e-02, -4.44580540e-02, -1.87864751e-02,\n","       -3.73696275e-02,  2.99609937e-02,  8.92250915e-04,  4.50423248e-02,\n","       -2.37070937e-02, -5.07910084e-03,  2.01050602e-02,  3.24099846e-02,\n","        1.53116155e-02,  2.56512817e-02,  3.68517637e-02,  8.89541861e-03,\n","        4.98626754e-03,  8.70059151e-03,  1.44259892e-02, -6.51103968e-04,\n","       -1.55594172e-02, -8.23423546e-03, -1.58873200e-02,  1.46150608e-02,\n","        1.43542187e-02,  2.58699469e-02, -2.94946004e-02,  1.61645301e-02,\n","        3.58139660e-05, -2.15368699e-02, -4.07521613e-02, -9.47770942e-03,\n","       -6.04129955e-02,  2.39512622e-02,  8.85874406e-03, -9.09529720e-03,\n","       -4.28392813e-02, -1.67643055e-02, -4.68294621e-02,  1.56996883e-02,\n","       -2.08899435e-02,  1.93368569e-02,  6.26301542e-02, -2.04874873e-02,\n","       -5.59093431e-02, -1.04445685e-02,  8.03905819e-03,  3.08198133e-03,\n","       -7.38931308e-03,  1.38433021e-03,  4.20106482e-03, -7.24792341e-03,\n","        2.62353383e-02, -1.86032727e-02, -4.34183935e-03,  3.27309640e-03,\n","       -1.73762310e-02, -2.83252038e-02,  5.73496036e-02,  1.90053247e-02,\n","       -9.89437383e-03, -2.68417434e-03,  1.34174936e-02, -1.12663386e-02,\n","        2.63333041e-02, -4.26020147e-03, -1.92943309e-02, -1.63444094e-02],\n","      dtype=float32), array([[ 0.10567962,  0.1689098 , -0.05418257, ...,  0.00326845,\n","        -0.06343153, -0.05631809],\n","       [-0.02626276, -0.10163645,  0.12610072, ..., -0.17047764,\n","        -0.02115906,  0.01834792],\n","       [ 0.26110733, -0.06990123,  0.02822711, ..., -0.09645732,\n","         0.14411278,  0.34036043],\n","       ...,\n","       [ 0.1589863 , -0.29539287,  0.14381738, ..., -0.00831783,\n","        -0.12215689,  0.09173866],\n","       [-0.09267164,  0.02064187, -0.00435368, ...,  0.06115988,\n","        -0.05876275,  0.18392089],\n","       [ 0.02689496,  0.03341082,  0.14948983, ...,  0.1418646 ,\n","         0.00879494,  0.16654766]], dtype=float32), array([ 0.04453431,  0.01513985,  0.05034912,  0.00863248,  0.01430399,\n","        0.01324769, -0.06452089,  0.030794  , -0.02640084, -0.00664231,\n","        0.00587368, -0.03087561,  0.01982434,  0.01236716,  0.03086777,\n","        0.00391494,  0.03839106, -0.02540885, -0.00875309,  0.0046558 ,\n","       -0.00868807, -0.02127307,  0.02108099,  0.00538112,  0.00310727,\n","        0.00216586, -0.03677644, -0.01950147, -0.0098034 ,  0.01387077,\n","        0.04650908,  0.00138214,  0.02577692, -0.01060952,  0.00210141,\n","       -0.03269428, -0.00323451,  0.04245028,  0.01894254,  0.00783343,\n","       -0.00738018,  0.0155245 , -0.0357615 ,  0.01724633,  0.02475245,\n","        0.02610009,  0.00079622,  0.01612009, -0.01487087, -0.01616865,\n","        0.01433591,  0.00586841,  0.00331599,  0.00233672,  0.0409213 ,\n","        0.03355258, -0.01019948,  0.03724265, -0.00016605, -0.01823582,\n","        0.00557826,  0.024439  ,  0.02083096, -0.02247876], dtype=float32), array([[-0.20467617,  0.1778523 ],\n","       [ 0.4949826 , -0.525576  ],\n","       [-0.3843109 , -0.02696853],\n","       [-0.0342684 , -0.3725763 ],\n","       [ 0.08966445, -0.34114942],\n","       [-0.42516568,  0.4309203 ],\n","       [ 0.24188974, -0.04133563],\n","       [-0.1760392 ,  0.24765953],\n","       [-0.00719151, -0.39015558],\n","       [ 0.16913706, -0.3621068 ],\n","       [ 0.06596771,  0.30583182],\n","       [ 0.5676562 , -0.37974057],\n","       [ 0.2749207 , -0.35361984],\n","       [ 0.4405195 , -0.35995424],\n","       [ 0.513581  , -0.3324285 ],\n","       [-0.50131017,  0.6051691 ],\n","       [ 0.48671618, -0.6195777 ],\n","       [-0.47283283,  0.36543125],\n","       [ 0.47339588, -0.47870168],\n","       [-0.84887326,  0.7353559 ],\n","       [ 0.5901789 , -0.6986107 ],\n","       [ 0.5205169 , -0.15093759],\n","       [ 0.10066845, -0.06110815],\n","       [ 0.36830005, -0.13059397],\n","       [ 0.6743553 , -0.38543573],\n","       [ 0.52065027, -0.8347034 ],\n","       [ 0.638933  , -0.27638084],\n","       [-0.6193829 ,  0.57976043],\n","       [ 0.26211518, -0.08090986],\n","       [-0.7571817 ,  0.63070136],\n","       [-0.3455377 ,  0.34303334],\n","       [-0.38468906,  0.39659232],\n","       [-0.2596262 ,  0.05349904],\n","       [-0.23175335,  0.41872364],\n","       [ 0.18892829,  0.29354843],\n","       [ 0.01923642, -0.21226445],\n","       [-0.44694167,  0.86009204],\n","       [-0.33425924,  0.40899512],\n","       [ 0.1652976 , -0.16897148],\n","       [-0.7344581 ,  0.56827277],\n","       [ 0.02289761,  0.38574398],\n","       [ 0.09947474, -0.18681154],\n","       [-0.27718347,  0.47806758],\n","       [-0.06509557, -0.44308275],\n","       [ 0.84290624, -1.0414311 ],\n","       [-0.61763024,  0.23236772],\n","       [-0.06079618, -0.34862322],\n","       [ 0.33235323, -0.16677691],\n","       [-0.29358798,  0.2086793 ],\n","       [ 0.4491498 , -0.38305983],\n","       [-0.21208692,  0.30097464],\n","       [ 0.01403608,  0.36891308],\n","       [-0.35459736,  0.48923868],\n","       [-0.4004239 ,  0.23530635],\n","       [-0.30632314,  0.5502802 ],\n","       [-0.48272622,  0.23187849],\n","       [ 0.32420716,  0.21264394],\n","       [ 0.23958966, -0.19419733],\n","       [-0.01974771,  0.26601437],\n","       [-0.3876212 ,  0.17680764],\n","       [-0.4436834 ,  0.6582498 ],\n","       [-0.3130388 , -0.02925647],\n","       [ 0.03240507,  0.24984108],\n","       [-0.30234826,  0.75064546]], dtype=float32), array([-0.00546715,  0.00546695], dtype=float32)]\n","\n","knn_loss 0.8636363636363636\n","retrieval_loss 0.8484848484848485\n","adapt with source 0.8636363636363636\n","adapt without source 0.9090909090909091\n","\n","Epoch: 0, accuracy:0.8080,  loss:0.4182,  val_accuracy:0.8470,  val_loss:0.3175,  \n","................................adapt model (without source) last loss:  0.030843716114759445\n","\n","Epoch: 0, accuracy:0.8238,  loss:0.3895,  val_accuracy:0.8839,  val_loss:0.2917,  \n","...............................................adapt model (with source) last loss:  0.03629021346569061\n","weights\n","[array([[-0.01405293, -0.07382887,  0.0233496 , ..., -0.02585305,\n","         0.18805346,  0.25768986],\n","       [-0.04081892, -0.24554183, -0.08347548, ..., -0.10416836,\n","        -0.10798208, -0.12373663],\n","       [ 0.10702298,  0.08703502, -0.12309798, ..., -0.05208728,\n","        -0.03564746, -0.05171041],\n","       ...,\n","       [ 0.06832227,  0.13289097, -0.1524736 , ..., -0.03669942,\n","        -0.11050233, -0.10240459],\n","       [ 0.06394953,  0.3373645 ,  0.15802959, ..., -0.03833099,\n","         0.2729829 ,  0.00832908],\n","       [ 0.08080021, -0.30203947,  0.15456837, ...,  0.02107163,\n","         0.10073106,  0.40963572]], dtype=float32), array([ 6.93497527e-03, -5.97666437e-03,  1.15302391e-03, -5.30176470e-03,\n","        1.48860924e-03,  2.64992248e-02,  2.91825272e-02,  1.52474055e-02,\n","        1.67997479e-02,  1.70710515e-02,  1.19337738e-02,  7.43854092e-03,\n","       -1.90160256e-02, -5.82929421e-03, -3.27370333e-04, -4.36919928e-02,\n","        1.45225609e-02,  2.97276285e-02, -4.92852367e-02, -1.55128967e-02,\n","       -4.47855750e-03, -3.08324043e-02, -2.25907788e-02,  3.70506942e-02,\n","       -4.80986498e-02, -5.16090319e-02, -1.00933211e-02, -4.68505435e-02,\n","        2.29775924e-02,  7.69052934e-03, -4.17859927e-02,  3.97403985e-02,\n","        8.84494558e-03, -4.16933745e-03, -9.06525366e-03, -1.85300000e-02,\n","        3.38383317e-02, -3.50951366e-02, -5.75878471e-03, -2.81659570e-02,\n","       -6.36706827e-03, -2.56443974e-02,  1.76623706e-02, -3.47103877e-03,\n","       -3.08350939e-02, -1.48518626e-02, -5.72640486e-02,  3.51292491e-02,\n","       -3.18383500e-02, -1.22487368e-02, -3.73025537e-02,  1.23928848e-03,\n","       -5.20673431e-02, -8.30838829e-03, -4.17331308e-02,  3.52619775e-03,\n","       -4.02193479e-02,  2.19009095e-03,  3.18350606e-02,  8.41171574e-03,\n","       -1.64351910e-02, -2.90648770e-02,  4.04933393e-02, -2.17561722e-02,\n","       -2.52811587e-04,  5.89977344e-03,  4.28634882e-03, -1.64446738e-02,\n","       -1.20384865e-01, -3.12896334e-02, -1.54822404e-02, -1.59937795e-03,\n","       -6.13361713e-04,  2.84675322e-03, -1.23742633e-02,  3.19683142e-02,\n","       -1.19264368e-02,  4.64677066e-02, -6.97242916e-02,  1.86058879e-02,\n","       -2.16088556e-02, -6.22484367e-03, -1.21204918e-02, -1.07341423e-03,\n","       -3.03830579e-02,  8.38254672e-03, -5.03769331e-03, -3.93552110e-02,\n","        1.91888809e-02, -6.91764206e-02, -5.51052913e-02, -1.88228898e-02,\n","       -1.76222008e-02, -8.99651786e-04,  2.18655579e-02, -2.27575451e-02,\n","        3.83973159e-02, -1.15141002e-02, -6.13528350e-03,  8.96546803e-03,\n","        6.09937590e-03, -2.12903433e-02, -1.75562892e-02, -6.91169202e-02,\n","       -3.39625217e-02,  2.82861176e-03, -5.96635835e-03,  2.54885526e-03,\n","       -2.94413827e-02, -4.51952368e-02, -5.32047041e-02,  2.32568607e-02,\n","       -2.19113361e-02,  1.93735361e-02,  3.39000039e-02, -1.99382082e-02,\n","        1.65977590e-02, -6.72156736e-02,  2.05213926e-03,  4.58238386e-02,\n","        1.50897540e-03, -3.44640426e-02, -6.50078207e-02, -1.41877990e-06,\n","       -2.95580644e-02, -1.36374952e-02,  3.37781087e-02,  4.53109294e-02],\n","      dtype=float32), array([[-0.07977843,  0.13897188, -0.34588614, ...,  0.15294962,\n","         0.03406427,  0.13655172],\n","       [ 0.12287191,  0.19856276,  0.07529036, ..., -0.15048108,\n","         0.13818835, -0.10722861],\n","       [ 0.08056643,  0.00686379, -0.17441528, ...,  0.19369659,\n","         0.08012272,  0.12406597],\n","       ...,\n","       [ 0.15969612, -0.021235  ,  0.0922752 , ..., -0.01915825,\n","         0.00187121, -0.08229637],\n","       [ 0.1783564 ,  0.10273961, -0.06162692, ..., -0.11091176,\n","        -0.01367918,  0.18962947],\n","       [-0.11148141, -0.13845046, -0.00829539, ...,  0.12682703,\n","         0.24774116, -0.14750478]], dtype=float32), array([ 0.04399326,  0.01188373, -0.02628212, -0.02714855, -0.0418541 ,\n","        0.04863061,  0.01156958, -0.0336293 , -0.02001587, -0.04572379,\n","       -0.04794619,  0.02214961, -0.04652947, -0.00297122, -0.00495593,\n","        0.01644206,  0.02512917,  0.06377571,  0.06047431,  0.04094563,\n","        0.00674449,  0.03678536,  0.00641831,  0.02130032,  0.01481963,\n","       -0.06357291, -0.04012135,  0.03962879, -0.00323403,  0.01783055,\n","        0.01647528,  0.04235812,  0.00884399,  0.004795  ,  0.03235021,\n","        0.0281457 ,  0.02902481,  0.01585282, -0.00625736,  0.00280279,\n","       -0.00035935,  0.04980025, -0.02054687, -0.02709749, -0.04432166,\n","        0.03311463, -0.02271251, -0.04608572,  0.05443254, -0.02092083,\n","        0.02241368, -0.01924824, -0.00263813,  0.01802785,  0.03734728,\n","        0.02381301, -0.00917426,  0.01798468, -0.03583702,  0.02309954,\n","        0.0483148 ,  0.00063854,  0.02192107,  0.01513302], dtype=float32), array([[-1.6686669e-01,  4.1686460e-01],\n","       [ 3.3339709e-01, -4.3688732e-01],\n","       [-5.3784233e-01,  3.4049389e-01],\n","       [ 3.7709120e-01, -3.2410774e-01],\n","       [ 7.1359390e-01, -8.8881862e-01],\n","       [-5.8911443e-01,  7.2293347e-01],\n","       [ 3.9534706e-01,  1.6424222e-02],\n","       [ 6.7100167e-02, -8.5763343e-02],\n","       [ 2.7226201e-01, -1.2860438e-01],\n","       [ 2.1446675e-01, -4.2629689e-01],\n","       [ 1.6698301e-01, -6.6055092e-03],\n","       [-2.9581913e-01,  3.6107142e-02],\n","       [ 3.4780297e-02, -3.3917111e-01],\n","       [ 8.6801611e-02,  3.9818764e-01],\n","       [ 4.1518882e-01, -5.7906717e-01],\n","       [-3.5105047e-01, -6.1359413e-02],\n","       [-2.5509569e-01,  1.1518223e-01],\n","       [ 5.2865773e-01, -8.6613816e-01],\n","       [-4.5403492e-01,  4.1599989e-02],\n","       [-5.3294617e-01,  6.7280793e-01],\n","       [-6.1639786e-01,  2.9796258e-01],\n","       [-4.0399131e-01, -1.2761982e-01],\n","       [ 4.4878727e-01, -5.8661121e-01],\n","       [-3.0021393e-01,  4.5779005e-01],\n","       [ 9.2295971e-04,  2.8951362e-01],\n","       [ 5.1129228e-01, -4.6962544e-01],\n","       [ 2.5067925e-01, -4.0398237e-01],\n","       [-3.4552407e-01,  4.8468940e-02],\n","       [ 2.5348109e-01, -2.5741309e-01],\n","       [-1.4086927e-01,  5.6341779e-01],\n","       [ 3.3829188e-01, -6.0812742e-02],\n","       [ 2.9911137e-01, -3.3674768e-01],\n","       [ 3.7350553e-01, -3.1879342e-01],\n","       [-9.5262468e-02,  6.0326850e-01],\n","       [ 2.6576778e-01, -1.8153876e-01],\n","       [ 8.1303650e-01, -9.0027475e-01],\n","       [ 6.1794621e-01, -7.9661375e-01],\n","       [-5.0418079e-01,  2.3473099e-01],\n","       [ 2.8081712e-01, -5.6001508e-01],\n","       [-3.2866569e-03,  3.7141404e-01],\n","       [ 3.2912895e-01, -2.3631905e-01],\n","       [ 2.3726003e-01, -4.2564243e-01],\n","       [ 5.1786739e-01, -3.9727890e-01],\n","       [ 2.7720922e-01, -3.9235762e-01],\n","       [ 1.7026688e-01, -6.4599857e-02],\n","       [-2.3794147e-01,  2.1342544e-01],\n","       [-5.0521773e-01,  1.0183606e-01],\n","       [-5.0676531e-01,  5.3355241e-01],\n","       [-7.0380874e-02,  2.7242664e-01],\n","       [ 4.8603511e-01, -3.1729439e-01],\n","       [-4.0032202e-01,  1.7216334e-01],\n","       [ 1.8165754e-01, -2.3827624e-02],\n","       [ 7.4111038e-01, -6.2832451e-01],\n","       [ 4.1833889e-01, -4.7401154e-01],\n","       [ 7.3795773e-02, -4.2407751e-01],\n","       [-4.0619177e-01, -4.5866437e-02],\n","       [ 4.6058440e-01, -9.7251546e-01],\n","       [-9.4020590e-02,  3.0288666e-01],\n","       [ 5.0266510e-01, -3.9869401e-01],\n","       [-5.9930515e-02,  2.2750036e-01],\n","       [-3.4679666e-01,  2.8261724e-01],\n","       [-1.2497268e-02,  2.3500787e-01],\n","       [ 3.0409870e-01, -2.7333272e-01],\n","       [ 4.1013491e-01, -2.2677867e-01]], dtype=float32), array([-0.02631061,  0.02631035], dtype=float32)]\n","\n","knn_loss 0.8\n","retrieval_loss 0.7692307692307693\n","adapt with source 0.7384615384615385\n","adapt without source 0.7692307692307693\n","\n","Epoch: 0, accuracy:0.8298,  loss:0.3818,  val_accuracy:0.8442,  val_loss:0.3518,  \n","..........................................adapt model (without source) last loss:  0.06612427532672882\n","\n","Epoch: 0, accuracy:0.8274,  loss:0.3889,  val_accuracy:0.8669,  val_loss:0.2888,  \n",".................................................adapt model (with source) last loss:  0.022921651601791382\n","weights\n","[array([[ 0.1403983 , -0.27298635, -0.15558192, ...,  0.2130033 ,\n","         0.20344062, -0.0929223 ],\n","       [-0.10127912,  0.15417115,  0.05264356, ..., -0.13719186,\n","        -0.22312729,  0.0777885 ],\n","       [ 0.1250438 , -0.18044265,  0.15057299, ..., -0.00408628,\n","         0.13743523, -0.07271251],\n","       ...,\n","       [-0.32455704,  0.15891731,  0.27005965, ...,  0.13098644,\n","        -0.212105  , -0.16565245],\n","       [-0.0649065 , -0.08980749, -0.15473323, ..., -0.25940675,\n","         0.06884161,  0.08818286],\n","       [ 0.1072142 ,  0.19582152, -0.414182  , ..., -0.3768295 ,\n","        -0.05576361, -0.16441259]], dtype=float32), array([-0.04523021,  0.00325903,  0.02016963, -0.03054322,  0.01618007,\n","       -0.04586227, -0.00822397, -0.01752776, -0.03355468, -0.00161035,\n","       -0.02691586,  0.02320387,  0.02152974, -0.02032105, -0.09330343,\n","       -0.03241279, -0.05603081,  0.01335368, -0.01835812, -0.02279051,\n","        0.01055711, -0.04777412, -0.01702321, -0.04025413, -0.02025136,\n","       -0.01546757, -0.0234795 ,  0.0160575 , -0.00891291, -0.02301523,\n","       -0.00037962, -0.04318072, -0.04273901, -0.02957096, -0.00755342,\n","       -0.02567802, -0.01153264, -0.03605903, -0.03345184, -0.02612831,\n","       -0.05582018, -0.02533436, -0.01010469, -0.02694736, -0.00276992,\n","       -0.05863328,  0.05703456,  0.01175689, -0.05431427,  0.00508555,\n","       -0.01326931, -0.05170197,  0.03445241, -0.00446247, -0.00097062,\n","       -0.0354094 ,  0.02043436, -0.00237076, -0.00888108,  0.01318542,\n","       -0.04535542, -0.02980169, -0.00155023, -0.03845174, -0.01899136,\n","        0.00359307, -0.03314922, -0.03270277, -0.02900369, -0.01138179,\n","       -0.02555447, -0.00707769, -0.01252168,  0.00548805, -0.05038481,\n","       -0.03184149, -0.00463024,  0.00124528,  0.00173622, -0.0002116 ,\n","       -0.02431153, -0.02166927,  0.00065199, -0.0291642 , -0.02041887,\n","       -0.02172078,  0.02435235, -0.00018393, -0.04551543,  0.006108  ,\n","       -0.04136489,  0.04214973, -0.03125977,  0.02646502, -0.02190391,\n","       -0.02603932,  0.03031453,  0.01883971, -0.01890392,  0.01959949,\n","        0.03556203, -0.00040531, -0.0164298 , -0.0158108 , -0.02523486,\n","        0.00268108, -0.03320936,  0.02607484, -0.0398631 , -0.04871986,\n","        0.01269794, -0.05199878,  0.02272825,  0.01289805, -0.0163017 ,\n","       -0.01229773, -0.00447903, -0.01453888,  0.00010076,  0.02658014,\n","       -0.02072073,  0.01651794, -0.014014  , -0.03881183, -0.02349321,\n","       -0.01082919,  0.00770321,  0.03964362], dtype=float32), array([[ 0.18368828,  0.09611415, -0.209764  , ...,  0.15671748,\n","         0.0892837 , -0.05597305],\n","       [ 0.06120294, -0.08980281, -0.09965567, ...,  0.01443228,\n","        -0.22391406,  0.09366023],\n","       [ 0.00698562, -0.17358492,  0.26088458, ..., -0.1491812 ,\n","         0.13585888, -0.14637521],\n","       ...,\n","       [ 0.09372439, -0.18972124,  0.14244631, ...,  0.08530972,\n","        -0.1375699 ,  0.21328595],\n","       [ 0.05611369, -0.01440259,  0.08631802, ...,  0.06457556,\n","         0.25714844,  0.18431173],\n","       [-0.0871589 , -0.13832684, -0.14763537, ..., -0.12174086,\n","         0.31002548, -0.24741146]], dtype=float32), array([ 0.02880952,  0.00314376,  0.02184996,  0.01434256,  0.01958   ,\n","       -0.00795349,  0.00568981,  0.03033118,  0.00042508,  0.01642625,\n","       -0.00894694,  0.02567874,  0.0333037 , -0.01007446,  0.07598633,\n","       -0.01006584,  0.0100478 ,  0.01883143,  0.02065188,  0.00159666,\n","        0.02926736,  0.00140268,  0.05260005, -0.03104375,  0.00037727,\n","       -0.0078259 ,  0.02912636,  0.01278558, -0.00623257, -0.00902157,\n","        0.00202696,  0.01729753,  0.03124618,  0.08845942,  0.01774365,\n","        0.00783547,  0.01639991,  0.02055914,  0.00167212, -0.01270619,\n","        0.00201043, -0.00628264, -0.02823321,  0.03857248,  0.01839763,\n","       -0.00649675, -0.00280018,  0.02407202,  0.00353506,  0.02353761,\n","        0.03549738,  0.03585731,  0.02853069,  0.03703615, -0.00590916,\n","       -0.00454915, -0.02850153,  0.02386501,  0.0341775 ,  0.01674021,\n","        0.03786939,  0.00238646,  0.01655133,  0.00524351], dtype=float32), array([[ 0.32628658,  0.03858874],\n","       [ 0.53672487, -0.7161852 ],\n","       [ 0.37739208, -0.1704238 ],\n","       [ 0.32225674, -0.7542448 ],\n","       [-0.89424956,  0.55173   ],\n","       [-0.4237804 ,  0.312312  ],\n","       [ 0.4155554 , -0.00106245],\n","       [ 0.43838596, -0.29560986],\n","       [ 0.00642854,  0.37307978],\n","       [ 0.3424775 , -0.39308873],\n","       [ 0.54591167, -0.5884185 ],\n","       [ 0.30279368, -0.22932875],\n","       [ 0.2800874 , -0.02316835],\n","       [ 0.48204437, -0.33828527],\n","       [-0.7521044 ,  0.2015094 ],\n","       [-0.7418876 ,  0.43439832],\n","       [-0.32994556,  0.32914546],\n","       [-0.2840407 ,  0.40702164],\n","       [ 0.48182425, -0.5312083 ],\n","       [ 0.8105156 , -0.3070323 ],\n","       [-0.48631364,  0.13871762],\n","       [-0.3953153 ,  0.06409764],\n","       [ 0.33552787, -0.15635188],\n","       [ 0.18178758,  0.19227938],\n","       [ 0.47283235, -0.30570903],\n","       [ 0.06249219, -0.2517587 ],\n","       [-0.36933953,  0.6786621 ],\n","       [-0.9048731 ,  0.5192464 ],\n","       [-0.16768624,  0.16922478],\n","       [-0.19788116,  0.18679643],\n","       [-0.49956122,  0.17767854],\n","       [-0.6102373 ,  0.6954748 ],\n","       [-0.0265676 , -0.43535107],\n","       [ 0.96488446, -1.0190588 ],\n","       [-0.5263294 ,  0.4075725 ],\n","       [-0.44003773,  0.21055739],\n","       [-0.11470854,  0.4634654 ],\n","       [-0.07236814, -0.35009006],\n","       [ 0.62377274, -0.30239466],\n","       [-0.19260395,  0.21418232],\n","       [-0.38277587,  0.43487898],\n","       [-0.60096353,  0.5339133 ],\n","       [-0.446586  , -0.04394187],\n","       [ 0.09861789, -0.6368353 ],\n","       [ 0.3288321 , -0.41853246],\n","       [-0.03883347,  0.25899804],\n","       [-0.3460552 ,  0.04292703],\n","       [ 0.01205924,  0.4223655 ],\n","       [ 0.42249668, -0.47990212],\n","       [ 0.45465055, -0.49704686],\n","       [-0.18226063, -0.31722113],\n","       [ 0.54577005,  0.02097523],\n","       [-0.63928825,  0.7671005 ],\n","       [-0.5869757 ,  0.3929896 ],\n","       [-0.36025867,  0.67729235],\n","       [-0.42834106,  0.37738463],\n","       [-0.57110995,  0.09346598],\n","       [-0.30871683,  0.18865116],\n","       [-0.06162185,  0.46385857],\n","       [ 0.00424342, -0.29883537],\n","       [-0.37110776,  0.2933696 ],\n","       [ 0.18815683, -0.35392734],\n","       [ 0.00290885,  0.3487035 ],\n","       [ 0.42748863, -0.14201054]], dtype=float32), array([ 0.02229084, -0.02229127], dtype=float32)]\n","\n","knn_loss 0.7846153846153846\n","retrieval_loss 0.7692307692307693\n","adapt with source 0.8\n","adapt without source 0.8153846153846154\n","\n","Epoch: 0, accuracy:0.8134,  loss:0.4145,  val_accuracy:0.8555,  val_loss:0.3237,  \n","..........................................................adapt model (without source) last loss:  0.027079671621322632\n","\n","Epoch: 0, accuracy:0.8181,  loss:0.4004,  val_accuracy:0.8725,  val_loss:0.3029,  \n","...................................adapt model (with source) last loss:  0.03382069617509842\n","weights\n","[array([[-0.10240645,  0.03619688,  0.09849654, ...,  0.10141105,\n","         0.01582449,  0.09627309],\n","       [ 0.10299176, -0.01395416,  0.07580543, ...,  0.13742049,\n","        -0.14067543, -0.17306495],\n","       [ 0.06135122,  0.00179166,  0.04200776, ...,  0.24197707,\n","        -0.0101927 ,  0.23101011],\n","       ...,\n","       [-0.08768889,  0.16471843, -0.1874858 , ..., -0.1392401 ,\n","         0.01386344, -0.11237391],\n","       [-0.20994398, -0.09108534,  0.0941487 , ..., -0.2404232 ,\n","        -0.12755638,  0.08004943],\n","       [ 0.18248515,  0.06418669,  0.17150913, ..., -0.15321475,\n","        -0.06287047, -0.08979156]], dtype=float32), array([-1.01881914e-01, -2.08301917e-02,  3.08519192e-02, -3.35619077e-02,\n","        8.64414312e-03, -2.86348462e-02, -1.03385234e-02, -4.94581200e-02,\n","       -1.78795066e-02,  3.27474158e-03,  6.18333183e-03, -5.42973634e-03,\n","       -9.07807946e-02,  5.63895376e-03, -4.77436036e-02, -1.88596919e-02,\n","       -8.19843709e-02,  3.99946086e-02,  2.25314237e-02, -1.27505353e-02,\n","       -3.56960781e-02, -1.02833351e-02, -1.76253375e-02, -4.63911965e-02,\n","        2.06489395e-02, -5.77300182e-03, -2.82201334e-03, -4.43293229e-02,\n","        1.16200587e-02,  7.35201780e-03, -2.79440898e-02, -1.31020835e-02,\n","       -6.08615838e-02, -2.71486416e-02, -3.60989571e-02, -2.19986886e-02,\n","       -4.92656343e-02, -1.11424131e-03, -5.42517044e-02,  3.44684045e-03,\n","       -1.69813971e-03, -6.68029441e-03, -4.29099612e-03, -6.53275400e-02,\n","       -9.23648290e-03, -1.80127285e-02,  1.53098628e-02, -3.22655924e-02,\n","        4.40603308e-02, -2.99399849e-02, -9.92472284e-03, -4.36195657e-02,\n","        2.84982845e-02,  1.32252062e-02, -7.24737346e-03,  1.14084443e-03,\n","       -5.40523902e-02,  6.72457693e-03,  1.89656131e-02, -8.49846937e-03,\n","       -4.98368889e-02, -1.68548329e-04,  1.72638781e-02,  1.25479475e-02,\n","       -4.97030618e-04, -4.64897156e-02,  9.20486636e-03, -5.80915585e-02,\n","        2.98101269e-02, -1.56942084e-02, -5.10478392e-02, -2.07237676e-02,\n","       -7.97723383e-02, -1.22075966e-02,  7.38184480e-03, -2.43437216e-02,\n","       -1.43723674e-02, -5.43467402e-02, -1.84388589e-02, -6.37015700e-02,\n","       -7.24432478e-03, -2.05793157e-02,  1.66472830e-02, -2.88562514e-02,\n","       -3.37495320e-02, -9.40406136e-03,  2.54689567e-02,  4.56072651e-02,\n","       -1.43095781e-03, -1.59575846e-02,  1.04206312e-03,  4.70039360e-02,\n","        2.90306122e-03,  3.42464983e-03,  3.22485995e-03,  1.45945055e-02,\n","       -9.79901291e-03, -7.42919219e-05, -7.03155696e-02, -8.81776563e-04,\n","        1.64511632e-02,  4.17901529e-03,  5.66525422e-02, -4.52745222e-02,\n","       -2.21748445e-02, -4.68602479e-02, -4.51245345e-02, -5.28190546e-02,\n","        3.51679884e-02, -8.01432040e-03, -6.50593191e-02, -2.30422877e-02,\n","        1.13758501e-02, -2.33499091e-02, -1.38010290e-02, -5.44296838e-02,\n","       -2.36958135e-02, -1.31859183e-02, -7.59347621e-03, -3.55864502e-02,\n","        8.31526413e-04, -1.42651815e-02, -6.16765693e-02,  3.29843402e-04,\n","       -2.06534714e-02, -5.00656776e-02, -2.09870506e-02, -2.63931099e-02],\n","      dtype=float32), array([[ 0.03236285,  0.13738404, -0.03821088, ...,  0.01762353,\n","         0.0236612 ,  0.20499668],\n","       [ 0.22288646,  0.11454573,  0.12905397, ...,  0.03548542,\n","         0.1847653 ,  0.3253586 ],\n","       [ 0.27600434, -0.21414308,  0.3072523 , ...,  0.131073  ,\n","         0.23959   ,  0.24614538],\n","       ...,\n","       [ 0.04411936,  0.03669491, -0.2365868 , ..., -0.02278464,\n","         0.20486288,  0.04505416],\n","       [ 0.08890072,  0.08708213,  0.13825314, ..., -0.12297801,\n","         0.18725835, -0.11210146],\n","       [ 0.04544991,  0.21821852, -0.23004878, ..., -0.11776007,\n","         0.2392347 ,  0.08256898]], dtype=float32), array([ 0.02183601,  0.00113596, -0.03448592, -0.03612514, -0.03335039,\n","        0.02557953, -0.03693918,  0.03453613,  0.023507  ,  0.05694774,\n","       -0.00336832,  0.0295719 ,  0.01420553,  0.04079954, -0.0444985 ,\n","        0.01796392,  0.03924298,  0.04779811,  0.00569741,  0.02690462,\n","        0.07616258,  0.01614603,  0.06136216,  0.01359571, -0.02837673,\n","        0.05058701, -0.01002622, -0.00587803,  0.02647357,  0.01418275,\n","       -0.02034731,  0.05234471,  0.02758108,  0.00645923, -0.06721557,\n","        0.02823611,  0.05739104,  0.01373657,  0.02363766,  0.03713797,\n","        0.02281094,  0.06591477, -0.04893198, -0.00871775,  0.00396771,\n","       -0.01368529,  0.00486514, -0.01595266,  0.02401677,  0.03201504,\n","       -0.11785102,  0.03689856,  0.02595408,  0.00422673,  0.05581892,\n","        0.03049718,  0.01262371, -0.00076637,  0.04289351,  0.00190457,\n","        0.0023445 , -0.00425634,  0.00281908,  0.0279142 ], dtype=float32), array([[ 0.3695012 , -0.5827677 ],\n","       [-0.2552597 ,  0.19602382],\n","       [ 0.57259893, -0.48248652],\n","       [ 0.07566271,  0.07249033],\n","       [ 0.16275737, -0.4211382 ],\n","       [ 0.1647008 , -0.601131  ],\n","       [-0.02802956,  0.19201614],\n","       [-0.2719738 ,  0.46432915],\n","       [ 0.14673261, -0.12144055],\n","       [-0.9076473 ,  0.33363804],\n","       [ 0.19219653, -0.28596714],\n","       [ 0.33532843, -0.60051006],\n","       [-0.3699833 ,  0.28353766],\n","       [-0.73151004,  0.3540004 ],\n","       [-0.73145795,  0.9503047 ],\n","       [ 0.27810088, -0.26407766],\n","       [-0.26213312,  0.2003925 ],\n","       [-0.7084764 ,  0.5334359 ],\n","       [ 0.37467104, -0.37928414],\n","       [-0.05104413, -0.36820424],\n","       [-0.52703446,  0.9028391 ],\n","       [ 0.33716708, -0.25758442],\n","       [-0.57314134,  0.7116979 ],\n","       [-0.5064348 ,  0.2924136 ],\n","       [ 0.3101803 ,  0.17554595],\n","       [-0.46103814,  0.17902051],\n","       [ 0.6904213 , -0.55360997],\n","       [-0.4662155 , -0.03662251],\n","       [-0.18816173,  0.1895767 ],\n","       [-0.3960136 ,  0.6726109 ],\n","       [-0.30460715,  0.34853894],\n","       [-0.07192126, -0.3891065 ],\n","       [-0.43635327,  0.4434204 ],\n","       [-0.37889016,  0.53847957],\n","       [-0.05922754,  0.5618176 ],\n","       [-0.7499979 ,  0.50657064],\n","       [-0.7027986 ,  0.76176894],\n","       [ 0.02357683, -0.37177172],\n","       [-0.34733528,  0.35344574],\n","       [-0.44972017,  0.491077  ],\n","       [-0.09432458,  0.54216295],\n","       [-0.80860704,  0.31805062],\n","       [ 0.75177085, -0.43721372],\n","       [-0.2954703 ,  0.33008972],\n","       [ 0.61786705, -0.23186721],\n","       [ 0.24003677, -0.6203047 ],\n","       [-0.36713532,  0.45153666],\n","       [-0.24511449,  0.4035407 ],\n","       [-0.354781  ,  0.30721566],\n","       [-0.52690727,  0.458522  ],\n","       [ 0.86118454, -1.0374227 ],\n","       [-0.03995192,  0.5814886 ],\n","       [-0.34296754,  0.11700503],\n","       [ 0.1834106 , -0.27336922],\n","       [ 0.42063323, -0.6093027 ],\n","       [-0.36446145,  0.5279154 ],\n","       [-0.5002685 ,  0.30580106],\n","       [ 0.0943152 , -0.2285984 ],\n","       [-0.40120512,  0.5713394 ],\n","       [-0.21833149,  0.1723019 ],\n","       [ 0.12660709, -0.00399687],\n","       [ 0.02936385, -0.2160641 ],\n","       [ 0.34834906,  0.14723781],\n","       [ 0.29535496, -0.3964115 ]], dtype=float32), array([ 0.03910441, -0.03910517], dtype=float32)]\n","\n","knn_loss 0.8307692307692308\n","retrieval_loss 0.7692307692307693\n","adapt with source 0.8461538461538461\n","adapt without source 0.8307692307692308\n","\n","Epoch: 0, accuracy:0.8080,  loss:0.4184,  val_accuracy:0.8584,  val_loss:0.3506,  \n","............................adapt model (without source) last loss:  0.09681646525859833\n","\n","Epoch: 0, accuracy:0.8008,  loss:0.4300,  val_accuracy:0.8527,  val_loss:0.3629,  \n","........................adapt model (with source) last loss:  0.06598226726055145\n","weights\n","[array([[-0.03438632,  0.08693996,  0.10318644, ..., -0.11748581,\n","         0.00541182,  0.0780382 ],\n","       [-0.03032395,  0.04546352,  0.17182799, ..., -0.02565211,\n","         0.18796968,  0.16190273],\n","       [ 0.30631194, -0.11726817,  0.08868482, ..., -0.23089299,\n","        -0.15189976, -0.0006967 ],\n","       ...,\n","       [-0.20265579, -0.07238378, -0.07561483, ..., -0.08447152,\n","         0.03996836, -0.17544681],\n","       [ 0.19820544,  0.20171729,  0.1468803 , ..., -0.12034783,\n","         0.00675849,  0.15984707],\n","       [-0.03991298, -0.00946882,  0.08051677, ..., -0.336678  ,\n","        -0.27934435, -0.0179121 ]], dtype=float32), array([ 2.27109063e-02, -4.49643983e-03,  1.27715962e-02,  7.07010878e-03,\n","       -8.22615623e-03,  5.06311320e-02,  1.42888799e-02,  3.88793983e-02,\n","        1.26483394e-02,  4.28073527e-03,  3.41725536e-02,  5.79710528e-02,\n","       -3.68296020e-02,  3.53927095e-03,  4.24916809e-03,  7.57550169e-03,\n","       -3.92703414e-02, -8.05014372e-03, -3.86592490e-03, -3.58693744e-03,\n","        5.13894157e-03,  7.99672864e-03, -1.42872508e-04, -1.30097207e-03,\n","        2.43052584e-03, -1.29197948e-02,  3.72403190e-02,  2.57977713e-02,\n","        2.04978902e-02, -2.20357236e-02,  1.60449259e-02, -4.42123376e-02,\n","       -9.96595621e-03, -1.41517054e-02, -1.13239726e-02,  1.20626613e-02,\n","        4.07868344e-03, -1.01361908e-02,  1.93325803e-02, -1.58749726e-02,\n","        1.32416105e-02,  2.28145276e-03, -7.94869289e-03, -2.71371417e-02,\n","       -6.96580755e-05, -4.83318716e-02, -4.62193461e-03, -3.28761563e-02,\n","        1.49055375e-02, -2.20456310e-02,  2.40674578e-02,  2.34889574e-02,\n","       -1.59398746e-02,  3.23981419e-02,  2.05702335e-03,  1.35082444e-02,\n","       -4.84799035e-02,  4.97748666e-02, -9.23189521e-03,  2.31006201e-02,\n","       -1.19060297e-02,  1.33365178e-02, -1.77416317e-02, -6.34109462e-03,\n","       -2.27300469e-02,  8.02589580e-03, -6.03090338e-02,  1.44360876e-02,\n","        2.13507675e-02, -1.03151873e-02,  4.30332609e-02, -5.92798218e-02,\n","       -3.38015556e-02,  2.51870751e-02,  1.07138446e-02, -1.30215019e-03,\n","       -1.09541193e-02, -7.26347789e-02, -7.95919448e-03, -8.94965604e-03,\n","        1.26621164e-02, -2.00976841e-02,  1.59853976e-02,  2.50017401e-02,\n","        3.68750596e-04,  2.94480994e-02, -3.68211195e-02, -1.36272088e-02,\n","        6.13877596e-03, -2.14024018e-02, -2.79654749e-02,  3.31635028e-02,\n","       -2.19842121e-02, -6.90974444e-02,  3.56521383e-02,  9.08325426e-03,\n","        6.99969381e-03,  1.95563510e-02,  2.28862315e-02, -1.91075020e-02,\n","        4.16767187e-02,  8.53328500e-03,  4.85495254e-02, -1.63055547e-02,\n","       -7.11163646e-03, -5.34860510e-03,  3.21498327e-03, -9.95277055e-03,\n","       -7.16687515e-02,  2.71410495e-02, -2.08045635e-02,  1.87080633e-03,\n","        1.15534961e-02,  5.57641461e-02, -3.95846404e-02, -1.79496240e-02,\n","        2.05095019e-02, -1.94842853e-02,  1.95558020e-03, -1.39366202e-02,\n","       -2.26398297e-02, -5.15844906e-04, -3.08512691e-02, -6.49313182e-02,\n","       -1.60660427e-02, -2.31995136e-02,  4.89067193e-03, -9.27584805e-03],\n","      dtype=float32), array([[-0.00123796, -0.08498643, -0.23202993, ...,  0.04820351,\n","        -0.13918258, -0.10164469],\n","       [ 0.1853914 ,  0.16980162,  0.33799195, ..., -0.16625054,\n","        -0.02573968,  0.14776583],\n","       [ 0.07515954,  0.03411621,  0.1172887 , ..., -0.14313385,\n","         0.00841604,  0.05870238],\n","       ...,\n","       [ 0.06979955, -0.21393688, -0.1210388 , ...,  0.15609169,\n","        -0.21457544, -0.24664289],\n","       [ 0.00452942,  0.08880714,  0.13535683, ...,  0.02424549,\n","         0.09828738, -0.09818457],\n","       [ 0.23703122,  0.2295715 ,  0.01637194, ...,  0.13182208,\n","        -0.04192428,  0.07477277]], dtype=float32), array([ 0.02517546,  0.03119429,  0.00928951,  0.02249507,  0.00400978,\n","        0.02849656,  0.03479009,  0.04917121,  0.0162039 , -0.01003948,\n","       -0.00980423,  0.05732962, -0.00146687, -0.02355361,  0.0126953 ,\n","        0.02696075, -0.00676059,  0.01865402,  0.03693466,  0.02937495,\n","        0.03866301, -0.00326591,  0.04042491,  0.04269621, -0.02708912,\n","       -0.01254876, -0.00700589,  0.04602307,  0.00510009,  0.0021044 ,\n","        0.00747554,  0.00275283, -0.00782518,  0.02638545, -0.00736933,\n","        0.04685672, -0.0266376 ,  0.02334349, -0.00441243,  0.02881132,\n","        0.02957115,  0.01142995,  0.00278916,  0.04034194,  0.02627448,\n","        0.06584673,  0.001117  ,  0.02035304,  0.04385915,  0.02778281,\n","        0.03234441,  0.0099157 ,  0.0158596 ,  0.05665932,  0.02171549,\n","        0.01560411,  0.01900908,  0.03157684, -0.00495281, -0.00486232,\n","        0.0197955 ,  0.00724304,  0.03166354,  0.04891671], dtype=float32), array([[-0.88158196,  0.908932  ],\n","       [-0.5013114 ,  0.0751386 ],\n","       [-0.46980733,  0.13912874],\n","       [-0.23554811,  0.37252098],\n","       [-0.80373234,  0.4730584 ],\n","       [ 0.6416233 , -0.21783191],\n","       [ 0.45978463, -0.39131784],\n","       [ 0.45085117, -0.40624383],\n","       [ 0.6664162 , -0.12787703],\n","       [ 0.02903505, -0.15302143],\n","       [ 0.31966543, -0.32221603],\n","       [ 0.27974656, -0.41900906],\n","       [ 0.3264175 , -0.33559674],\n","       [ 0.20206581, -0.55411476],\n","       [ 0.3175308 ,  0.1307549 ],\n","       [ 0.6116484 , -0.5440547 ],\n","       [-0.05638792, -0.38193503],\n","       [ 0.3379049 , -0.3480056 ],\n","       [ 0.0417597 ,  0.30901203],\n","       [ 0.4302764 , -0.46052647],\n","       [ 0.59434396, -0.7235266 ],\n","       [ 0.29477298, -0.5044928 ],\n","       [-0.27067047,  0.0068989 ],\n","       [ 0.16513723, -0.32329908],\n","       [ 0.41972366, -0.36164197],\n","       [ 0.07662869,  0.19252223],\n","       [-0.24743953,  0.34554917],\n","       [-0.13040772,  0.15181762],\n","       [ 0.1425844 , -0.5280087 ],\n","       [ 0.2945629 , -0.5675509 ],\n","       [-0.3008575 ,  0.23163927],\n","       [ 0.3783212 , -0.5214689 ],\n","       [-0.21292023, -0.11001029],\n","       [-0.00737766,  0.32458654],\n","       [ 0.03482419, -0.4665114 ],\n","       [-0.22853002,  0.00177324],\n","       [ 0.31342635, -0.23443726],\n","       [ 0.3547257 , -0.27820686],\n","       [-0.12880473, -0.34253895],\n","       [ 0.5224201 , -0.5597882 ],\n","       [-0.30452612,  0.41234815],\n","       [ 0.48774913, -0.44410852],\n","       [ 0.23547275, -0.1989481 ],\n","       [-0.33346176,  0.24385424],\n","       [ 0.5697594 , -0.7634869 ],\n","       [-0.6725646 ,  0.34770423],\n","       [-0.2716828 ,  0.42939445],\n","       [-0.46390408,  0.43161705],\n","       [-0.40833214,  0.7111853 ],\n","       [ 0.16745973,  0.33328688],\n","       [-0.3158827 ,  0.2906901 ],\n","       [-0.66780806,  0.35159355],\n","       [ 0.24722771, -0.38209373],\n","       [ 0.47863948, -0.5571102 ],\n","       [ 0.5758415 , -0.44803113],\n","       [ 0.68927956, -0.71015006],\n","       [-0.2232477 ,  0.6996588 ],\n","       [ 0.38253462, -0.17968395],\n","       [ 0.42902318, -0.09796817],\n","       [ 0.27515885,  0.10236807],\n","       [-0.35123554,  0.17188187],\n","       [ 0.42834574, -0.6351725 ],\n","       [-0.05194144,  0.09572531],\n","       [-0.36996767,  0.2935945 ]], dtype=float32), array([-0.0343687 ,  0.03436858], dtype=float32)]\n","\n","knn_loss 0.8923076923076924\n","retrieval_loss 0.8307692307692308\n","adapt with source 0.8\n","adapt without source 0.7538461538461538\n","\n","Epoch: 0, accuracy:0.8305,  loss:0.3878,  val_accuracy:0.8329,  val_loss:0.3547,  \n","............................................adapt model (without source) last loss:  0.07848341763019562\n","\n","Epoch: 0, accuracy:0.8166,  loss:0.4136,  val_accuracy:0.8839,  val_loss:0.3236,  \n","......................................adapt model (with source) last loss:  0.01163092814385891\n","weights\n","[array([[-0.03549056,  0.23493952, -0.04535734, ..., -0.141837  ,\n","         0.1739318 , -0.11762024],\n","       [ 0.00660645, -0.0555197 ,  0.01619537, ..., -0.08933584,\n","        -0.05726128,  0.17640737],\n","       [-0.10496728,  0.196773  ,  0.02843487, ...,  0.00390251,\n","         0.16554967, -0.23439562],\n","       ...,\n","       [-0.15943909, -0.14726157, -0.12400699, ...,  0.16985244,\n","         0.20192558, -0.13075164],\n","       [ 0.13997804,  0.17333359, -0.18379329, ...,  0.21633804,\n","        -0.10749762, -0.24055527],\n","       [-0.09344197, -0.07388105,  0.15895963, ...,  0.1176884 ,\n","        -0.30922955, -0.05838141]], dtype=float32), array([-0.00850394, -0.0179206 ,  0.02132694, -0.00333799,  0.01025316,\n","       -0.0395459 ,  0.0017407 , -0.03214217,  0.03155471, -0.00899519,\n","        0.01753127,  0.03484784, -0.0380026 ,  0.0091644 , -0.03972893,\n","       -0.0010205 , -0.02579111,  0.00716976,  0.01659103, -0.01992152,\n","       -0.00099917,  0.01521793,  0.00378409, -0.03384663, -0.0053042 ,\n","        0.01491235, -0.00584199, -0.07073328,  0.03522318,  0.00061701,\n","        0.00755692,  0.04077664, -0.01525135, -0.00148451,  0.00623357,\n","        0.00128378,  0.01978045, -0.02529821, -0.02355017, -0.02786101,\n","       -0.05219643, -0.02664071, -0.01481752, -0.02273697,  0.01093202,\n","        0.03852038, -0.06514444, -0.00736773, -0.00074432, -0.00756073,\n","        0.02412105, -0.00660688, -0.04102897, -0.00416915, -0.02252262,\n","       -0.02080794, -0.01597915,  0.01806263, -0.04404973,  0.02951156,\n","        0.00922005, -0.01620433, -0.04908897, -0.00574543,  0.00649254,\n","        0.02152742,  0.0589436 ,  0.03000087,  0.00833007, -0.01686603,\n","       -0.06221838, -0.044698  ,  0.00117068, -0.01786726, -0.05999988,\n","       -0.06024745, -0.01296692, -0.01247774,  0.02530723, -0.00547904,\n","       -0.01274285,  0.00059848,  0.01118925, -0.01212255, -0.03447628,\n","        0.00075384,  0.03041403,  0.00988105, -0.02155564,  0.0295266 ,\n","       -0.03736411,  0.00503625, -0.05692584, -0.04913405, -0.00025465,\n","       -0.06121693, -0.018254  ,  0.01883746,  0.04924827, -0.0499879 ,\n","        0.0061907 ,  0.02317958, -0.00275198,  0.04414007,  0.003536  ,\n","       -0.01111073, -0.01156897,  0.0136317 , -0.000958  , -0.04995768,\n","       -0.03607868,  0.00860953,  0.00179202, -0.02299935,  0.01008619,\n","       -0.04609115,  0.00269533, -0.0221532 , -0.015381  ,  0.00650275,\n","       -0.00201464,  0.08851466, -0.03163306,  0.03374903, -0.01525668,\n","        0.04967692, -0.01658815,  0.05280355], dtype=float32), array([[ 0.19303116, -0.08915498,  0.02980407, ...,  0.04987099,\n","         0.03183392, -0.22517037],\n","       [-0.017299  , -0.08659036, -0.07326035, ..., -0.00260679,\n","         0.29035187,  0.07342367],\n","       [-0.15024768,  0.07273422,  0.24238239, ..., -0.12434404,\n","         0.22114517,  0.22291106],\n","       ...,\n","       [ 0.15843807,  0.24777497,  0.03880195, ..., -0.07059516,\n","         0.05668482,  0.08572166],\n","       [ 0.09341279,  0.05868022, -0.01261536, ..., -0.21022826,\n","         0.06691583, -0.112904  ],\n","       [-0.00513151, -0.15378334, -0.37369853, ...,  0.00301687,\n","        -0.09692455,  0.17658487]], dtype=float32), array([ 0.03025227, -0.00605755,  0.00039019,  0.00685293,  0.04132184,\n","        0.07056697, -0.02077558,  0.02719447,  0.01609024,  0.00892593,\n","        0.01458613,  0.02822706,  0.02145938, -0.00853231,  0.03172646,\n","        0.03530679, -0.04409301,  0.03068862,  0.04149065,  0.02429142,\n","       -0.03856459, -0.04134881, -0.02304799,  0.07504487,  0.01667003,\n","        0.01733045,  0.10282734, -0.00145479,  0.02329067,  0.02953948,\n","        0.05581735,  0.0428725 ,  0.05565916,  0.02126756,  0.05233355,\n","       -0.01554711,  0.01645862,  0.0220019 , -0.00842139,  0.01939905,\n","        0.02246705,  0.00545005,  0.00186787,  0.0330937 ,  0.04006968,\n","        0.01069105,  0.00293225,  0.05921752,  0.04942211, -0.02603442,\n","        0.00270808,  0.00660051,  0.01914521,  0.01086705,  0.01646633,\n","        0.00684961,  0.04768652,  0.01885025,  0.00409567,  0.02656726,\n","       -0.04831957, -0.02688747,  0.04928737,  0.0195855 ], dtype=float32), array([[-0.6492365 ,  0.41759568],\n","       [-0.46883628,  0.34829274],\n","       [-0.4494506 ,  0.56093067],\n","       [ 0.07218885, -0.25402716],\n","       [ 0.45738098, -0.6670652 ],\n","       [ 0.569033  , -0.10156249],\n","       [-0.05211789,  0.18699336],\n","       [-0.31603432,  0.01265924],\n","       [-0.4009118 ,  0.06269382],\n","       [ 0.9261154 , -0.6080242 ],\n","       [ 0.5333697 , -0.09862603],\n","       [-0.39583668,  0.22604439],\n","       [ 0.17039068, -0.13660613],\n","       [-0.439632  ,  0.3864262 ],\n","       [ 0.24801853, -0.08400076],\n","       [ 0.51971924, -0.40518484],\n","       [ 0.12750824,  0.17323567],\n","       [ 0.09339078, -0.22655505],\n","       [-0.69645196,  0.70499873],\n","       [ 0.4394826 , -0.4685346 ],\n","       [-0.21217194,  0.48055205],\n","       [-0.3085638 ,  0.41618875],\n","       [ 0.02291643, -0.38745335],\n","       [-0.4053479 ,  0.48993546],\n","       [-0.695164  ,  0.52125925],\n","       [ 0.3446835 , -0.29001346],\n","       [ 0.7289908 , -0.65459025],\n","       [-0.16077793,  0.5842534 ],\n","       [-0.04711271,  0.40237758],\n","       [ 0.09023256, -0.21942735],\n","       [-0.11325532,  0.53487223],\n","       [-0.45893955,  0.14485304],\n","       [-0.42161354,  0.32395992],\n","       [ 0.4778262 , -0.63409305],\n","       [ 0.21563232, -0.30175254],\n","       [-0.45970333,  0.53527516],\n","       [ 0.33795026, -0.12918091],\n","       [ 0.7602681 , -0.5519757 ],\n","       [-0.22617686,  0.24160798],\n","       [ 0.6293763 , -0.2865244 ],\n","       [ 0.2632902 , -0.2948251 ],\n","       [-0.2114075 ,  0.54389083],\n","       [ 0.31194663, -0.11032411],\n","       [-0.00678933, -0.36683154],\n","       [-0.31003812,  0.46443948],\n","       [ 0.14092456, -0.18796244],\n","       [ 0.4262952 ,  0.05575383],\n","       [-0.34382334,  0.42911243],\n","       [ 0.3727037 , -0.1804859 ],\n","       [ 0.25051084,  0.20238744],\n","       [-0.5387435 ,  0.47416568],\n","       [ 0.6278545 , -0.69751704],\n","       [-0.1601051 ,  0.49258298],\n","       [-0.20144877,  0.06259689],\n","       [ 0.12813404, -0.40296173],\n","       [ 0.20379166, -0.52553445],\n","       [-0.48856768,  0.05476923],\n","       [ 0.4489303 , -0.07097747],\n","       [-0.49151453,  0.22219744],\n","       [ 0.12504798, -0.23445717],\n","       [ 0.5052403 , -0.56852174],\n","       [-0.05025006,  0.40395913],\n","       [ 0.569515  , -0.55951583],\n","       [ 0.43136644, -0.23175108]], dtype=float32), array([-0.00268581,  0.00268513], dtype=float32)]\n","\n","knn_loss 0.7692307692307693\n","retrieval_loss 0.7538461538461538\n","adapt with source 0.7692307692307693\n","adapt without source 0.7692307692307693\n","\n","Epoch: 0, accuracy:0.8220,  loss:0.4085,  val_accuracy:0.8555,  val_loss:0.3012,  \n","..................................adapt model (without source) last loss:  0.06876502931118011\n","\n","Epoch: 0, accuracy:0.8260,  loss:0.3966,  val_accuracy:0.8385,  val_loss:0.3507,  \n","...................................adapt model (with source) last loss:  0.0726117268204689\n","weights\n","[array([[ 0.05720495, -0.10954131, -0.07865848, ..., -0.22467832,\n","        -0.04591336, -0.23367953],\n","       [ 0.19132662, -0.19025499, -0.17619555, ..., -0.09923242,\n","        -0.16885166, -0.2697306 ],\n","       [ 0.036615  ,  0.03165993,  0.00253857, ...,  0.07041617,\n","         0.19874267, -0.28704962],\n","       ...,\n","       [-0.15883663, -0.04221005,  0.12108402, ...,  0.03153678,\n","         0.20779121, -0.2581351 ],\n","       [-0.1855439 ,  0.2156781 ,  0.22983913, ..., -0.07634681,\n","         0.25173983,  0.26085177],\n","       [ 0.14011657,  0.14007035,  0.20479508, ...,  0.24580586,\n","         0.27173528,  0.3885471 ]], dtype=float32), array([-0.00902035, -0.01373284, -0.00844757, -0.03051493,  0.00935004,\n","        0.03686778,  0.01730927,  0.00337401, -0.00959826, -0.04048826,\n","       -0.00598129,  0.02276758, -0.00236113, -0.01394905,  0.0122898 ,\n","       -0.00753511,  0.04771566, -0.0342834 , -0.02445377, -0.04316516,\n","       -0.04423932, -0.02346305,  0.00713034,  0.00132957, -0.01052126,\n","       -0.03196681, -0.04699114, -0.03925198, -0.01708349,  0.03336099,\n","       -0.01975683, -0.03371527,  0.0179059 ,  0.01272981,  0.02183261,\n","        0.0262795 , -0.05013365, -0.0498455 , -0.02446055,  0.02067831,\n","        0.00875813,  0.04320993, -0.03737066, -0.03376915,  0.01598164,\n","        0.03491634, -0.04710519, -0.03185165,  0.00607981, -0.00673888,\n","        0.00103044, -0.05393951,  0.00843937,  0.00685236,  0.01580591,\n","        0.02425097, -0.02470624, -0.07159166, -0.03781451, -0.00291362,\n","       -0.01189949, -0.02102607, -0.01722307, -0.02960471, -0.0063159 ,\n","        0.01290562,  0.04736579,  0.00039935, -0.03133589,  0.00676495,\n","        0.05975379, -0.01657795, -0.01996609, -0.02309045,  0.00905313,\n","       -0.00855959, -0.03388906,  0.02578877, -0.01388368, -0.00423395,\n","       -0.02249938, -0.01101373, -0.02300007,  0.02186989, -0.04150523,\n","        0.03104366, -0.00749391,  0.01739963,  0.01917333, -0.0240541 ,\n","        0.02298331, -0.00799725, -0.02177834, -0.01574167,  0.0134499 ,\n","       -0.02325472,  0.03169854, -0.01143428,  0.00588433, -0.04813518,\n","        0.01055343,  0.01895028,  0.01412404, -0.00740614, -0.0110341 ,\n","       -0.01971219, -0.01753615,  0.0113079 ,  0.01536521,  0.0249139 ,\n","        0.03826334, -0.01508101, -0.00074611, -0.01700567,  0.04058672,\n","       -0.00742603,  0.00848095,  0.03608242,  0.01674353,  0.00633134,\n","        0.00468027,  0.03103788, -0.0319428 , -0.02976422,  0.01158985,\n","        0.00449303, -0.028525  ,  0.01071702], dtype=float32), array([[-0.22932543, -0.0944559 ,  0.38325575, ...,  0.17434764,\n","        -0.1027334 ,  0.0934857 ],\n","       [ 0.12692295, -0.06847759,  0.02572638, ...,  0.05457231,\n","         0.12459968, -0.17326857],\n","       [ 0.25458565,  0.0098837 ,  0.01104986, ...,  0.07534158,\n","         0.09489098,  0.13448846],\n","       ...,\n","       [-0.03628062, -0.06541576,  0.16723737, ...,  0.07028754,\n","         0.23096156,  0.16274843],\n","       [ 0.13377844, -0.12162403,  0.07561054, ..., -0.16963017,\n","        -0.0917477 ,  0.02528753],\n","       [ 0.17652611, -0.20016643, -0.05043172, ..., -0.12498183,\n","        -0.1772384 , -0.19991416]], dtype=float32), array([ 0.04036456,  0.02273605,  0.0025592 , -0.027752  , -0.01685023,\n","       -0.02556111,  0.00089053,  0.01469875, -0.01587193,  0.03283413,\n","        0.05131372, -0.04616024,  0.00575812,  0.01293458,  0.05765621,\n","        0.00322784,  0.05633711,  0.02333623, -0.00993525,  0.00575317,\n","        0.01513338,  0.0288272 ,  0.03708911, -0.02709267,  0.00193739,\n","       -0.00930734, -0.01986048,  0.04052247, -0.00685594, -0.02109386,\n","       -0.00436929, -0.008874  ,  0.03574448,  0.04919617, -0.05459367,\n","        0.01709607,  0.0293352 , -0.0989071 ,  0.00949341, -0.00370622,\n","        0.01567273,  0.02679127,  0.00207484,  0.01568005,  0.02842199,\n","        0.03054612, -0.03312754, -0.03718165, -0.00016789, -0.00945986,\n","       -0.0450637 ,  0.02209372,  0.03269783, -0.00449723, -0.02072876,\n","       -0.00076449, -0.02049542,  0.03044966, -0.04669483, -0.00134682,\n","        0.03833989, -0.0129469 , -0.00919338,  0.01040871], dtype=float32), array([[-0.23617382,  0.3035218 ],\n","       [ 0.13401404, -0.48124376],\n","       [ 0.42513573, -0.2778063 ],\n","       [ 0.4968032 ,  0.01195037],\n","       [-0.33498272,  0.48989514],\n","       [-0.3207901 ,  0.61292404],\n","       [ 0.5166979 , -0.53969586],\n","       [-0.49311063,  0.46436122],\n","       [ 0.3412025 , -0.12620912],\n","       [-0.03890527,  0.30129138],\n","       [-0.22322509,  0.2595193 ],\n","       [-0.16243951,  0.30447012],\n","       [ 0.68687814, -0.24612342],\n","       [ 0.1777351 , -0.22141758],\n","       [-0.80532664,  0.7458555 ],\n","       [-0.41939038, -0.01938813],\n","       [-0.1625652 ,  0.4638127 ],\n","       [ 0.17855108, -0.38129368],\n","       [ 0.32767668, -0.40806568],\n","       [ 0.06751779, -0.24054696],\n","       [-0.11323823, -0.45741996],\n","       [-0.36641338,  0.05078976],\n","       [-0.51067686,  0.05080554],\n","       [-0.44107392,  0.6604986 ],\n","       [ 0.18533824, -0.1760423 ],\n","       [-0.14148825,  0.3837312 ],\n","       [ 0.58949614, -0.27587885],\n","       [-0.42758247,  0.5026208 ],\n","       [-0.75766414,  0.6391717 ],\n","       [ 0.5696205 , -0.5016745 ],\n","       [ 0.74909425, -0.4838346 ],\n","       [ 0.3001433 , -0.3218593 ],\n","       [-0.27550864,  0.40993255],\n","       [-0.18363242,  0.48721132],\n","       [-0.03866113, -0.04158041],\n","       [-0.31093025,  0.06001087],\n","       [-0.41775128,  0.7480086 ],\n","       [-0.7141462 ,  0.2721173 ],\n","       [ 0.22386225, -0.17241831],\n","       [ 0.42889407, -0.1791788 ],\n","       [-0.5958588 ,  0.47317174],\n","       [-0.354351  ,  0.02573027],\n","       [ 0.36819977, -0.064307  ],\n","       [-0.58765095,  0.27380025],\n","       [ 0.4909405 , -0.54722434],\n","       [-0.4020737 ,  0.49245626],\n","       [ 1.0352565 , -1.0771458 ],\n","       [-0.60080785,  0.22220924],\n","       [ 0.6214693 , -0.33242986],\n","       [-0.38587362,  0.6798698 ],\n","       [ 0.24744935,  0.20092568],\n","       [-0.34602636,  0.22145413],\n","       [-0.31114748,  0.56620497],\n","       [ 0.26601157, -0.17800109],\n","       [ 0.46224892, -0.43786305],\n","       [ 0.14074726, -0.3688586 ],\n","       [ 0.19176212, -0.3809891 ],\n","       [-0.5986863 ,  0.5791982 ],\n","       [-0.43295696,  0.4262977 ],\n","       [ 0.2023213 , -0.04664974],\n","       [-0.5487041 ,  0.745649  ],\n","       [ 0.31417605, -0.32483453],\n","       [ 0.87740684, -0.8718936 ],\n","       [ 0.28415275, -0.14055456]], dtype=float32), array([-0.00515068,  0.00515036], dtype=float32)]\n","\n","knn_loss 0.8615384615384616\n","retrieval_loss 0.8307692307692308\n","adapt with source 0.8769230769230769\n","adapt without source 0.8769230769230769\n","\n","Epoch: 0, accuracy:0.8104,  loss:0.4093,  val_accuracy:0.8697,  val_loss:0.3054,  \n","...........................................................adapt model (without source) last loss:  0.020407728850841522\n","\n","Epoch: 0, accuracy:0.8141,  loss:0.4040,  val_accuracy:0.8612,  val_loss:0.3038,  \n",".......................................adapt model (with source) last loss:  0.046300191432237625\n","weights\n","[array([[-0.2503208 ,  0.06700348,  0.15446848, ...,  0.17177464,\n","        -0.16584782, -0.10294334],\n","       [ 0.10997175, -0.33176884,  0.06317441, ...,  0.08078762,\n","         0.01251976, -0.28652528],\n","       [-0.10043957, -0.32797396,  0.23247029, ...,  0.05906608,\n","         0.06410753, -0.28911227],\n","       ...,\n","       [ 0.08380217,  0.09074616, -0.15192665, ..., -0.15006658,\n","        -0.0720979 , -0.18276207],\n","       [ 0.12983742,  0.18042193, -0.08194357, ...,  0.10456479,\n","        -0.13013752, -0.24217637],\n","       [-0.3961092 , -0.36347246, -0.07297406, ..., -0.09708419,\n","         0.02794189,  0.11967385]], dtype=float32), array([-0.01954185,  0.00201845, -0.06695129, -0.01236798, -0.0534672 ,\n","       -0.04939556, -0.03104557, -0.02485502,  0.01714611,  0.01898584,\n","       -0.03458577, -0.01121994, -0.02563049,  0.03235225, -0.03715067,\n","       -0.0051991 , -0.04011345,  0.03066825, -0.01850562, -0.01796332,\n","        0.04053454, -0.03553575,  0.02829305,  0.01218335, -0.01732692,\n","       -0.07888604,  0.0082929 , -0.00014039, -0.05603071,  0.03545664,\n","        0.04136249, -0.05396381, -0.04610691, -0.01310011, -0.00339436,\n","        0.0386126 , -0.004408  , -0.01739159, -0.01519462, -0.05974675,\n","       -0.00537621, -0.01612551, -0.03411727, -0.01719729, -0.02830141,\n","       -0.02379757, -0.01780015, -0.02547712,  0.01121955, -0.00288656,\n","       -0.00254251,  0.00075258, -0.05194258, -0.01722279, -0.0285223 ,\n","        0.02231152, -0.02942026, -0.0345616 , -0.03132187, -0.05643696,\n","        0.02598033,  0.01198235, -0.01743691, -0.04097162, -0.05335904,\n","       -0.0246529 ,  0.02030473, -0.00622984,  0.04033171,  0.01348042,\n","       -0.10071818, -0.02697492, -0.00731244, -0.00187885,  0.01623501,\n","        0.00100268, -0.03327182, -0.0275509 , -0.00939008, -0.05853325,\n","       -0.01472548, -0.01269209,  0.00651554, -0.04956409, -0.05319816,\n","        0.03289431, -0.03174533, -0.01450103, -0.03618122, -0.05931547,\n","       -0.02918401, -0.03675409, -0.04324608,  0.0282709 ,  0.0119017 ,\n","       -0.02994655, -0.00039339, -0.03677671, -0.00352139, -0.00217469,\n","       -0.0123294 , -0.03447669, -0.01283469, -0.01324324,  0.01277366,\n","       -0.00589577, -0.01238047, -0.02409599, -0.01839678,  0.0188986 ,\n","       -0.03793367,  0.02688405, -0.04844771, -0.02223084, -0.00993622,\n","       -0.02136443, -0.03741194,  0.01041715, -0.0526361 ,  0.01065708,\n","       -0.01725537,  0.00844261, -0.04486442, -0.04576675,  0.00454588,\n","        0.02312663,  0.02601578,  0.02531998], dtype=float32), array([[-0.10527968, -0.10938151,  0.08778397, ...,  0.04965134,\n","         0.18806402, -0.1641707 ],\n","       [ 0.02222358,  0.17118594, -0.11369251, ..., -0.27262127,\n","         0.01522385,  0.1479315 ],\n","       [ 0.0066166 ,  0.0144118 , -0.15284346, ...,  0.02828944,\n","        -0.10580378, -0.08216793],\n","       ...,\n","       [-0.22530146, -0.20438518, -0.25857893, ..., -0.42716452,\n","        -0.06316524, -0.01385377],\n","       [-0.2853999 ,  0.26931986, -0.1036113 , ..., -0.21224932,\n","         0.00505638, -0.18233463],\n","       [ 0.34726286,  0.3263449 , -0.16711442, ..., -0.10599793,\n","        -0.16974261, -0.11666118]], dtype=float32), array([ 3.2945962e-03, -1.3134349e-04, -1.9003720e-03,  5.3083722e-02,\n","       -1.5045096e-02,  5.3002141e-02,  3.2702018e-02,  7.9410197e-03,\n","       -1.4253288e-02,  3.4160212e-02,  1.0114677e-02, -5.0204460e-02,\n","       -7.5227362e-03,  2.1540714e-02,  1.3149944e-02,  5.1177077e-02,\n","        4.0056087e-02, -8.7854248e-03,  2.5372891e-02,  2.2588883e-02,\n","       -1.8078556e-02, -1.4140067e-02, -5.5056773e-02,  2.7042834e-02,\n","       -1.3390584e-02,  1.4086126e-02,  2.3700094e-02,  7.7691905e-02,\n","       -3.9538115e-02,  1.4965693e-02,  4.1575424e-02,  6.9085181e-02,\n","       -3.2390226e-02, -6.6210344e-02, -2.5880837e-03, -1.3263797e-02,\n","        1.9574768e-03, -2.8716376e-02,  6.0236670e-02,  5.8949266e-02,\n","       -5.7502907e-02, -2.3074564e-02,  3.2611027e-02, -3.2989420e-02,\n","        1.6986171e-02,  6.2025707e-02,  2.2181330e-02,  1.7823342e-02,\n","        2.0424576e-02,  1.4452582e-02, -2.5600955e-02,  4.6645710e-08,\n","        1.2653999e-02, -6.8337861e-03,  3.6184717e-02,  5.0342143e-02,\n","        3.5609219e-02, -1.3521505e-02,  3.2627221e-02, -6.6219613e-02,\n","       -3.0460760e-02,  4.3887567e-02, -6.3558355e-02, -1.6052688e-02],\n","      dtype=float32), array([[-0.14847487,  0.57990485],\n","       [-0.8175767 ,  0.5663869 ],\n","       [ 0.24707146, -0.26650628],\n","       [ 0.10229414, -0.44711187],\n","       [-0.6382049 ,  0.51281685],\n","       [-0.28674078,  0.61663884],\n","       [-0.5177149 ,  0.58417076],\n","       [ 0.47749496, -0.6287373 ],\n","       [ 0.5659848 , -0.5204516 ],\n","       [-0.19420032,  0.3681944 ],\n","       [ 0.13833019, -0.17876014],\n","       [ 0.08895498,  0.05988425],\n","       [-0.3266969 ,  0.5289913 ],\n","       [-0.33252847,  0.23787104],\n","       [ 0.32890093, -0.10863887],\n","       [ 0.22225107, -0.05826904],\n","       [ 0.5054667 , -0.19928582],\n","       [ 0.6348849 , -0.49697167],\n","       [-0.29965267,  0.06185104],\n","       [-0.19401039,  0.39312127],\n","       [ 0.2138818 , -0.6975139 ],\n","       [ 0.16724364, -0.17602526],\n","       [ 0.60106367, -0.66804725],\n","       [ 0.3758964 , -0.3039953 ],\n","       [-0.6906136 ,  0.2867221 ],\n","       [ 0.97706026, -1.0062044 ],\n","       [-0.30656224,  0.72208565],\n","       [-0.20069407,  0.16435207],\n","       [ 0.17321683, -0.18283279],\n","       [ 0.24544695, -0.25662917],\n","       [ 0.20488776, -0.48285386],\n","       [ 0.2614668 , -0.52644145],\n","       [-0.4526553 ,  0.48766387],\n","       [-0.12614211,  0.53554446],\n","       [ 0.28472537, -0.1310745 ],\n","       [-0.15977046, -0.22760643],\n","       [-0.1584175 ,  0.38134888],\n","       [ 0.30860803, -0.77890563],\n","       [ 0.19607964, -0.35571525],\n","       [ 0.3125848 , -0.01692473],\n","       [ 0.6483685 , -0.68604195],\n","       [-0.11898012,  0.47885227],\n","       [-0.3900803 ,  0.42648676],\n","       [-0.54355437,  0.39476424],\n","       [ 0.39655095, -0.32124308],\n","       [ 0.78193533, -0.7653209 ],\n","       [-0.49412757,  0.7386504 ],\n","       [ 0.3654132 , -0.588427  ],\n","       [-0.7364007 ,  0.95091915],\n","       [-0.54550093,  0.44770694],\n","       [-0.28697595,  0.09394361],\n","       [ 0.49544758, -0.41900975],\n","       [-0.40092075,  0.40813085],\n","       [ 0.40948418, -0.45172065],\n","       [-0.3565626 ,  0.14313354],\n","       [-0.3277137 ,  0.3181511 ],\n","       [ 0.06418069, -0.50087607],\n","       [ 0.6431368 , -0.18429577],\n","       [-0.30604133,  0.53894126],\n","       [ 0.7755454 , -0.70891976],\n","       [-0.13674231,  0.06395301],\n","       [ 0.3880604 , -0.3047494 ],\n","       [-0.21901233, -0.23842622],\n","       [ 0.37354183, -0.886498  ]], dtype=float32), array([-0.04038763,  0.04038682], dtype=float32)]\n","\n","knn_loss 0.8615384615384616\n","retrieval_loss 0.8615384615384616\n","adapt with source 0.8461538461538461\n","adapt without source 0.8769230769230769\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.8360606060606062\n","np.mean(retrieval_loss_es) =  0.8039160839160839\n","np.mean(without_source_loss_es) =  0.8283216783216784\n","np.mean(with_source_loss_es) =  0.8192074592074594\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.03798876628854095\n","np.std(retrieval_loss_es) =  0.03834478287614729\n","np.std(without_source_loss_es) =  0.04937910851642399\n","np.std(with_source_loss_es) =  0.04088184696397106\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.8348077415512251\n","np.mean(retrieval_loss_es) =  0.8019415002134467\n","np.mean(without_source_loss_es) =  0.827949853516392\n","np.mean(with_source_loss_es) =  0.8191713775139322\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.03868762611837123\n","np.std(retrieval_loss_es) =  0.04019415393303344\n","np.std(without_source_loss_es) =  0.04645638161808649\n","np.std(with_source_loss_es) =  0.03612295408772946\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aLuYc0OK3mpi"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.8328111888111889\r\n","np.mean(retrieval_loss_es) =  0.7987925407925408\r\n","np.mean(without_source_loss_es) =  0.8205641025641026\r\n","np.mean(with_source_loss_es) =  0.8153100233100232\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.044620513012914094\r\n","np.std(retrieval_loss_es) =  0.04842702509473827\r\n","np.std(without_source_loss_es) =  0.04546265637992197\r\n","np.std(with_source_loss_es) =  0.04716968397373342\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.8311614407040221\r\n","np.mean(retrieval_loss_es) =  0.7969830152636375\r\n","np.mean(without_source_loss_es) =  0.8194399852074079\r\n","np.mean(with_source_loss_es) =  0.8131693358717937\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.04476559749708018\r\n","np.std(retrieval_loss_es) =  0.04890358244619819\r\n","np.std(without_source_loss_es) =  0.045772039445233545\r\n","np.std(with_source_loss_es) =  0.04844920547462508\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"a9HwivlKyR0x"},"source":["# Dataset loading: Balance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3pT2_pYzvfp","executionInfo":{"elapsed":2018431,"status":"ok","timestamp":1611013053321,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"f1377044-bf3c-4e4b-ae0e-0feaeb6c30a4"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/balance-scale.data'\r\n","nominalCols = [] \r\n","numericCols = [1,2,3,4]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(1,2,3,4,));\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(0,));\r\n","\r\n","    #remove rows with ? values\r\n","    if(X.values == '?'):\r\n","      rows_with_na = (X.values == '?').any(1)\r\n","      X = X[~rows_with_na]\r\n","      y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False)\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [1, 2, 3, 4]\n","Index: []\n","1    0\n","2    0\n","3    0\n","4    0\n","dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ve_1qLt504t3","executionInfo":{"elapsed":2018425,"status":"ok","timestamp":1611013053325,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"a80b823b-1c22-4e2f-da1c-4655695cef51"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(625, 4)"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"HbJPQUva0_1b","executionInfo":{"elapsed":2018416,"status":"ok","timestamp":1611013053326,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"8da6886c-8460-41b6-c858-4f9af654dbb5"},"source":["X.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>-1.414214</td>\n","      <td>-1.414214</td>\n","      <td>-0.707107</td>\n","      <td>0.707107</td>\n","    </tr>\n","    <tr>\n","      <th>502</th>\n","      <td>1.414214</td>\n","      <td>-1.414214</td>\n","      <td>-1.414214</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>-0.707107</td>\n","      <td>-0.707107</td>\n","      <td>0.000000</td>\n","      <td>1.414214</td>\n","    </tr>\n","    <tr>\n","      <th>246</th>\n","      <td>-0.707107</td>\n","      <td>1.414214</td>\n","      <td>1.414214</td>\n","      <td>-0.707107</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>-0.707107</td>\n","      <td>1.414214</td>\n","      <td>-1.414214</td>\n","      <td>0.707107</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            1         2         3         4\n","8   -1.414214 -1.414214 -0.707107  0.707107\n","502  1.414214 -1.414214 -1.414214  0.000000\n","164 -0.707107 -0.707107  0.000000  1.414214\n","246 -0.707107  1.414214  1.414214 -0.707107\n","228 -0.707107  1.414214 -1.414214  0.707107"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"23c4MQEV1C0k","executionInfo":{"elapsed":2018406,"status":"ok","timestamp":1611013053326,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"1d69d31d-c321-4d5b-b7a5-8cae059f5928"},"source":["y.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0_B</th>\n","      <th>0_L</th>\n","      <th>0_R</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>502</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>246</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     0_B  0_L  0_R\n","8      0    0    1\n","502    0    1    0\n","164    0    0    1\n","246    1    0    0\n","228    0    1    0"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tZHbSc260523","executionInfo":{"elapsed":2018398,"status":"ok","timestamp":1611013053327,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"99b8fe4d-db2a-407d-d53a-26add5cf5fd3"},"source":["y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(625, 3)"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"BFD0B8UF0yEW"},"source":["from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state= None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sbpKSII31NAx"},"source":["# Trying 10 fold: Balance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUtBN63N1Mfi","executionInfo":{"elapsed":6890744,"status":"ok","timestamp":1611017925683,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"fefc60ad-ce5b-4342-b9a1-1b813d19b40d"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","kFoldExperiment(X,y,5)\r\n","# kf = KFold(n_splits=10, shuffle=True, random_state=42)\r\n","# dl_loss_es=[]\r\n","# knn_loss_es = [] \r\n","# retrieval_loss_es = []\r\n","# retrieval_N_adapt_loss_es = []\r\n","# normal_cdh_loss_es = []\r\n","# retrieval_N_EAC_adapt_loss_es = []\r\n","\r\n","# bal_dl_loss_es=[]\r\n","# bal_knn_loss_es = [] \r\n","# bal_retrieval_loss_es = []\r\n","# bal_retrieval_N_adapt_loss_es = []\r\n","# bal_normal_cdh_loss_es = []\r\n","# bal_retrieval_N_EAC_adapt_loss_es = []\r\n","\r\n","# for train_index, test_index in kf.split(X):\r\n","#     # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n","#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n","#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n","\r\n","#     (dl_model, knn, adapt_models, cdh_knns, knn_by_class) = train_models(X_train,y_train,EAC_adapt,pair_selection, pair_knowledge, 0)\r\n","#     (dl_loss, knn_loss, retrieval_loss, retrieval_N_adapt_loss, normal_cdh_loss, retrieval_N_EAC_adapt_loss,\r\n","#      bal_dl_loss, bal_knn_loss, bal_retrieval_loss, bal_retrieval_N_adapt_loss, bal_normal_cdh_loss, bal_retrieval_N_EAC_adapt_loss) = test_models(X_test,y_test, EAC_adapt, dl_model, knn, adapt_models, cdh_knns, knn_by_class)\r\n","    \r\n","#     dl_loss_es.append(dl_loss)\r\n","#     knn_loss_es.append(knn_loss)\r\n","#     retrieval_loss_es.append(retrieval_loss)\r\n","#     retrieval_N_adapt_loss_es.append(retrieval_N_adapt_loss)\r\n","#     normal_cdh_loss_es.append(normal_cdh_loss)\r\n","#     retrieval_N_EAC_adapt_loss_es.append(retrieval_N_EAC_adapt_loss)\r\n","\r\n","#     bal_dl_loss_es.append(bal_dl_loss)\r\n","#     bal_knn_loss_es.append(bal_knn_loss)\r\n","#     bal_retrieval_loss_es.append(bal_retrieval_loss)\r\n","#     bal_retrieval_N_adapt_loss_es.append(bal_retrieval_N_adapt_loss)\r\n","#     bal_normal_cdh_loss_es.append(bal_normal_cdh_loss)\r\n","#     bal_retrieval_N_EAC_adapt_loss_es.append(bal_retrieval_N_EAC_adapt_loss)\r\n","# reportResults_kFold(\"average\", dl_loss_es,knn_loss_es, retrieval_loss_es,retrieval_N_adapt_loss_es, normal_cdh_loss_es, retrieval_N_EAC_adapt_loss_es)\r\n","# reportResults_kFold(\"balanced\", bal_dl_loss_es, bal_knn_loss_es, bal_retrieval_loss_es, \r\n","#                     bal_retrieval_N_adapt_loss_es, bal_normal_cdh_loss_es, bal_retrieval_N_EAC_adapt_loss_es)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.8461,  loss:0.4228,  val_accuracy:0.9317,  val_loss:0.2519,  \n",".........................................................................................adapt model (without source) last loss:  0.0005196684505790472\n","\n","Epoch: 0, accuracy:0.8412,  loss:0.4124,  val_accuracy:0.9126,  val_loss:0.2354,  \n","........................................................................................adapt model (with source) last loss:  0.00028704176656901836\n","\n","knn_loss 0.7936507936507936\n","retrieval_loss 0.746031746031746\n","adapt with source 0.9841269841269841\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8205,  loss:0.4649,  val_accuracy:0.9098,  val_loss:0.2581,  \n","..................................adapt model (without source) last loss:  0.006259358488023281\n","\n","Epoch: 0, accuracy:0.8336,  loss:0.4272,  val_accuracy:0.9235,  val_loss:0.2486,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..........................adapt model (with source) last loss:  8.329413503815886e-06\n","\n","knn_loss 0.7777777777777778\n","retrieval_loss 0.7301587301587301\n","adapt with source 0.9841269841269841\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8347,  loss:0.4238,  val_accuracy:0.8880,  val_loss:0.3096,  \n",".....................................................adapt model (without source) last loss:  0.0011973092332482338\n","\n","Epoch: 0, accuracy:0.8349,  loss:0.4241,  val_accuracy:0.9098,  val_loss:0.2451,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".................................................adapt model (with source) last loss:  2.5599925379538035e-07\n","\n","knn_loss 0.7936507936507936\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8356,  loss:0.4282,  val_accuracy:0.8989,  val_loss:0.2431,  \n","..........................................adapt model (without source) last loss:  0.015229016542434692\n","\n","Epoch: 0, accuracy:0.8182,  loss:0.4531,  val_accuracy:0.9235,  val_loss:0.2480,  \n","................................................................................................adapt model (with source) last loss:  1.886938298412133e-05\n","\n","knn_loss 0.7777777777777778\n","retrieval_loss 0.7936507936507936\n","adapt with source 0.9841269841269841\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8431,  loss:0.4130,  val_accuracy:0.9071,  val_loss:0.2676,  \n","...........................................................................adapt model (without source) last loss:  0.0005125171737745404\n","\n","Epoch: 0, accuracy:0.8323,  loss:0.4307,  val_accuracy:0.9153,  val_loss:0.2550,  \n","..............................................................adapt model (with source) last loss:  0.00047040279605425894\n","\n","knn_loss 0.8412698412698413\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8317,  loss:0.4333,  val_accuracy:0.9317,  val_loss:0.2103,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".............................................................adapt model (without source) last loss:  4.26677253528851e-08\n","\n","Epoch: 0, accuracy:0.8366,  loss:0.4222,  val_accuracy:0.9044,  val_loss:0.2666,  \n",".............................................................................................adapt model (with source) last loss:  0.0032035536132752895\n","\n","knn_loss 0.6935483870967742\n","retrieval_loss 0.7096774193548387\n","adapt with source 0.967741935483871\n","adapt without source 0.9838709677419355\n","\n","Epoch: 0, accuracy:0.8470,  loss:0.3957,  val_accuracy:0.9208,  val_loss:0.2475,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","...............................................adapt model (without source) last loss:  1.8689572243602015e-05\n","\n","Epoch: 0, accuracy:0.8360,  loss:0.4227,  val_accuracy:0.9016,  val_loss:0.2488,  \n","...............................................adapt model (with source) last loss:  0.0009511345997452736\n","\n","knn_loss 0.7741935483870968\n","retrieval_loss 0.8387096774193549\n","adapt with source 0.9838709677419355\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8152,  loss:0.4461,  val_accuracy:0.9016,  val_loss:0.2871,  \n","............................................adapt model (without source) last loss:  0.02109532058238983\n","\n","Epoch: 0, accuracy:0.8347,  loss:0.4293,  val_accuracy:0.8770,  val_loss:0.2947,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0002,  \n","................................................................................................adapt model (with source) last loss:  2.378481440246105e-06\n","\n","knn_loss 0.8548387096774194\n","retrieval_loss 0.8387096774193549\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8345,  loss:0.4195,  val_accuracy:0.9153,  val_loss:0.2451,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","...................adapt model (without source) last loss:  2.905220810589526e-07\n","\n","Epoch: 0, accuracy:0.8181,  loss:0.4581,  val_accuracy:0.8989,  val_loss:0.2455,  \n","..........................................adapt model (with source) last loss:  0.002725602127611637\n","\n","knn_loss 0.8225806451612904\n","retrieval_loss 0.8064516129032258\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8294,  loss:0.4409,  val_accuracy:0.9098,  val_loss:0.2720,  \n","..................................................................adapt model (without source) last loss:  0.0034661374520510435\n","\n","Epoch: 0, accuracy:0.8248,  loss:0.4414,  val_accuracy:0.8852,  val_loss:0.3163,  \n",".............................................................adapt model (with source) last loss:  0.0033064542803913355\n","\n","knn_loss 0.8387096774193549\n","retrieval_loss 0.8064516129032258\n","adapt with source 0.9838709677419355\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8278,  loss:0.4338,  val_accuracy:0.8661,  val_loss:0.3090,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","...............................................adapt model (without source) last loss:  3.496369345157291e-06\n","\n","Epoch: 0, accuracy:0.8254,  loss:0.4414,  val_accuracy:0.9262,  val_loss:0.2799,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","............adapt model (with source) last loss:  4.63755395685439e-06\n","\n","knn_loss 0.8412698412698413\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9841269841269841\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8422,  loss:0.4214,  val_accuracy:0.9044,  val_loss:0.2689,  \n","............................adapt model (without source) last loss:  0.01518572960048914\n","\n","Epoch: 0, accuracy:0.8225,  loss:0.4704,  val_accuracy:0.8689,  val_loss:0.2955,  \n","...................................................................adapt model (with source) last loss:  0.0007988986326381564\n","\n","knn_loss 0.7936507936507936\n","retrieval_loss 0.746031746031746\n","adapt with source 1.0\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8213,  loss:0.4557,  val_accuracy:0.9071,  val_loss:0.2577,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0005,  \n","..adapt model (without source) last loss:  0.0005797527846880257\n","\n","Epoch: 0, accuracy:0.8305,  loss:0.4412,  val_accuracy:0.8770,  val_loss:0.2871,  \n","..................................adapt model (with source) last loss:  0.008427116088569164\n","\n","knn_loss 0.7619047619047619\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9841269841269841\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8249,  loss:0.4470,  val_accuracy:0.9180,  val_loss:0.2667,  \n",".............................................................adapt model (without source) last loss:  0.0016878019087016582\n","\n","Epoch: 0, accuracy:0.8444,  loss:0.4063,  val_accuracy:0.9016,  val_loss:0.2619,  \n",".........................................................................adapt model (with source) last loss:  0.0012688774149864912\n","\n","knn_loss 0.7777777777777778\n","retrieval_loss 0.7936507936507936\n","adapt with source 0.9841269841269841\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8275,  loss:0.4305,  val_accuracy:0.8689,  val_loss:0.3056,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","................adapt model (without source) last loss:  7.608265946146275e-07\n","\n","Epoch: 0, accuracy:0.7996,  loss:0.4928,  val_accuracy:0.8579,  val_loss:0.3284,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".................adapt model (with source) last loss:  6.774677530074769e-08\n","\n","knn_loss 0.8095238095238095\n","retrieval_loss 0.8095238095238095\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8299,  loss:0.4293,  val_accuracy:0.8607,  val_loss:0.3229,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","...........................adapt model (without source) last loss:  1.5318545365516911e-06\n","\n","Epoch: 0, accuracy:0.8230,  loss:0.4388,  val_accuracy:0.8880,  val_loss:0.2903,  \n",".........................................................adapt model (with source) last loss:  0.0017283702036365867\n","\n","knn_loss 0.7580645161290323\n","retrieval_loss 0.8064516129032258\n","adapt with source 0.9354838709677419\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8310,  loss:0.4153,  val_accuracy:0.9290,  val_loss:0.2210,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","..adapt model (without source) last loss:  9.710716403787956e-05\n","\n","Epoch: 0, accuracy:0.8060,  loss:0.4867,  val_accuracy:0.8962,  val_loss:0.2730,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................adapt model (with source) last loss:  2.27995888835153e-09\n","\n","knn_loss 0.7903225806451613\n","retrieval_loss 0.7419354838709677\n","adapt with source 0.967741935483871\n","adapt without source 0.9516129032258065\n","\n","Epoch: 0, accuracy:0.8333,  loss:0.4297,  val_accuracy:0.9098,  val_loss:0.2413,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0005,  \n",".............adapt model (without source) last loss:  0.00024298936477862298\n","\n","Epoch: 0, accuracy:0.8375,  loss:0.4226,  val_accuracy:0.8962,  val_loss:0.2550,  \n","........................................................adapt model (with source) last loss:  0.0093833077698946\n","\n","knn_loss 0.7741935483870968\n","retrieval_loss 0.8064516129032258\n","adapt with source 0.967741935483871\n","adapt without source 0.9838709677419355\n","\n","Epoch: 0, accuracy:0.8386,  loss:0.4228,  val_accuracy:0.8798,  val_loss:0.2988,  \n",".........................................adapt model (without source) last loss:  0.0067057302221655846\n","\n","Epoch: 0, accuracy:0.8270,  loss:0.4524,  val_accuracy:0.8497,  val_loss:0.2930,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","...................................................adapt model (with source) last loss:  8.851880579641147e-07\n","\n","knn_loss 0.7096774193548387\n","retrieval_loss 0.7096774193548387\n","adapt with source 0.9838709677419355\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8303,  loss:0.4483,  val_accuracy:0.9372,  val_loss:0.2187,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..........................................................adapt model (without source) last loss:  4.55991777670306e-09\n","\n","Epoch: 0, accuracy:0.8303,  loss:0.4409,  val_accuracy:0.9208,  val_loss:0.2591,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..................................................adapt model (with source) last loss:  1.1688156519085169e-05\n","\n","knn_loss 0.7258064516129032\n","retrieval_loss 0.7741935483870968\n","adapt with source 0.967741935483871\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8081,  loss:0.4917,  val_accuracy:0.9126,  val_loss:0.2771,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..................................adapt model (without source) last loss:  3.719406436175632e-07\n","\n","Epoch: 0, accuracy:0.8267,  loss:0.4440,  val_accuracy:0.8989,  val_loss:0.2633,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n",".................................................adapt model (with source) last loss:  2.9444252504617907e-05\n","\n","knn_loss 0.7619047619047619\n","retrieval_loss 0.7619047619047619\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8383,  loss:0.4182,  val_accuracy:0.9098,  val_loss:0.2815,  \n","...................................................................adapt model (without source) last loss:  0.0035666609182953835\n","\n","Epoch: 0, accuracy:0.8269,  loss:0.4398,  val_accuracy:0.8962,  val_loss:0.3140,  \n",".......................................................adapt model (with source) last loss:  0.005163006950169802\n","\n","knn_loss 0.746031746031746\n","retrieval_loss 0.7777777777777778\n","adapt with source 0.9682539682539683\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8406,  loss:0.4167,  val_accuracy:0.9180,  val_loss:0.2654,  \n",".......................................adapt model (without source) last loss:  0.007825709879398346\n","\n","Epoch: 0, accuracy:0.8017,  loss:0.4823,  val_accuracy:0.9071,  val_loss:0.2767,  \n",".............................................................................adapt model (with source) last loss:  0.003966434858739376\n","\n","knn_loss 0.7936507936507936\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9841269841269841\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8457,  loss:0.3964,  val_accuracy:0.9481,  val_loss:0.2317,  \n","......................................adapt model (without source) last loss:  0.007924698293209076\n","\n","Epoch: 0, accuracy:0.8207,  loss:0.4519,  val_accuracy:0.9044,  val_loss:0.2535,  \n","..........................................................adapt model (with source) last loss:  0.001438312348909676\n","\n","knn_loss 0.746031746031746\n","retrieval_loss 0.7777777777777778\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8259,  loss:0.4375,  val_accuracy:0.9426,  val_loss:0.2313,  \n",".............................adapt model (without source) last loss:  0.025062914937734604\n","\n","Epoch: 0, accuracy:0.8246,  loss:0.4522,  val_accuracy:0.9044,  val_loss:0.2663,  \n","...............................................................................................adapt model (with source) last loss:  0.0003552003763616085\n","\n","knn_loss 0.7777777777777778\n","retrieval_loss 0.7619047619047619\n","adapt with source 0.9682539682539683\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8358,  loss:0.4169,  val_accuracy:0.8825,  val_loss:0.2959,  \n","...................................................................................................adapt model (without source) last loss:  0.004874387290328741\n","\n","Epoch: 0, accuracy:0.8260,  loss:0.4414,  val_accuracy:0.9016,  val_loss:0.2606,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".................adapt model (with source) last loss:  1.530828264151296e-08\n","\n","knn_loss 0.8709677419354839\n","retrieval_loss 0.7903225806451613\n","adapt with source 0.9838709677419355\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8320,  loss:0.4150,  val_accuracy:0.8743,  val_loss:0.2928,  \n","...........................................adapt model (without source) last loss:  0.011913759633898735\n","\n","Epoch: 0, accuracy:0.8172,  loss:0.4573,  val_accuracy:0.9180,  val_loss:0.2753,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".....................................................adapt model (with source) last loss:  2.443321818645927e-06\n","\n","knn_loss 0.8387096774193549\n","retrieval_loss 0.7741935483870968\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8324,  loss:0.4307,  val_accuracy:0.8989,  val_loss:0.2610,  \n","..................................................adapt model (without source) last loss:  0.008254659362137318\n","\n","Epoch: 0, accuracy:0.8110,  loss:0.4715,  val_accuracy:0.8579,  val_loss:0.3304,  \n","...............................................................................adapt model (with source) last loss:  0.0016164808766916394\n","\n","knn_loss 0.7580645161290323\n","retrieval_loss 0.6774193548387096\n","adapt with source 0.9838709677419355\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8432,  loss:0.4091,  val_accuracy:0.8907,  val_loss:0.2706,  \n",".............................................................adapt model (without source) last loss:  0.004733429756015539\n","\n","Epoch: 0, accuracy:0.8421,  loss:0.4034,  val_accuracy:0.9016,  val_loss:0.2594,  \n","......................................adapt model (with source) last loss:  0.009608471766114235\n","\n","knn_loss 0.7903225806451613\n","retrieval_loss 0.7258064516129032\n","adapt with source 0.9838709677419355\n","adapt without source 0.9838709677419355\n","\n","Epoch: 0, accuracy:0.8362,  loss:0.4169,  val_accuracy:0.8770,  val_loss:0.2887,  \n","..............................................adapt model (without source) last loss:  0.009502651169896126\n","\n","Epoch: 0, accuracy:0.8077,  loss:0.4783,  val_accuracy:0.8852,  val_loss:0.3032,  \n","................................................adapt model (with source) last loss:  0.007388438563793898\n","\n","knn_loss 0.7580645161290323\n","retrieval_loss 0.7580645161290323\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.7986,  loss:0.5123,  val_accuracy:0.8770,  val_loss:0.3000,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".....................................................................adapt model (without source) last loss:  3.381575652383617e-06\n","\n","Epoch: 0, accuracy:0.8203,  loss:0.4534,  val_accuracy:0.8907,  val_loss:0.2678,  \n",".................................adapt model (with source) last loss:  0.022490710020065308\n","\n","knn_loss 0.7301587301587301\n","retrieval_loss 0.6507936507936508\n","adapt with source 0.9682539682539683\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8424,  loss:0.4044,  val_accuracy:0.9481,  val_loss:0.1960,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","...........................................................adapt model (without source) last loss:  0.00023588532349094748\n","\n","Epoch: 0, accuracy:0.8327,  loss:0.4247,  val_accuracy:0.9180,  val_loss:0.2419,  \n",".....................................................................adapt model (with source) last loss:  0.0009243530803360045\n","\n","knn_loss 0.6825396825396826\n","retrieval_loss 0.6825396825396826\n","adapt with source 1.0\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8281,  loss:0.4337,  val_accuracy:0.9235,  val_loss:0.2261,  \n",".....................................................adapt model (without source) last loss:  0.007054472807794809\n","\n","Epoch: 0, accuracy:0.8366,  loss:0.4193,  val_accuracy:0.8907,  val_loss:0.2528,  \n","...................................adapt model (with source) last loss:  0.009168894030153751\n","\n","knn_loss 0.7619047619047619\n","retrieval_loss 0.746031746031746\n","adapt with source 0.9841269841269841\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8288,  loss:0.4444,  val_accuracy:0.8716,  val_loss:0.3187,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0002,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".....adapt model (without source) last loss:  4.103584160475293e-06\n","\n","Epoch: 0, accuracy:0.8465,  loss:0.4102,  val_accuracy:0.8934,  val_loss:0.2715,  \n","..................................................................................adapt model (with source) last loss:  2.697089803405106e-05\n","\n","knn_loss 0.8095238095238095\n","retrieval_loss 0.8253968253968254\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8105,  loss:0.4812,  val_accuracy:0.9016,  val_loss:0.2618,  \n","..........................................................adapt model (without source) last loss:  0.0032658290583640337\n","\n","Epoch: 0, accuracy:0.8287,  loss:0.4370,  val_accuracy:0.8415,  val_loss:0.3390,  \n","......................................adapt model (with source) last loss:  0.012898240238428116\n","\n","knn_loss 0.8412698412698413\n","retrieval_loss 0.8412698412698413\n","adapt with source 0.9841269841269841\n","adapt without source 0.9841269841269841\n","\n","Epoch: 0, accuracy:0.8265,  loss:0.4481,  val_accuracy:0.9071,  val_loss:0.2704,  \n",".............................................................adapt model (without source) last loss:  0.0028933645226061344\n","\n","Epoch: 0, accuracy:0.8114,  loss:0.4680,  val_accuracy:0.9153,  val_loss:0.2620,  \n","........................................adapt model (with source) last loss:  0.005254141520708799\n","\n","knn_loss 0.8548387096774194\n","retrieval_loss 0.7903225806451613\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8145,  loss:0.4585,  val_accuracy:0.8716,  val_loss:0.3254,  \n",".......................................................adapt model (without source) last loss:  0.00028458813903853297\n","\n","Epoch: 0, accuracy:0.8222,  loss:0.4596,  val_accuracy:0.9071,  val_loss:0.2866,  \n","....................................................................adapt model (with source) last loss:  0.00040307739982381463\n","\n","knn_loss 0.8225806451612904\n","retrieval_loss 0.7580645161290323\n","adapt with source 0.9838709677419355\n","adapt without source 0.9838709677419355\n","\n","Epoch: 0, accuracy:0.8431,  loss:0.4033,  val_accuracy:0.9153,  val_loss:0.2225,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..................................................................................adapt model (without source) last loss:  1.801140854240657e-07\n","\n","Epoch: 0, accuracy:0.8169,  loss:0.4687,  val_accuracy:0.8880,  val_loss:0.2984,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0008,  \n",".............................................................................adapt model (with source) last loss:  2.5844379706541076e-05\n","\n","knn_loss 0.8064516129032258\n","retrieval_loss 0.7903225806451613\n","adapt with source 0.9838709677419355\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8258,  loss:0.4494,  val_accuracy:0.8852,  val_loss:0.2813,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n",".......................................................adapt model (without source) last loss:  1.4675608326797374e-05\n","\n","Epoch: 0, accuracy:0.8316,  loss:0.4311,  val_accuracy:0.9153,  val_loss:0.2529,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".......................................adapt model (with source) last loss:  2.651228498962155e-07\n","\n","knn_loss 0.7580645161290323\n","retrieval_loss 0.7419354838709677\n","adapt with source 0.967741935483871\n","adapt without source 0.9516129032258065\n","\n","Epoch: 0, accuracy:0.8442,  loss:0.4117,  val_accuracy:0.8415,  val_loss:0.3036,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".............................................................................adapt model (without source) last loss:  2.9964579084662546e-07\n","\n","Epoch: 0, accuracy:0.8235,  loss:0.4488,  val_accuracy:0.9153,  val_loss:0.2523,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","........................adapt model (with source) last loss:  3.155976742164057e-07\n","\n","knn_loss 0.7419354838709677\n","retrieval_loss 0.7419354838709677\n","adapt with source 0.9516129032258065\n","adapt without source 0.9516129032258065\n","\n","Epoch: 0, accuracy:0.8354,  loss:0.4167,  val_accuracy:0.9016,  val_loss:0.2572,  \n","....................................................................................................adapt model (without source) last loss:  0.0010671969503164291\n","\n","Epoch: 0, accuracy:0.8320,  loss:0.4216,  val_accuracy:0.8907,  val_loss:0.3122,  \n","..........................................adapt model (with source) last loss:  0.006506298203021288\n","\n","knn_loss 0.7619047619047619\n","retrieval_loss 0.7619047619047619\n","adapt with source 0.9841269841269841\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8414,  loss:0.4126,  val_accuracy:0.9208,  val_loss:0.2317,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","........................................................adapt model (without source) last loss:  7.181233172559587e-07\n","\n","Epoch: 0, accuracy:0.8373,  loss:0.4256,  val_accuracy:0.8852,  val_loss:0.2656,  \n","..................................................................................................adapt model (with source) last loss:  0.006948351860046387\n","\n","knn_loss 0.7619047619047619\n","retrieval_loss 0.7619047619047619\n","adapt with source 0.9682539682539683\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8497,  loss:0.4058,  val_accuracy:0.9071,  val_loss:0.2430,  \n",".........................................................................adapt model (without source) last loss:  0.0014221260789781809\n","\n","Epoch: 0, accuracy:0.8225,  loss:0.4409,  val_accuracy:0.8798,  val_loss:0.2597,  \n","........................................................................................adapt model (with source) last loss:  6.984447099966928e-05\n","\n","knn_loss 0.6984126984126984\n","retrieval_loss 0.6825396825396826\n","adapt with source 0.9523809523809523\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8244,  loss:0.4367,  val_accuracy:0.8689,  val_loss:0.3073,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","............adapt model (without source) last loss:  5.748274247707741e-07\n","\n","Epoch: 0, accuracy:0.8114,  loss:0.4745,  val_accuracy:0.8880,  val_loss:0.3078,  \n","...................................................................................adapt model (with source) last loss:  0.0002293295692652464\n","\n","knn_loss 0.8253968253968254\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9841269841269841\n","adapt without source 0.9682539682539683\n","\n","Epoch: 0, accuracy:0.8197,  loss:0.4459,  val_accuracy:0.8934,  val_loss:0.2739,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n",".........adapt model (without source) last loss:  0.010226120240986347\n","\n","Epoch: 0, accuracy:0.8131,  loss:0.4603,  val_accuracy:0.8689,  val_loss:0.2760,  \n","...............................................adapt model (with source) last loss:  0.0028261712286621332\n","\n","knn_loss 0.7777777777777778\n","retrieval_loss 0.7619047619047619\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8309,  loss:0.4439,  val_accuracy:0.9071,  val_loss:0.2484,  \n",".................................................................................adapt model (without source) last loss:  0.000977807561866939\n","\n","Epoch: 0, accuracy:0.8139,  loss:0.4670,  val_accuracy:0.9044,  val_loss:0.3067,  \n","...........................................................................adapt model (with source) last loss:  0.0013002456398680806\n","\n","knn_loss 0.7741935483870968\n","retrieval_loss 0.7903225806451613\n","adapt with source 0.967741935483871\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8310,  loss:0.4266,  val_accuracy:0.9153,  val_loss:0.2392,  \n","........................................................................adapt model (without source) last loss:  0.0009156749001704156\n","\n","Epoch: 0, accuracy:0.8396,  loss:0.4148,  val_accuracy:0.9126,  val_loss:0.2613,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".......................adapt model (with source) last loss:  9.166014933725819e-06\n","\n","knn_loss 0.8064516129032258\n","retrieval_loss 0.7741935483870968\n","adapt with source 0.967741935483871\n","adapt without source 0.967741935483871\n","\n","Epoch: 0, accuracy:0.8125,  loss:0.4631,  val_accuracy:0.9208,  val_loss:0.2804,  \n","...........................................adapt model (without source) last loss:  0.012241674587130547\n","\n","Epoch: 0, accuracy:0.7844,  loss:0.5244,  val_accuracy:0.8907,  val_loss:0.3090,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................adapt model (with source) last loss:  6.533021519317117e-07\n","\n","knn_loss 0.8387096774193549\n","retrieval_loss 0.8548387096774194\n","adapt with source 0.967741935483871\n","adapt without source 0.9838709677419355\n","\n","Epoch: 0, accuracy:0.8024,  loss:0.4823,  val_accuracy:0.9044,  val_loss:0.2540,  \n",".........................................adapt model (without source) last loss:  0.01303893607109785\n","\n","Epoch: 0, accuracy:0.8207,  loss:0.4427,  val_accuracy:0.9071,  val_loss:0.2681,  \n","............................................................adapt model (with source) last loss:  0.008397931233048439\n","\n","knn_loss 0.7580645161290323\n","retrieval_loss 0.7580645161290323\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8171,  loss:0.4494,  val_accuracy:0.9016,  val_loss:0.2730,  \n","........................................................................adapt model (without source) last loss:  0.0016904723597690463\n","\n","Epoch: 0, accuracy:0.8455,  loss:0.4025,  val_accuracy:0.8825,  val_loss:0.2923,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0003,  \n","........adapt model (with source) last loss:  6.824859883636236e-05\n","\n","knn_loss 0.7903225806451613\n","retrieval_loss 0.8064516129032258\n","adapt with source 0.967741935483871\n","adapt without source 1.0\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.7830824372759857\n","np.mean(retrieval_loss_es) =  0.7728161802355351\n","np.mean(without_source_loss_es) =  0.9792217101894523\n","np.mean(with_source_loss_es) =  0.9785611879160265\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.042992950988940334\n","np.std(retrieval_loss_es) =  0.044419274859155575\n","np.std(without_source_loss_es) =  0.01698825346387991\n","np.std(with_source_loss_es) =  0.01619228731198973\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.5670324023216132\n","np.mean(retrieval_loss_es) =  0.5597474026155743\n","np.mean(without_source_loss_es) =  0.9650711935963369\n","np.mean(with_source_loss_es) =  0.965703475734754\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.028379529991084753\n","np.std(retrieval_loss_es) =  0.028264891273725726\n","np.std(without_source_loss_es) =  0.03736830721868779\n","np.std(with_source_loss_es) =  0.03435014647369677\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U8e_Dj7NKNer"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.7830824372759857\r\n","np.mean(retrieval_loss_es) =  0.7728161802355351\r\n","np.mean(without_source_loss_es) =  0.9792217101894523\r\n","np.mean(with_source_loss_es) =  0.9785611879160265\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.042992950988940334\r\n","np.std(retrieval_loss_es) =  0.044419274859155575\r\n","np.std(without_source_loss_es) =  0.01698825346387991\r\n","np.std(with_source_loss_es) =  0.01619228731198973\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.5670324023216132\r\n","np.mean(retrieval_loss_es) =  0.5597474026155743\r\n","np.mean(without_source_loss_es) =  0.9650711935963369\r\n","np.mean(with_source_loss_es) =  0.965703475734754\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.028379529991084753\r\n","np.std(retrieval_loss_es) =  0.028264891273725726\r\n","np.std(without_source_loss_es) =  0.03736830721868779\r\n","np.std(with_source_loss_es) =  0.03435014647369677\r\n","```\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kj3Ih8_jtJQZ","executionInfo":{"elapsed":6890737,"status":"ok","timestamp":1611017925684,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"e41f6630-7158-49be-b0ce-ce0d47ea11ee"},"source":["np.std([1.0, 0.9206349206349206, 0.9841269841269841, 1.0, 0.9841269841269841, 0.967741935483871, 0.967741935483871, 0.9838709677419355, 0.9838709677419355, 1.0]\r\n",")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.022544506902824456"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"2IufTphWCTHP"},"source":["\r\n","```\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = 1\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = 124\r\n","random_pairs_count = 100\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9729390681003585\r\n","np.mean(arr_knn) =  0.7889400921658986\r\n","np.mean(arr_retrieval_loss) =  0.7856118791602663\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.8959549411162314\r\n","np.mean(arr_normal_cdh_loss) =  0.7888888888888889\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9232206861239117\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9469392463604986\r\n","np.mean(arr_knn) =  0.57911306672938\r\n","np.mean(arr_retrieval_loss) =  0.5713817031277086\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.774252877344564\r\n","np.mean(arr_normal_cdh_loss) =  0.6273414474125498\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.8021367288833943\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"OEF94NU8oTVh"},"source":["Using more pairs produces a lot better result\r\n","\r\n","```\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"1\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"124\"\r\n","random_pairs_count = 6000\r\n","\r\n","dl_loss 1.0\r\n","knn_loss 0.7580645161290323\r\n","retrieval_loss 0.7580645161290323\r\n","retrieval_N_adapt_loss 0.9838709677419355\r\n","CBR normal CDH loss 0.7258064516129032\r\n","retrieval_N_EAC_adapt_loss loss 0.9838709677419355\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9776241679467486\r\n","np.mean(arr_knn) =  0.7968509984639016\r\n","np.mean(arr_retrieval_loss) =  0.7633640552995391\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9760112647209421\r\n","np.mean(arr_normal_cdh_loss) =  0.7808499743983615\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9759856630824373\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  -1.0\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9546992387101767\r\n","np.mean(arr_knn) =  0.5762784229508773\r\n","np.mean(arr_retrieval_loss) =  0.5512892255629526\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9744648511841227\r\n","np.mean(arr_normal_cdh_loss) =  0.6132406730544281\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9588398511841227\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  -1.0\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"ebtpmDpTH04_"},"source":["\r\n","\r\n","```\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9712237583205325\r\n","np.mean(arr_knn) =  0.7870967741935484\r\n","np.mean(arr_retrieval_loss) =  0.7790322580645161\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.969636456733231\r\n","np.mean(arr_normal_cdh_loss) =  0.6608550947260625\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9744239631336405\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.967741935483871\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.937722595627719\r\n","np.mean(arr_knn) =  0.5676574856948584\r\n","np.mean(arr_retrieval_loss) =  0.5616761381193102\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9574465246258415\r\n","np.mean(arr_normal_cdh_loss) =  0.5422665812453158\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9662637289269167\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9765873015873017\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"9apSHSZx8txT"},"source":["Using STD with multi runs\r\n","\r\n","\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9737532002048133\r\n","np.mean(arr_knn) =  0.7964925755248334\r\n","np.mean(arr_retrieval_loss) =  0.7769943676395289\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9763184843830007\r\n","np.mean(arr_normal_cdh_loss) =  0.6561546338965694\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9737685611879161\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9516129032258065\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.01971400906942525\r\n","np.std(arr_knn) =  0.051138111374122844\r\n","np.std(arr_retrieval_loss) =  0.05455483683696814\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.017609107718912546\r\n","np.std(arr_normal_cdh_loss) =  0.05414928499979276\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.01859286877318543\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.0\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9591936439458675\r\n","np.mean(arr_knn) =  0.57784063014861\r\n","np.mean(arr_retrieval_loss) =  0.5630270785334525\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9663559535837376\r\n","np.mean(arr_normal_cdh_loss) =  0.5497414496609297\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9639199490045327\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9043478260869565\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.04885578713837359\r\n","np.std(arr_knn) =  0.026486130761340414\r\n","np.std(arr_retrieval_loss) =  0.02865470426646368\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.045669393639572925\r\n","np.std(arr_normal_cdh_loss) =  0.08541824772469106\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.046519168993125026\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.0\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"dqgRCpA_XExu"},"source":["# Dataset: Car"]},{"cell_type":"markdown","metadata":{"id":"-Vm2mG65XNWl"},"source":["https://archive.ics.uci.edu/ml/datasets/car+evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XfRbf7CXReb","executionInfo":{"elapsed":6891774,"status":"ok","timestamp":1611017926730,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"09fc944f-5869-4c40-fbc4-9bdeb29d58ca"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/car.data'\r\n","nominalCols = [0,1,2,3,4,5] \r\n","numericCols = []\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,));\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(6,));\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False)\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    \r\n","    # X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5]\n","Index: []\n","0_high     0\n","0_low      0\n","0_med      0\n","0_vhigh    0\n","1_high     0\n","1_low      0\n","1_med      0\n","1_vhigh    0\n","2_2        0\n","2_3        0\n","2_4        0\n","2_5more    0\n","3_2        0\n","3_4        0\n","3_more     0\n","4_big      0\n","4_med      0\n","4_small    0\n","5_high     0\n","5_low      0\n","5_med      0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RIEBkBbIk5u","executionInfo":{"elapsed":6891767,"status":"ok","timestamp":1611017926731,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"062aba05-0a05-4940-e187-b75dd541f0dd"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1728, 21)"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"Owq_3qnxYjmq"},"source":["# Trying 10 fold: Car"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mpzk8WTuYoDT","executionInfo":{"elapsed":16088903,"status":"ok","timestamp":1611027123874,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"02dfb28b-d12b-4b7a-daf1-19e311cc910e"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,5)\r\n","\r\n","# kf = KFold(n_splits=10, shuffle=True, random_state=42)\r\n","# dl_loss_es=[]\r\n","# knn_loss_es = [] \r\n","# retrieval_loss_es = []\r\n","# retrieval_N_adapt_loss_es = []\r\n","# normal_cdh_loss_es = []\r\n","# retrieval_N_EAC_adapt_loss_es = []\r\n","\r\n","# bal_dl_loss_es=[]\r\n","# bal_knn_loss_es = [] \r\n","# bal_retrieval_loss_es = []\r\n","# bal_retrieval_N_adapt_loss_es = []\r\n","# bal_normal_cdh_loss_es = []\r\n","# bal_retrieval_N_EAC_adapt_loss_es = []\r\n","\r\n","# for train_index, test_index in kf.split(X):\r\n","#     # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\r\n","#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\r\n","#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\r\n","\r\n","#     (dl_model, knn, adapt_models, cdh_knns, knn_by_class) = train_models(X_train,y_train,EAC_adapt,pair_selection, pair_knowledge, 0)\r\n","#     (dl_loss, knn_loss, retrieval_loss, retrieval_N_adapt_loss, normal_cdh_loss, retrieval_N_EAC_adapt_loss,\r\n","#      bal_dl_loss, bal_knn_loss, bal_retrieval_loss, bal_retrieval_N_adapt_loss, bal_normal_cdh_loss, bal_retrieval_N_EAC_adapt_loss) = test_models(X_test,y_test, EAC_adapt, dl_model, knn, adapt_models, cdh_knns, knn_by_class)\r\n","    \r\n","#     dl_loss_es.append(dl_loss)\r\n","#     knn_loss_es.append(knn_loss)\r\n","#     retrieval_loss_es.append(retrieval_loss)\r\n","#     retrieval_N_adapt_loss_es.append(retrieval_N_adapt_loss)\r\n","#     normal_cdh_loss_es.append(normal_cdh_loss)\r\n","#     retrieval_N_EAC_adapt_loss_es.append(retrieval_N_EAC_adapt_loss)\r\n","\r\n","#     bal_dl_loss_es.append(bal_dl_loss)\r\n","#     bal_knn_loss_es.append(bal_knn_loss)\r\n","#     bal_retrieval_loss_es.append(bal_retrieval_loss)\r\n","#     bal_retrieval_N_adapt_loss_es.append(bal_retrieval_N_adapt_loss)\r\n","#     bal_normal_cdh_loss_es.append(bal_normal_cdh_loss)\r\n","#     bal_retrieval_N_EAC_adapt_loss_es.append(bal_retrieval_N_EAC_adapt_loss)\r\n","# reportResults_kFold(\"average\", dl_loss_es,knn_loss_es, retrieval_loss_es,retrieval_N_adapt_loss_es, normal_cdh_loss_es, retrieval_N_EAC_adapt_loss_es)\r\n","# reportResults_kFold(\"balanced\", bal_dl_loss_es, bal_knn_loss_es, bal_retrieval_loss_es, \r\n","#                     bal_retrieval_N_adapt_loss_es, bal_normal_cdh_loss_es, bal_retrieval_N_EAC_adapt_loss_es)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.8909,  loss:0.2900,  val_accuracy:0.9761,  val_loss:0.0853,  \n","......................................................................adapt model (without source) last loss:  2.881051557324099e-07\n","\n","Epoch: 0, accuracy:0.8881,  loss:0.2975,  val_accuracy:0.9679,  val_loss:0.1041,  \n","....................................................................adapt model (with source) last loss:  7.5409548117022496e-06\n","\n","knn_loss 0.8265895953757225\n","retrieval_loss 0.7687861271676301\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8931,  loss:0.2884,  val_accuracy:0.9780,  val_loss:0.0821,  \n","................................................................adapt model (without source) last loss:  1.5682760931667872e-05\n","\n","Epoch: 0, accuracy:0.8888,  loss:0.2943,  val_accuracy:0.9624,  val_loss:0.1011,  \n","........................................................................adapt model (with source) last loss:  2.567428964539431e-06\n","\n","knn_loss 0.8728323699421965\n","retrieval_loss 0.8034682080924855\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8909,  loss:0.2951,  val_accuracy:0.9688,  val_loss:0.0969,  \n",".........................................................................adapt model (without source) last loss:  2.7216288799536414e-05\n","\n","Epoch: 0, accuracy:0.8906,  loss:0.2962,  val_accuracy:0.9752,  val_loss:0.0833,  \n",".......................................................adapt model (with source) last loss:  7.115336320140386e-09\n","\n","knn_loss 0.8786127167630058\n","retrieval_loss 0.8439306358381503\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8849,  loss:0.3096,  val_accuracy:0.9780,  val_loss:0.0838,  \n","..........................................................adapt model (without source) last loss:  4.269202324991284e-09\n","\n","Epoch: 0, accuracy:0.8884,  loss:0.2991,  val_accuracy:0.9780,  val_loss:0.0856,  \n","..................................................................adapt model (with source) last loss:  2.9109996830811724e-06\n","\n","knn_loss 0.7803468208092486\n","retrieval_loss 0.7687861271676301\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8871,  loss:0.2959,  val_accuracy:0.9706,  val_loss:0.0970,  \n","....................................................................adapt model (without source) last loss:  2.7524520191946067e-06\n","\n","Epoch: 0, accuracy:0.8893,  loss:0.2927,  val_accuracy:0.9734,  val_loss:0.0949,  \n",".............................................................adapt model (with source) last loss:  1.9375580251335123e-08\n","\n","knn_loss 0.8265895953757225\n","retrieval_loss 0.7630057803468208\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8899,  loss:0.2995,  val_accuracy:0.9624,  val_loss:0.1076,  \n",".....................................................................adapt model (without source) last loss:  3.5991570257465355e-07\n","\n","Epoch: 0, accuracy:0.8943,  loss:0.2927,  val_accuracy:0.9725,  val_loss:0.0928,  \n",".................................................................adapt model (with source) last loss:  1.0137898243556265e-05\n","\n","knn_loss 0.861271676300578\n","retrieval_loss 0.8323699421965318\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8967,  loss:0.2888,  val_accuracy:0.9835,  val_loss:0.0806,  \n","........................................................adapt model (without source) last loss:  6.58284334349446e-05\n","\n","Epoch: 0, accuracy:0.8887,  loss:0.3008,  val_accuracy:0.9679,  val_loss:0.1013,  \n","......................................................................adapt model (with source) last loss:  4.119953302961221e-07\n","\n","knn_loss 0.8554913294797688\n","retrieval_loss 0.8323699421965318\n","adapt with source 0.9942196531791907\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8804,  loss:0.3166,  val_accuracy:0.9669,  val_loss:0.1078,  \n","........................................................................adapt model (without source) last loss:  2.9826429454260506e-05\n","\n","Epoch: 0, accuracy:0.8805,  loss:0.3119,  val_accuracy:0.9743,  val_loss:0.0876,  \n",".............................................................adapt model (with source) last loss:  5.3638689045953925e-09\n","\n","knn_loss 0.861271676300578\n","retrieval_loss 0.8208092485549133\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8880,  loss:0.2943,  val_accuracy:0.9734,  val_loss:0.0899,  \n","...............................................................adapt model (without source) last loss:  1.2905215562852845e-08\n","\n","Epoch: 0, accuracy:0.8979,  loss:0.2732,  val_accuracy:0.9780,  val_loss:0.0822,  \n",".................................................................adapt model (with source) last loss:  4.147999845827144e-07\n","\n","knn_loss 0.8023255813953488\n","retrieval_loss 0.6976744186046512\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8946,  loss:0.2890,  val_accuracy:0.9661,  val_loss:0.0978,  \n","........................................................................adapt model (without source) last loss:  3.6504982290352928e-06\n","\n","Epoch: 0, accuracy:0.8831,  loss:0.3096,  val_accuracy:0.9633,  val_loss:0.1177,  \n","....................................................................adapt model (with source) last loss:  1.4840767107671127e-05\n","\n","knn_loss 0.8372093023255814\n","retrieval_loss 0.7965116279069767\n","adapt with source 1.0\n","adapt without source 0.9941860465116279\n","\n","Epoch: 0, accuracy:0.9010,  loss:0.2688,  val_accuracy:0.9715,  val_loss:0.0924,  \n","...................................................................adapt model (without source) last loss:  2.8789635564407945e-08\n","\n","Epoch: 0, accuracy:0.8961,  loss:0.2753,  val_accuracy:0.9789,  val_loss:0.0786,  \n",".................................................................adapt model (with source) last loss:  3.258793867644272e-06\n","\n","knn_loss 0.815028901734104\n","retrieval_loss 0.7167630057803468\n","adapt with source 0.9942196531791907\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8969,  loss:0.2813,  val_accuracy:0.9752,  val_loss:0.0930,  \n","......................................................................adapt model (without source) last loss:  3.46883666679787e-07\n","\n","Epoch: 0, accuracy:0.8826,  loss:0.3102,  val_accuracy:0.9734,  val_loss:0.1014,  \n",".........................................................adapt model (with source) last loss:  2.8680114283474722e-08\n","\n","knn_loss 0.7976878612716763\n","retrieval_loss 0.7803468208092486\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8933,  loss:0.2925,  val_accuracy:0.9835,  val_loss:0.0729,  \n","..............................................................adapt model (without source) last loss:  1.4766611684535746e-06\n","\n","Epoch: 0, accuracy:0.8939,  loss:0.2923,  val_accuracy:0.9734,  val_loss:0.0909,  \n",".................................................................adapt model (with source) last loss:  2.984181037390954e-06\n","\n","knn_loss 0.8959537572254336\n","retrieval_loss 0.815028901734104\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8913,  loss:0.2924,  val_accuracy:0.9688,  val_loss:0.0956,  \n","...........................................................................adapt model (without source) last loss:  3.382627255632542e-05\n","\n","Epoch: 0, accuracy:0.8902,  loss:0.2965,  val_accuracy:0.9605,  val_loss:0.1069,  \n","...................................................................adapt model (with source) last loss:  4.340167834016029e-07\n","\n","knn_loss 0.8439306358381503\n","retrieval_loss 0.7803468208092486\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8964,  loss:0.2790,  val_accuracy:0.9642,  val_loss:0.0853,  \n","........................................................................adapt model (without source) last loss:  2.6505977075430565e-06\n","\n","Epoch: 0, accuracy:0.8871,  loss:0.3009,  val_accuracy:0.9743,  val_loss:0.0846,  \n",".................................................................adapt model (with source) last loss:  2.243777316834894e-06\n","\n","knn_loss 0.791907514450867\n","retrieval_loss 0.7398843930635838\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8913,  loss:0.2936,  val_accuracy:0.9725,  val_loss:0.0866,  \n","...................................................................adapt model (without source) last loss:  5.317489808476239e-07\n","\n","Epoch: 0, accuracy:0.8877,  loss:0.3021,  val_accuracy:0.9633,  val_loss:0.1058,  \n","......................................................................adapt model (with source) last loss:  1.1106204738098313e-06\n","\n","knn_loss 0.8497109826589595\n","retrieval_loss 0.7976878612716763\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8833,  loss:0.3159,  val_accuracy:0.9688,  val_loss:0.0904,  \n","..................................................................adapt model (without source) last loss:  9.698994836071506e-05\n","\n","Epoch: 0, accuracy:0.8842,  loss:0.3011,  val_accuracy:0.9807,  val_loss:0.0727,  \n",".....................................................................adapt model (with source) last loss:  5.8236189204308175e-08\n","\n","knn_loss 0.815028901734104\n","retrieval_loss 0.7630057803468208\n","adapt with source 0.9942196531791907\n","adapt without source 0.9884393063583815\n","\n","Epoch: 0, accuracy:0.8972,  loss:0.2852,  val_accuracy:0.9826,  val_loss:0.0809,  \n","...........................................................................adapt model (without source) last loss:  6.215725989022758e-06\n","\n","Epoch: 0, accuracy:0.8877,  loss:0.3002,  val_accuracy:0.9706,  val_loss:0.0943,  \n","...............................................................adapt model (with source) last loss:  9.216710594728283e-08\n","\n","knn_loss 0.8265895953757225\n","retrieval_loss 0.7687861271676301\n","adapt with source 1.0\n","adapt without source 0.9942196531791907\n","\n","Epoch: 0, accuracy:0.8932,  loss:0.2810,  val_accuracy:0.9752,  val_loss:0.0906,  \n","....................................................................adapt model (without source) last loss:  1.326812366642116e-06\n","\n","Epoch: 0, accuracy:0.8847,  loss:0.3107,  val_accuracy:0.9716,  val_loss:0.0967,  \n","....................................................................adapt model (with source) last loss:  9.213048883793817e-07\n","\n","knn_loss 0.8197674418604651\n","retrieval_loss 0.7209302325581395\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.9045,  loss:0.2638,  val_accuracy:0.9789,  val_loss:0.0792,  \n","...................................................................adapt model (without source) last loss:  6.328367589958361e-07\n","\n","Epoch: 0, accuracy:0.9008,  loss:0.2751,  val_accuracy:0.9734,  val_loss:0.0854,  \n","......................................................................adapt model (with source) last loss:  1.0710440392358578e-06\n","\n","knn_loss 0.8604651162790697\n","retrieval_loss 0.7674418604651163\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8960,  loss:0.2805,  val_accuracy:0.9798,  val_loss:0.0779,  \n",".........................................................................adapt model (without source) last loss:  1.173867872239498e-06\n","\n","Epoch: 0, accuracy:0.8986,  loss:0.2845,  val_accuracy:0.9679,  val_loss:0.0965,  \n","...............................................................adapt model (with source) last loss:  9.364364814246073e-05\n","\n","knn_loss 0.7572254335260116\n","retrieval_loss 0.7341040462427746\n","adapt with source 0.9942196531791907\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8988,  loss:0.2771,  val_accuracy:0.9789,  val_loss:0.0847,  \n","..............................................................adapt model (without source) last loss:  8.067370799835771e-06\n","\n","Epoch: 0, accuracy:0.9098,  loss:0.2513,  val_accuracy:0.9715,  val_loss:0.0900,  \n","..................................................................adapt model (with source) last loss:  8.45080165845502e-08\n","\n","knn_loss 0.8554913294797688\n","retrieval_loss 0.7398843930635838\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8914,  loss:0.2951,  val_accuracy:0.9715,  val_loss:0.0943,  \n","................................................................adapt model (without source) last loss:  2.0251318844088928e-08\n","\n","Epoch: 0, accuracy:0.8914,  loss:0.3001,  val_accuracy:0.9807,  val_loss:0.0818,  \n",".....................................................................adapt model (with source) last loss:  1.552376306790393e-05\n","\n","knn_loss 0.815028901734104\n","retrieval_loss 0.7745664739884393\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8794,  loss:0.3165,  val_accuracy:0.9734,  val_loss:0.0868,  \n",".......................................................................adapt model (without source) last loss:  0.0002190258528571576\n","\n","Epoch: 0, accuracy:0.8936,  loss:0.2817,  val_accuracy:0.9835,  val_loss:0.0748,  \n",".....................................................................adapt model (with source) last loss:  2.126894713683214e-07\n","\n","knn_loss 0.8497109826589595\n","retrieval_loss 0.7976878612716763\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.9003,  loss:0.2704,  val_accuracy:0.9752,  val_loss:0.0822,  \n","..........................................................adapt model (without source) last loss:  6.0206697405362775e-09\n","\n","Epoch: 0, accuracy:0.8838,  loss:0.3086,  val_accuracy:0.9715,  val_loss:0.0921,  \n","............................................................adapt model (with source) last loss:  1.7295713305998106e-08\n","\n","knn_loss 0.8265895953757225\n","retrieval_loss 0.7167630057803468\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8872,  loss:0.2984,  val_accuracy:0.9752,  val_loss:0.0845,  \n","....................................................................adapt model (without source) last loss:  1.1869676654896466e-06\n","\n","Epoch: 0, accuracy:0.9006,  loss:0.2748,  val_accuracy:0.9761,  val_loss:0.0834,  \n","..............................................................adapt model (with source) last loss:  1.946273329167525e-07\n","\n","knn_loss 0.8439306358381503\n","retrieval_loss 0.7630057803468208\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8877,  loss:0.3012,  val_accuracy:0.9614,  val_loss:0.1158,  \n","............................................................adapt model (without source) last loss:  1.4340134413259875e-08\n","\n","Epoch: 0, accuracy:0.8943,  loss:0.2802,  val_accuracy:0.9780,  val_loss:0.0815,  \n",".......................................................................adapt model (with source) last loss:  5.950203672000498e-07\n","\n","knn_loss 0.8208092485549133\n","retrieval_loss 0.7630057803468208\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8841,  loss:0.3034,  val_accuracy:0.9697,  val_loss:0.0926,  \n","...................................................................adapt model (without source) last loss:  3.2120838113769423e-06\n","\n","Epoch: 0, accuracy:0.8873,  loss:0.2973,  val_accuracy:0.9614,  val_loss:0.1073,  \n",".....................................................adapt model (with source) last loss:  4.2253738286035514e-08\n","\n","knn_loss 0.861271676300578\n","retrieval_loss 0.8265895953757225\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8942,  loss:0.2878,  val_accuracy:0.9752,  val_loss:0.0883,  \n","...............................................................adapt model (without source) last loss:  7.765005527460289e-09\n","\n","Epoch: 0, accuracy:0.8847,  loss:0.3073,  val_accuracy:0.9688,  val_loss:0.1015,  \n","................................................................adapt model (with source) last loss:  1.0322016350983176e-05\n","\n","knn_loss 0.8546511627906976\n","retrieval_loss 0.8197674418604651\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8975,  loss:0.2783,  val_accuracy:0.9679,  val_loss:0.1002,  \n",".............................................................adapt model (without source) last loss:  1.0389795690457504e-08\n","\n","Epoch: 0, accuracy:0.8840,  loss:0.3051,  val_accuracy:0.9486,  val_loss:0.1350,  \n","........................................................adapt model (with source) last loss:  1.5714851997472579e-07\n","\n","knn_loss 0.8255813953488372\n","retrieval_loss 0.7848837209302325\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.9061,  loss:0.2653,  val_accuracy:0.9624,  val_loss:0.1030,  \n","..............................................................adapt model (without source) last loss:  2.0251333054943643e-08\n","\n","Epoch: 0, accuracy:0.9085,  loss:0.2592,  val_accuracy:0.9761,  val_loss:0.0879,  \n","....................................................................adapt model (with source) last loss:  2.0603647499228828e-06\n","\n","knn_loss 0.8497109826589595\n","retrieval_loss 0.7976878612716763\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8932,  loss:0.2877,  val_accuracy:0.9853,  val_loss:0.0803,  \n",".................................................................adapt model (without source) last loss:  5.07037930219667e-06\n","\n","Epoch: 0, accuracy:0.9016,  loss:0.2685,  val_accuracy:0.9706,  val_loss:0.0934,  \n","................................................................adapt model (with source) last loss:  1.4667347159047495e-06\n","\n","knn_loss 0.8439306358381503\n","retrieval_loss 0.8092485549132948\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8962,  loss:0.2817,  val_accuracy:0.9789,  val_loss:0.0754,  \n","...............................................................adapt model (without source) last loss:  9.917324206298872e-08\n","\n","Epoch: 0, accuracy:0.8975,  loss:0.2759,  val_accuracy:0.9614,  val_loss:0.1066,  \n","..............................................................adapt model (with source) last loss:  2.448018221912207e-06\n","\n","knn_loss 0.838150289017341\n","retrieval_loss 0.7803468208092486\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8928,  loss:0.2829,  val_accuracy:0.9770,  val_loss:0.0807,  \n",".................................................................adapt model (without source) last loss:  7.119957103896013e-07\n","\n","Epoch: 0, accuracy:0.8901,  loss:0.2920,  val_accuracy:0.9743,  val_loss:0.0903,  \n","........................................................................adapt model (with source) last loss:  8.252557108789915e-07\n","\n","knn_loss 0.7687861271676301\n","retrieval_loss 0.7514450867052023\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8850,  loss:0.3023,  val_accuracy:0.9780,  val_loss:0.0900,  \n","...............................................................adapt model (without source) last loss:  1.3026532741378105e-08\n","\n","Epoch: 0, accuracy:0.8868,  loss:0.3027,  val_accuracy:0.9688,  val_loss:0.0907,  \n","....................................................................adapt model (with source) last loss:  4.1726437416400586e-07\n","\n","knn_loss 0.884393063583815\n","retrieval_loss 0.8034682080924855\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8875,  loss:0.3005,  val_accuracy:0.9679,  val_loss:0.1059,  \n","...............................................................adapt model (without source) last loss:  1.5740973822175874e-06\n","\n","Epoch: 0, accuracy:0.8949,  loss:0.2809,  val_accuracy:0.9651,  val_loss:0.0974,  \n","............................................................adapt model (with source) last loss:  1.0837201358526727e-08\n","\n","knn_loss 0.7976878612716763\n","retrieval_loss 0.7572254335260116\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8977,  loss:0.2762,  val_accuracy:0.9826,  val_loss:0.0709,  \n","..........................................................adapt model (without source) last loss:  2.2987943992802684e-08\n","\n","Epoch: 0, accuracy:0.9053,  loss:0.2640,  val_accuracy:0.9789,  val_loss:0.0796,  \n","........................................................................adapt model (with source) last loss:  2.0656086974213395e-07\n","\n","knn_loss 0.8323699421965318\n","retrieval_loss 0.791907514450867\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8918,  loss:0.2915,  val_accuracy:0.9715,  val_loss:0.0924,  \n","...........................................................adapt model (without source) last loss:  1.5106385475860407e-08\n","\n","Epoch: 0, accuracy:0.8827,  loss:0.3062,  val_accuracy:0.9614,  val_loss:0.1146,  \n","................................................................adapt model (with source) last loss:  2.55056935571929e-08\n","\n","knn_loss 0.8497109826589595\n","retrieval_loss 0.8323699421965318\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8964,  loss:0.2766,  val_accuracy:0.9761,  val_loss:0.0768,  \n","....................................................................adapt model (without source) last loss:  8.289910624625918e-08\n","\n","Epoch: 0, accuracy:0.9034,  loss:0.2680,  val_accuracy:0.9780,  val_loss:0.0784,  \n","..........................................................adapt model (with source) last loss:  8.902064507765317e-08\n","\n","knn_loss 0.8372093023255814\n","retrieval_loss 0.7616279069767442\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8952,  loss:0.2838,  val_accuracy:0.9743,  val_loss:0.0967,  \n","....................................................................adapt model (without source) last loss:  1.3631652109324932e-06\n","\n","Epoch: 0, accuracy:0.8951,  loss:0.2848,  val_accuracy:0.9743,  val_loss:0.0906,  \n",".....................................................................adapt model (with source) last loss:  3.2119527304530493e-07\n","\n","knn_loss 0.8081395348837209\n","retrieval_loss 0.7616279069767442\n","adapt with source 1.0\n","adapt without source 0.9941860465116279\n","\n","Epoch: 0, accuracy:0.8980,  loss:0.2758,  val_accuracy:0.9660,  val_loss:0.0962,  \n","...................................................................adapt model (without source) last loss:  2.0754546881107672e-07\n","\n","Epoch: 0, accuracy:0.9015,  loss:0.2659,  val_accuracy:0.9725,  val_loss:0.0910,  \n","......................................................................adapt model (with source) last loss:  2.631449262935348e-07\n","\n","knn_loss 0.861271676300578\n","retrieval_loss 0.8034682080924855\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8911,  loss:0.2913,  val_accuracy:0.9688,  val_loss:0.1044,  \n","......................................................................adapt model (without source) last loss:  2.899742412409978e-06\n","\n","Epoch: 0, accuracy:0.8946,  loss:0.2884,  val_accuracy:0.9725,  val_loss:0.0826,  \n",".......................................................................adapt model (with source) last loss:  7.039729439384246e-07\n","\n","knn_loss 0.791907514450867\n","retrieval_loss 0.7283236994219653\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8769,  loss:0.3247,  val_accuracy:0.9798,  val_loss:0.0897,  \n",".......................................................adapt model (without source) last loss:  1.0508800940556284e-08\n","\n","Epoch: 0, accuracy:0.8878,  loss:0.2938,  val_accuracy:0.9752,  val_loss:0.0960,  \n",".............................................................adapt model (with source) last loss:  8.949156836024486e-06\n","\n","knn_loss 0.8323699421965318\n","retrieval_loss 0.7861271676300579\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8984,  loss:0.2792,  val_accuracy:0.9798,  val_loss:0.0836,  \n",".....................................................................adapt model (without source) last loss:  2.0536147076199995e-06\n","\n","Epoch: 0, accuracy:0.8791,  loss:0.3211,  val_accuracy:0.9725,  val_loss:0.0939,  \n","..............................................................adapt model (with source) last loss:  0.0012414208613336086\n","\n","knn_loss 0.7861271676300579\n","retrieval_loss 0.6878612716763006\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8953,  loss:0.2778,  val_accuracy:0.9715,  val_loss:0.0853,  \n","............................................................adapt model (without source) last loss:  2.357735553459861e-07\n","\n","Epoch: 0, accuracy:0.8908,  loss:0.2862,  val_accuracy:0.9798,  val_loss:0.0697,  \n","..........................................................................adapt model (with source) last loss:  2.4530342557227414e-07\n","\n","knn_loss 0.7687861271676301\n","retrieval_loss 0.7803468208092486\n","adapt with source 0.9826589595375722\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.9020,  loss:0.2687,  val_accuracy:0.9734,  val_loss:0.0848,  \n","..................................................................adapt model (without source) last loss:  4.2945166569552384e-06\n","\n","Epoch: 0, accuracy:0.8980,  loss:0.2787,  val_accuracy:0.9697,  val_loss:0.0902,  \n","......................................................................adapt model (with source) last loss:  2.3425448603120458e-07\n","\n","knn_loss 0.8323699421965318\n","retrieval_loss 0.791907514450867\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8872,  loss:0.3037,  val_accuracy:0.9633,  val_loss:0.1034,  \n","............................................................adapt model (without source) last loss:  1.0169016206873494e-07\n","\n","Epoch: 0, accuracy:0.8896,  loss:0.2935,  val_accuracy:0.9743,  val_loss:0.0843,  \n","...................................................................adapt model (with source) last loss:  3.672278694466513e-07\n","\n","knn_loss 0.8497109826589595\n","retrieval_loss 0.8034682080924855\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8849,  loss:0.3051,  val_accuracy:0.9743,  val_loss:0.0895,  \n",".........................................................................adapt model (without source) last loss:  2.894230419769883e-07\n","\n","Epoch: 0, accuracy:0.8835,  loss:0.3051,  val_accuracy:0.9761,  val_loss:0.0920,  \n","............................................................adapt model (with source) last loss:  4.19253076699988e-08\n","\n","knn_loss 0.861271676300578\n","retrieval_loss 0.8439306358381503\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8968,  loss:0.2898,  val_accuracy:0.9716,  val_loss:0.0871,  \n",".................................................................adapt model (without source) last loss:  1.847172228508498e-07\n","\n","Epoch: 0, accuracy:0.9011,  loss:0.2750,  val_accuracy:0.9725,  val_loss:0.1000,  \n",".......................................................................adapt model (with source) last loss:  1.615782707631297e-06\n","\n","knn_loss 0.8488372093023255\n","retrieval_loss 0.7906976744186046\n","adapt with source 1.0\n","adapt without source 0.9941860465116279\n","\n","Epoch: 0, accuracy:0.8828,  loss:0.3146,  val_accuracy:0.9752,  val_loss:0.0969,  \n","............................................................................adapt model (without source) last loss:  1.960898543984513e-06\n","\n","Epoch: 0, accuracy:0.8949,  loss:0.2823,  val_accuracy:0.9697,  val_loss:0.0993,  \n",".........................................................adapt model (with source) last loss:  1.2467754828549005e-08\n","\n","knn_loss 0.8197674418604651\n","retrieval_loss 0.8081395348837209\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.8318282027154187\n","np.mean(retrieval_loss_es) =  0.7793883586503563\n","np.mean(without_source_loss_es) =  0.9993043419814492\n","np.mean(with_source_loss_es) =  0.9991907514450866\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.0305214856653105\n","np.std(retrieval_loss_es) =  0.036613558655121475\n","np.std(without_source_loss_es) =  0.0022102995652189495\n","np.std(with_source_loss_es) =  0.0028341388837297846\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.6046581154816685\n","np.mean(retrieval_loss_es) =  0.5565904480242856\n","np.mean(without_source_loss_es) =  0.9996693764596623\n","np.mean(with_source_loss_es) =  0.9990325238065197\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.06009652139821458\n","np.std(retrieval_loss_es) =  0.08399737641352775\n","np.std(without_source_loss_es) =  0.0011225236162172084\n","np.std(with_source_loss_es) =  0.005066217379284004\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P2pU2YFVzbMR"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.8318282027154187\r\n","np.mean(retrieval_loss_es) =  0.7793883586503563\r\n","np.mean(without_source_loss_es) =  0.9993043419814492\r\n","np.mean(with_source_loss_es) =  0.9991907514450866\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.0305214856653105\r\n","np.std(retrieval_loss_es) =  0.036613558655121475\r\n","np.std(without_source_loss_es) =  0.0022102995652189495\r\n","np.std(with_source_loss_es) =  0.0028341388837297846\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.6046581154816685\r\n","np.mean(retrieval_loss_es) =  0.5565904480242856\r\n","np.mean(without_source_loss_es) =  0.9996693764596623\r\n","np.mean(with_source_loss_es) =  0.9990325238065197\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.06009652139821458\r\n","np.std(retrieval_loss_es) =  0.08399737641352775\r\n","np.std(without_source_loss_es) =  0.0011225236162172084\r\n","np.std(with_source_loss_es) =  0.005066217379284004\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"jCEq-nxqMFmn"},"source":["\r\n","\r\n","```\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = 1\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = 124\r\n","random_pairs_count = 100\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  1.0\r\n","np.mean(arr_knn) =  0.8281119774163195\r\n","np.mean(arr_retrieval_loss) =  0.8003394273423847\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.8790361607742977\r\n","np.mean(arr_normal_cdh_loss) =  0.7297284581260921\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9074001881973384\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  1.0\r\n","np.mean(arr_knn) =  0.6022642862673279\r\n","np.mean(arr_retrieval_loss) =  0.6162098982135521\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.6585996871178228\r\n","np.mean(arr_normal_cdh_loss) =  0.4869124047923922\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.6974682316945179\r\n","```\r\n"]},{"cell_type":"markdown","metadata":{"id":"Q0UobsDEFtE9"},"source":["IMPORTANT NOTE:\r\n","Interestingly we get bad accuracy scores here. There are 2 ways to improve\r\n","1. more pairs for NN-CDH-EAC  because they only have 100 random pairs per net\r\n","EAC style pairs also\r\n","C2C-EAC style pairs also\r\n","C2C-EAC classification process\r\n","2. Using the retrieval of the original EAC. Notice that the knn is performing poorly.  This is a lot worse than the special knn in Vahid's paper."]},{"cell_type":"markdown","metadata":{"id":"WlwDvFGzifQn"},"source":["\r\n","\r\n","```\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","random_pairs_count = 30000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.999421965317919\r\n","np.mean(arr_knn) =  0.8275238607339697\r\n","np.mean(arr_retrieval_loss) =  0.7812407581664202\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9959470358919209\r\n","np.mean(arr_normal_cdh_loss) =  0.7019794327194515\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9965250705740019\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9941860465116279\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9997826086956522\r\n","np.mean(arr_knn) =  0.6089479409264086\r\n","np.mean(arr_retrieval_loss) =  0.5769741353708231\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9857708565589001\r\n","np.mean(arr_normal_cdh_loss) =  0.5704297387587864\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9849960233297986\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.99375\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"p5rZNUr6r7On"},"source":["Down scale to 6000 pairs\r\n","\r\n","\r\n","\r\n","```\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9965284312407581\r\n","np.mean(arr_knn) =  0.8275238607339697\r\n","np.mean(arr_retrieval_loss) =  0.7812407581664202\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9837814222341711\r\n","np.mean(arr_normal_cdh_loss) =  0.6776986154052964\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.991897432450598\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9883720930232558\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.987081248262441\r\n","np.mean(arr_knn) =  0.6089479409264086\r\n","np.mean(arr_retrieval_loss) =  0.5769741353708231\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9508979312902591\r\n","np.mean(arr_normal_cdh_loss) =  0.5524140549287838\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9698078170915923\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9917174796747967\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"dqiSsL5WXrfs"},"source":["Using 10 * training number as random pair number\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9965250705740019\r\n","np.mean(arr_knn) =  0.823440650625084\r\n","np.mean(arr_retrieval_loss) =  0.7760182820271542\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9930535018147599\r\n","np.mean(arr_normal_cdh_loss) =  0.6753461486758974\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9918974324505981\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9941860465116279\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9984232199181632\r\n","np.mean(arr_knn) =  0.6108833970029404\r\n","np.mean(arr_retrieval_loss) =  0.5309070704038723\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9715752359502361\r\n","np.mean(arr_normal_cdh_loss) =  0.5354995320623634\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9572234387059968\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9944444444444445\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"4Jww9oe8qP8x"},"source":["with STD\r\n","\r\n","\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9974559752654926\r\n","np.mean(arr_knn) =  0.8313624143029977\r\n","np.mean(arr_retrieval_loss) =  0.7810202984272078\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9890065869068421\r\n","np.mean(arr_normal_cdh_loss) =  0.6822832369942198\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9936355692969485\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9941860465116279\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.005191159835236904\r\n","np.std(arr_knn) =  0.02526178528859611\r\n","np.std(arr_retrieval_loss) =  0.028800644274238243\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.008749778786491984\r\n","np.std(arr_normal_cdh_loss) =  0.03448260562534618\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.007427678396361223\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.0\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9974142678849565\r\n","np.mean(arr_knn) =  0.6056267519903155\r\n","np.mean(arr_retrieval_loss) =  0.5623310611064158\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9553387342412119\r\n","np.mean(arr_normal_cdh_loss) =  0.5360104748568112\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9789716923497828\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9980314960629921\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.006836961784849787\r\n","np.std(arr_knn) =  0.06597657617907499\r\n","np.std(arr_retrieval_loss) =  0.07878962568591576\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.03835590364768343\r\n","np.std(arr_normal_cdh_loss) =  0.0784487264211488\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.028302792154520584\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.0\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"aCm1E6p4gH8X"},"source":["# Dataset: Yeast\r\n","\r\n","Starting from here, the datasets are chosen based on this paper\r\n","\r\n","Anup-to-datecomparisonofstate-of-the-artclassificationalgorithms.pdf"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RypMXB92gvHE","executionInfo":{"elapsed":16089828,"status":"ok","timestamp":1611027124808,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"6c59df5d-30f2-4d6e-ce60-7e0837319301"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/yeast.data'\r\n","nominalCols = [] \r\n","numericCols = [1,2,3,4,5,6,7,8]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(1,2,3,4,5,6,7,8,),delim_whitespace=True);\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(9,),delim_whitespace=True);\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False)\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [1, 2, 3, 4, 5, 6, 7, 8]\n","Index: []\n","1    0\n","2    0\n","3    0\n","4    0\n","5    0\n","6    0\n","7    0\n","8    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"P6mdlko9iY7-","executionInfo":{"elapsed":16089822,"status":"ok","timestamp":1611027124810,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"cb3cdaea-4294-4a61-aea0-21a81e92f36c"},"source":["X.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1059</th>\n","      <td>-0.438033</td>\n","      <td>1.695697</td>\n","      <td>-0.000389</td>\n","      <td>-0.373480</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>0.694298</td>\n","      <td>-0.058236</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>-0.875181</td>\n","      <td>-0.322342</td>\n","      <td>0.230449</td>\n","      <td>3.566647</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>0.001983</td>\n","      <td>-0.152172</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>-0.656607</td>\n","      <td>-0.160899</td>\n","      <td>-1.385414</td>\n","      <td>-0.957203</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>0.175062</td>\n","      <td>0.693258</td>\n","    </tr>\n","    <tr>\n","      <th>1258</th>\n","      <td>-0.875181</td>\n","      <td>-0.645229</td>\n","      <td>-0.000389</td>\n","      <td>-0.519411</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>-1.036491</td>\n","      <td>-0.527919</td>\n","    </tr>\n","    <tr>\n","      <th>575</th>\n","      <td>-0.510891</td>\n","      <td>2.664357</td>\n","      <td>0.576705</td>\n","      <td>-0.446445</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>-0.517254</td>\n","      <td>1.162942</td>\n","    </tr>\n","    <tr>\n","      <th>1121</th>\n","      <td>-0.802323</td>\n","      <td>-0.403064</td>\n","      <td>0.115030</td>\n","      <td>0.210242</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>0.694298</td>\n","      <td>-0.527919</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>1.747712</td>\n","      <td>1.372811</td>\n","      <td>-0.346645</td>\n","      <td>0.575069</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>-1.382649</td>\n","      <td>-0.527919</td>\n","    </tr>\n","    <tr>\n","      <th>1226</th>\n","      <td>-1.385188</td>\n","      <td>0.081266</td>\n","      <td>-1.385414</td>\n","      <td>-0.592376</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>-0.690333</td>\n","      <td>0.317511</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>-0.802323</td>\n","      <td>0.646317</td>\n","      <td>-0.000389</td>\n","      <td>-0.008654</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>0.694298</td>\n","      <td>2.947739</td>\n","    </tr>\n","    <tr>\n","      <th>1383</th>\n","      <td>-0.510891</td>\n","      <td>-0.725950</td>\n","      <td>-1.500833</td>\n","      <td>-0.592376</td>\n","      <td>-0.09759</td>\n","      <td>-0.099131</td>\n","      <td>0.694298</td>\n","      <td>0.317511</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             1         2         3  ...         6         7         8\n","1059 -0.438033  1.695697 -0.000389  ... -0.099131  0.694298 -0.058236\n","433  -0.875181 -0.322342  0.230449  ... -0.099131  0.001983 -0.152172\n","742  -0.656607 -0.160899 -1.385414  ... -0.099131  0.175062  0.693258\n","1258 -0.875181 -0.645229 -0.000389  ... -0.099131 -1.036491 -0.527919\n","575  -0.510891  2.664357  0.576705  ... -0.099131 -0.517254  1.162942\n","1121 -0.802323 -0.403064  0.115030  ... -0.099131  0.694298 -0.527919\n","35    1.747712  1.372811 -0.346645  ... -0.099131 -1.382649 -0.527919\n","1226 -1.385188  0.081266 -1.385414  ... -0.099131 -0.690333  0.317511\n","136  -0.802323  0.646317 -0.000389  ... -0.099131  0.694298  2.947739\n","1383 -0.510891 -0.725950 -1.500833  ... -0.099131  0.694298  0.317511\n","\n","[10 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"foQLA0dBjRMK","executionInfo":{"elapsed":16089813,"status":"ok","timestamp":1611027124811,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"3965189a-de9c-4846-fc4c-202da14e552c"},"source":["y.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>9_CYT</th>\n","      <th>9_ERL</th>\n","      <th>9_EXC</th>\n","      <th>9_ME1</th>\n","      <th>9_ME2</th>\n","      <th>9_ME3</th>\n","      <th>9_MIT</th>\n","      <th>9_NUC</th>\n","      <th>9_POX</th>\n","      <th>9_VAC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1059</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1258</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>575</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      9_CYT  9_ERL  9_EXC  9_ME1  9_ME2  9_ME3  9_MIT  9_NUC  9_POX  9_VAC\n","1059      1      0      0      0      0      0      0      0      0      0\n","433       0      0      0      0      0      0      1      0      0      0\n","742       0      0      0      0      0      1      0      0      0      0\n","1258      1      0      0      0      0      0      0      0      0      0\n","575       0      0      0      0      0      0      0      1      0      0"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"markdown","metadata":{"id":"YYym1peqiIYc"},"source":["#Trying 10 fold: Yeast"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAaP68gxiB3K","executionInfo":{"elapsed":28161650,"status":"ok","timestamp":1611039196657,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"354b35f1-e237-431f-f947-bf31a2bdea54"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.4682,  loss:1.4105,  val_accuracy:0.5064,  val_loss:1.2439,  \n","......................................................................adapt model (without source) last loss:  0.09153098613023758\n","\n","Epoch: 0, accuracy:0.4835,  loss:1.3821,  val_accuracy:0.5625,  val_loss:1.1500,  \n",".....................................................................adapt model (with source) last loss:  0.14591634273529053\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5436241610738255\n","retrieval_loss 0.5302013422818792\n","adapt with source 0.48322147651006714\n","adapt without source 0.4966442953020134\n","\n","Epoch: 0, accuracy:0.4913,  loss:1.3513,  val_accuracy:0.5603,  val_loss:1.1766,  \n","................................................................adapt model (without source) last loss:  0.07541321963071823\n","\n","Epoch: 0, accuracy:0.4846,  loss:1.3770,  val_accuracy:0.5296,  val_loss:1.2037,  \n","..................................................................................................adapt model (with source) last loss:  0.09454739093780518\n","\n","knn_loss 0.4899328859060403\n","retrieval_loss 0.5167785234899329\n","adapt with source 0.4228187919463087\n","adapt without source 0.5033557046979866\n","\n","Epoch: 0, accuracy:0.4890,  loss:1.3702,  val_accuracy:0.5603,  val_loss:1.1458,  \n",".................................................................................adapt model (without source) last loss:  0.05556813254952431\n","\n","Epoch: 0, accuracy:0.4904,  loss:1.3708,  val_accuracy:0.5596,  val_loss:1.1534,  \n","............................................................................adapt model (with source) last loss:  0.08492035418748856\n","\n","knn_loss 0.4899328859060403\n","retrieval_loss 0.5369127516778524\n","adapt with source 0.48322147651006714\n","adapt without source 0.4966442953020134\n","\n","Epoch: 0, accuracy:0.4883,  loss:1.3804,  val_accuracy:0.5625,  val_loss:1.1585,  \n","..............................................................adapt model (without source) last loss:  0.0726773664355278\n","\n","Epoch: 0, accuracy:0.4802,  loss:1.3915,  val_accuracy:0.5333,  val_loss:1.2076,  \n",".........................................................adapt model (with source) last loss:  0.1576632857322693\n","\n","knn_loss 0.46308724832214765\n","retrieval_loss 0.5167785234899329\n","adapt with source 0.5838926174496645\n","adapt without source 0.5503355704697986\n","\n","Epoch: 0, accuracy:0.4739,  loss:1.4068,  val_accuracy:0.5187,  val_loss:1.2452,  \n","...................................................................adapt model (without source) last loss:  0.09460683166980743\n","\n","Epoch: 0, accuracy:0.4785,  loss:1.3911,  val_accuracy:0.5457,  val_loss:1.1711,  \n",".................................................................adapt model (with source) last loss:  0.10283233970403671\n","\n","knn_loss 0.5202702702702703\n","retrieval_loss 0.5743243243243243\n","adapt with source 0.5540540540540541\n","adapt without source 0.4864864864864865\n","\n","Epoch: 0, accuracy:0.4846,  loss:1.3859,  val_accuracy:0.5427,  val_loss:1.1831,  \n","..............................................................adapt model (without source) last loss:  0.10010310262441635\n","\n","Epoch: 0, accuracy:0.4803,  loss:1.3990,  val_accuracy:0.5449,  val_loss:1.1814,  \n","..............................................................................adapt model (with source) last loss:  0.10525897890329361\n","\n","knn_loss 0.4391891891891892\n","retrieval_loss 0.46621621621621623\n","adapt with source 0.5135135135135135\n","adapt without source 0.5\n","\n","Epoch: 0, accuracy:0.4789,  loss:1.4036,  val_accuracy:0.5210,  val_loss:1.2326,  \n","...............................................................................adapt model (without source) last loss:  0.08702506870031357\n","\n","Epoch: 0, accuracy:0.4770,  loss:1.4126,  val_accuracy:0.5419,  val_loss:1.1978,  \n",".....................................................................................adapt model (with source) last loss:  0.078113853931427\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.527027027027027\n","retrieval_loss 0.5337837837837838\n","adapt with source 0.5540540540540541\n","adapt without source 0.49324324324324326\n","\n","Epoch: 0, accuracy:0.4854,  loss:1.3797,  val_accuracy:0.5412,  val_loss:1.1897,  \n","...............................................................................adapt model (without source) last loss:  0.061394102871418\n","\n","Epoch: 0, accuracy:0.4798,  loss:1.3921,  val_accuracy:0.5337,  val_loss:1.1945,  \n","..............................................................................adapt model (with source) last loss:  0.0918298289179802\n","\n","knn_loss 0.5135135135135135\n","retrieval_loss 0.5135135135135135\n","adapt with source 0.4797297297297297\n","adapt without source 0.5\n","\n","Epoch: 0, accuracy:0.4814,  loss:1.3763,  val_accuracy:0.5659,  val_loss:1.1436,  \n","...............................................................adapt model (without source) last loss:  0.0839841291308403\n","\n","Epoch: 0, accuracy:0.4877,  loss:1.3515,  val_accuracy:0.5397,  val_loss:1.1664,  \n","..................................................................................adapt model (with source) last loss:  0.15649409592151642\n","\n","knn_loss 0.5202702702702703\n","retrieval_loss 0.6081081081081081\n","adapt with source 0.5608108108108109\n","adapt without source 0.5540540540540541\n","\n","Epoch: 0, accuracy:0.4769,  loss:1.3988,  val_accuracy:0.5569,  val_loss:1.1771,  \n",".................................................................................adapt model (without source) last loss:  0.04243050888180733\n","\n","Epoch: 0, accuracy:0.4714,  loss:1.4055,  val_accuracy:0.5322,  val_loss:1.1916,  \n","................................................adapt model (with source) last loss:  0.14581407606601715\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.4594594594594595\n","retrieval_loss 0.5337837837837838\n","adapt with source 0.49324324324324326\n","adapt without source 0.5\n","\n","Epoch: 0, accuracy:0.4708,  loss:1.4199,  val_accuracy:0.5491,  val_loss:1.2260,  \n","....................................................................adapt model (without source) last loss:  0.06433886289596558\n","\n","Epoch: 0, accuracy:0.4779,  loss:1.3886,  val_accuracy:0.5221,  val_loss:1.2453,  \n","............................................................................adapt model (with source) last loss:  0.1281578540802002\n","\n","knn_loss 0.5033557046979866\n","retrieval_loss 0.5436241610738255\n","adapt with source 0.5570469798657718\n","adapt without source 0.5436241610738255\n","\n","Epoch: 0, accuracy:0.4697,  loss:1.4180,  val_accuracy:0.5506,  val_loss:1.2002,  \n","..............................................................................adapt model (without source) last loss:  0.060590606182813644\n","\n","Epoch: 0, accuracy:0.4800,  loss:1.3943,  val_accuracy:0.5393,  val_loss:1.1700,  \n","............................................................................................adapt model (with source) last loss:  0.03850812837481499\n","\n","knn_loss 0.4429530201342282\n","retrieval_loss 0.5167785234899329\n","adapt with source 0.5302013422818792\n","adapt without source 0.47651006711409394\n","\n","Epoch: 0, accuracy:0.4784,  loss:1.4043,  val_accuracy:0.5356,  val_loss:1.1900,  \n","..................................................................................adapt model (without source) last loss:  0.06878115981817245\n","\n","Epoch: 0, accuracy:0.4814,  loss:1.3821,  val_accuracy:0.5446,  val_loss:1.1725,  \n","..........................................................................adapt model (with source) last loss:  0.1202225610613823\n","\n","knn_loss 0.48322147651006714\n","retrieval_loss 0.5100671140939598\n","adapt with source 0.5302013422818792\n","adapt without source 0.5436241610738255\n","\n","Epoch: 0, accuracy:0.4815,  loss:1.3758,  val_accuracy:0.5723,  val_loss:1.1564,  \n",".....................................................................adapt model (without source) last loss:  0.12715725600719452\n","\n","Epoch: 0, accuracy:0.4865,  loss:1.3661,  val_accuracy:0.5446,  val_loss:1.1348,  \n","............................................................................adapt model (with source) last loss:  0.1368330419063568\n","\n","knn_loss 0.47651006711409394\n","retrieval_loss 0.5436241610738255\n","adapt with source 0.5100671140939598\n","adapt without source 0.5369127516778524\n","\n","Epoch: 0, accuracy:0.4781,  loss:1.3815,  val_accuracy:0.5479,  val_loss:1.1914,  \n","............................................................adapt model (without source) last loss:  0.09084197878837585\n","\n","Epoch: 0, accuracy:0.4823,  loss:1.3852,  val_accuracy:0.5501,  val_loss:1.1736,  \n",".............................................................adapt model (with source) last loss:  0.10258366167545319\n","\n","knn_loss 0.5472972972972973\n","retrieval_loss 0.581081081081081\n","adapt with source 0.5743243243243243\n","adapt without source 0.5540540540540541\n","\n","Epoch: 0, accuracy:0.4958,  loss:1.3577,  val_accuracy:0.5472,  val_loss:1.1593,  \n",".......................................................................adapt model (without source) last loss:  0.06689325720071793\n","\n","Epoch: 0, accuracy:0.4913,  loss:1.3644,  val_accuracy:0.5501,  val_loss:1.1585,  \n","................................................................................adapt model (with source) last loss:  0.10996992141008377\n","\n","knn_loss 0.4594594594594595\n","retrieval_loss 0.5472972972972973\n","adapt with source 0.5067567567567568\n","adapt without source 0.5135135135135135\n","\n","Epoch: 0, accuracy:0.4768,  loss:1.3986,  val_accuracy:0.5479,  val_loss:1.1746,  \n",".............................................................................................adapt model (without source) last loss:  0.06431036442518234\n","\n","Epoch: 0, accuracy:0.4819,  loss:1.3943,  val_accuracy:0.5307,  val_loss:1.2049,  \n",".......................................................................adapt model (with source) last loss:  0.032010503113269806\n","\n","knn_loss 0.4797297297297297\n","retrieval_loss 0.5067567567567568\n","adapt with source 0.5743243243243243\n","adapt without source 0.5540540540540541\n","\n","Epoch: 0, accuracy:0.4727,  loss:1.4080,  val_accuracy:0.5284,  val_loss:1.2345,  \n",".........................................................................adapt model (without source) last loss:  0.06298621743917465\n","\n","Epoch: 0, accuracy:0.4736,  loss:1.3950,  val_accuracy:0.5112,  val_loss:1.2326,  \n","......................................................................adapt model (with source) last loss:  0.12163550406694412\n","\n","knn_loss 0.5405405405405406\n","retrieval_loss 0.5675675675675675\n","adapt with source 0.4797297297297297\n","adapt without source 0.527027027027027\n","\n","Epoch: 0, accuracy:0.4790,  loss:1.3882,  val_accuracy:0.5457,  val_loss:1.2032,  \n","............................................................adapt model (without source) last loss:  0.08101137727499008\n","\n","Epoch: 0, accuracy:0.4775,  loss:1.3829,  val_accuracy:0.5524,  val_loss:1.1874,  \n","............................................................................adapt model (with source) last loss:  0.05761457234621048\n","\n","knn_loss 0.5135135135135135\n","retrieval_loss 0.5472972972972973\n","adapt with source 0.5472972972972973\n","adapt without source 0.5675675675675675\n","\n","Epoch: 0, accuracy:0.4863,  loss:1.3811,  val_accuracy:0.5404,  val_loss:1.2307,  \n",".............................................................adapt model (without source) last loss:  0.17490708827972412\n","\n","Epoch: 0, accuracy:0.4801,  loss:1.3866,  val_accuracy:0.5307,  val_loss:1.2642,  \n",".............................................................adapt model (with source) last loss:  0.11831667274236679\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.46621621621621623\n","retrieval_loss 0.5135135135135135\n","adapt with source 0.5337837837837838\n","adapt without source 0.5540540540540541\n","\n","Epoch: 0, accuracy:0.4760,  loss:1.3940,  val_accuracy:0.5124,  val_loss:1.2197,  \n","........................................................adapt model (without source) last loss:  0.07211554795503616\n","\n","Epoch: 0, accuracy:0.4712,  loss:1.3949,  val_accuracy:0.5258,  val_loss:1.1984,  \n","..........................................................................adapt model (with source) last loss:  0.08490626513957977\n","\n","knn_loss 0.5100671140939598\n","retrieval_loss 0.5100671140939598\n","adapt with source 0.48322147651006714\n","adapt without source 0.44966442953020136\n","\n","Epoch: 0, accuracy:0.4888,  loss:1.3580,  val_accuracy:0.5723,  val_loss:1.1226,  \n","......................................................................adapt model (without source) last loss:  0.04469132423400879\n","\n","Epoch: 0, accuracy:0.4796,  loss:1.3699,  val_accuracy:0.5258,  val_loss:1.2407,  \n",".........................................................................adapt model (with source) last loss:  0.10610553622245789\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5100671140939598\n","retrieval_loss 0.5436241610738255\n","adapt with source 0.5167785234899329\n","adapt without source 0.5771812080536913\n","\n","Epoch: 0, accuracy:0.4835,  loss:1.3817,  val_accuracy:0.5476,  val_loss:1.2361,  \n","..........................................................................adapt model (without source) last loss:  0.07304991036653519\n","\n","Epoch: 0, accuracy:0.4727,  loss:1.4058,  val_accuracy:0.5363,  val_loss:1.2180,  \n",".........................................................adapt model (with source) last loss:  0.09718725085258484\n","\n","knn_loss 0.4563758389261745\n","retrieval_loss 0.5369127516778524\n","adapt with source 0.5302013422818792\n","adapt without source 0.5369127516778524\n","\n","Epoch: 0, accuracy:0.4813,  loss:1.3710,  val_accuracy:0.5596,  val_loss:1.1671,  \n","........................................................................................adapt model (without source) last loss:  0.022058110684156418\n","\n","Epoch: 0, accuracy:0.4714,  loss:1.4084,  val_accuracy:0.5281,  val_loss:1.1622,  \n",".........................................................................................adapt model (with source) last loss:  0.014060869812965393\n","\n","knn_loss 0.5503355704697986\n","retrieval_loss 0.5234899328859061\n","adapt with source 0.47651006711409394\n","adapt without source 0.48322147651006714\n","\n","Epoch: 0, accuracy:0.4758,  loss:1.4047,  val_accuracy:0.5412,  val_loss:1.1641,  \n",".....................................................adapt model (without source) last loss:  0.0733560100197792\n","\n","Epoch: 0, accuracy:0.4788,  loss:1.3899,  val_accuracy:0.4978,  val_loss:1.2510,  \n","........................................................................adapt model (with source) last loss:  0.06807918846607208\n","\n","knn_loss 0.5675675675675675\n","retrieval_loss 0.527027027027027\n","adapt with source 0.5540540540540541\n","adapt without source 0.49324324324324326\n","\n","Epoch: 0, accuracy:0.4842,  loss:1.3721,  val_accuracy:0.5501,  val_loss:1.1899,  \n",".....................................................................adapt model (without source) last loss:  0.07647290080785751\n","\n","Epoch: 0, accuracy:0.4705,  loss:1.3967,  val_accuracy:0.5434,  val_loss:1.2059,  \n","......................................................................adapt model (with source) last loss:  0.1265217512845993\n","\n","knn_loss 0.5472972972972973\n","retrieval_loss 0.5608108108108109\n","adapt with source 0.5472972972972973\n","adapt without source 0.581081081081081\n","\n","Epoch: 0, accuracy:0.4804,  loss:1.3744,  val_accuracy:0.5449,  val_loss:1.2061,  \n","...........................................................adapt model (without source) last loss:  0.06972739100456238\n","\n","Epoch: 0, accuracy:0.4798,  loss:1.3819,  val_accuracy:0.5254,  val_loss:1.2304,  \n","................................................................adapt model (with source) last loss:  0.15250392258167267\n","\n","knn_loss 0.4797297297297297\n","retrieval_loss 0.5878378378378378\n","adapt with source 0.4864864864864865\n","adapt without source 0.5\n","\n","Epoch: 0, accuracy:0.4820,  loss:1.3815,  val_accuracy:0.5464,  val_loss:1.2260,  \n","...................................................................................adapt model (without source) last loss:  0.08408559858798981\n","\n","Epoch: 0, accuracy:0.4785,  loss:1.3954,  val_accuracy:0.5449,  val_loss:1.2245,  \n","..............................................................................adapt model (with source) last loss:  0.08082301169633865\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.4864864864864865\n","retrieval_loss 0.5405405405405406\n","adapt with source 0.5\n","adapt without source 0.5067567567567568\n","\n","Epoch: 0, accuracy:0.4873,  loss:1.3591,  val_accuracy:0.5614,  val_loss:1.1523,  \n","..........................................................................adapt model (without source) last loss:  0.07187885046005249\n","\n","Epoch: 0, accuracy:0.4856,  loss:1.3782,  val_accuracy:0.5711,  val_loss:1.1670,  \n","........................................................................adapt model (with source) last loss:  0.113449327647686\n","\n","knn_loss 0.4864864864864865\n","retrieval_loss 0.5067567567567568\n","adapt with source 0.5608108108108109\n","adapt without source 0.49324324324324326\n","\n","Epoch: 0, accuracy:0.4802,  loss:1.3996,  val_accuracy:0.5442,  val_loss:1.1912,  \n","........................................................................................adapt model (without source) last loss:  0.08807563781738281\n","\n","Epoch: 0, accuracy:0.4778,  loss:1.3855,  val_accuracy:0.5314,  val_loss:1.2032,  \n","............................................................................................adapt model (with source) last loss:  0.044009286910295486\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5\n","retrieval_loss 0.5202702702702703\n","adapt with source 0.581081081081081\n","adapt without source 0.5472972972972973\n","\n","Epoch: 0, accuracy:0.4833,  loss:1.3747,  val_accuracy:0.5378,  val_loss:1.2252,  \n","......................................................................adapt model (without source) last loss:  0.09634418040513992\n","\n","Epoch: 0, accuracy:0.4814,  loss:1.3699,  val_accuracy:0.5438,  val_loss:1.1502,  \n","..............................................................adapt model (with source) last loss:  0.12632684409618378\n","\n","knn_loss 0.46308724832214765\n","retrieval_loss 0.5100671140939598\n","adapt with source 0.46308724832214765\n","adapt without source 0.5302013422818792\n","\n","Epoch: 0, accuracy:0.4787,  loss:1.3826,  val_accuracy:0.5551,  val_loss:1.1863,  \n",".........................................................................adapt model (without source) last loss:  0.10700751096010208\n","\n","Epoch: 0, accuracy:0.4689,  loss:1.4141,  val_accuracy:0.5423,  val_loss:1.2076,  \n","...............................................................adapt model (with source) last loss:  0.08787029981613159\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.4966442953020134\n","retrieval_loss 0.47651006711409394\n","adapt with source 0.44966442953020136\n","adapt without source 0.5033557046979866\n","\n","Epoch: 0, accuracy:0.4764,  loss:1.3974,  val_accuracy:0.5640,  val_loss:1.1611,  \n",".....................................................................adapt model (without source) last loss:  0.06941533833742142\n","\n","Epoch: 0, accuracy:0.4805,  loss:1.3908,  val_accuracy:0.5850,  val_loss:1.1498,  \n",".......................................................adapt model (with source) last loss:  0.07117782533168793\n","\n","knn_loss 0.4563758389261745\n","retrieval_loss 0.5033557046979866\n","adapt with source 0.5436241610738255\n","adapt without source 0.48322147651006714\n","\n","Epoch: 0, accuracy:0.4731,  loss:1.3831,  val_accuracy:0.5513,  val_loss:1.1614,  \n","..............................................................................adapt model (without source) last loss:  0.05705570429563522\n","\n","Epoch: 0, accuracy:0.4763,  loss:1.3899,  val_accuracy:0.5393,  val_loss:1.2016,  \n","........................................................................................adapt model (with source) last loss:  0.08287440985441208\n","\n","knn_loss 0.5704697986577181\n","retrieval_loss 0.5637583892617449\n","adapt with source 0.5637583892617449\n","adapt without source 0.5906040268456376\n","\n","Epoch: 0, accuracy:0.4785,  loss:1.3721,  val_accuracy:0.5359,  val_loss:1.1914,  \n",".............................................................................adapt model (without source) last loss:  0.0648818239569664\n","\n","Epoch: 0, accuracy:0.4705,  loss:1.3938,  val_accuracy:0.5427,  val_loss:1.1790,  \n","..................................................................adapt model (with source) last loss:  0.08481484651565552\n","\n","knn_loss 0.5472972972972973\n","retrieval_loss 0.5878378378378378\n","adapt with source 0.5675675675675675\n","adapt without source 0.5608108108108109\n","\n","Epoch: 0, accuracy:0.4907,  loss:1.3646,  val_accuracy:0.5726,  val_loss:1.1333,  \n","...............................................................adapt model (without source) last loss:  0.10583969205617905\n","\n","Epoch: 0, accuracy:0.4825,  loss:1.3854,  val_accuracy:0.5516,  val_loss:1.2008,  \n",".............................................................................adapt model (with source) last loss:  0.04230326786637306\n","\n","knn_loss 0.5337837837837838\n","retrieval_loss 0.5405405405405406\n","adapt with source 0.47297297297297297\n","adapt without source 0.4527027027027027\n","\n","Epoch: 0, accuracy:0.4842,  loss:1.3845,  val_accuracy:0.5434,  val_loss:1.1899,  \n","...........................................................adapt model (without source) last loss:  0.15886561572551727\n","\n","Epoch: 0, accuracy:0.4775,  loss:1.3904,  val_accuracy:0.5397,  val_loss:1.2264,  \n","..............................................................adapt model (with source) last loss:  0.10747245699167252\n","\n","knn_loss 0.4797297297297297\n","retrieval_loss 0.5337837837837838\n","adapt with source 0.5067567567567568\n","adapt without source 0.5743243243243243\n","\n","Epoch: 0, accuracy:0.4814,  loss:1.3916,  val_accuracy:0.5711,  val_loss:1.1683,  \n","...........................................................adapt model (without source) last loss:  0.1267925500869751\n","\n","Epoch: 0, accuracy:0.4822,  loss:1.3741,  val_accuracy:0.5569,  val_loss:1.1610,  \n","......................................................................................adapt model (with source) last loss:  0.07715114951133728\n","\n","knn_loss 0.42567567567567566\n","retrieval_loss 0.46621621621621623\n","adapt with source 0.46621621621621623\n","adapt without source 0.4797297297297297\n","\n","Epoch: 0, accuracy:0.4832,  loss:1.3786,  val_accuracy:0.5749,  val_loss:1.1454,  \n",".............................................................................................adapt model (without source) last loss:  0.05853921175003052\n","\n","Epoch: 0, accuracy:0.4741,  loss:1.3976,  val_accuracy:0.5509,  val_loss:1.1714,  \n","...........................................................................adapt model (with source) last loss:  0.04688611999154091\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.527027027027027\n","retrieval_loss 0.5135135135135135\n","adapt with source 0.4864864864864865\n","adapt without source 0.5675675675675675\n","\n","Epoch: 0, accuracy:0.4754,  loss:1.3898,  val_accuracy:0.5262,  val_loss:1.2233,  \n","...............................................................................adapt model (without source) last loss:  0.1062965840101242\n","\n","Epoch: 0, accuracy:0.4824,  loss:1.3768,  val_accuracy:0.5337,  val_loss:1.1841,  \n","..............................................................................................adapt model (with source) last loss:  0.07798022776842117\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5608108108108109\n","retrieval_loss 0.5675675675675675\n","adapt with source 0.49324324324324326\n","adapt without source 0.5337837837837838\n","\n","Epoch: 0, accuracy:0.4908,  loss:1.3529,  val_accuracy:0.5551,  val_loss:1.1759,  \n","......................................................................................adapt model (without source) last loss:  0.04636790603399277\n","\n","Epoch: 0, accuracy:0.4824,  loss:1.3731,  val_accuracy:0.5401,  val_loss:1.1907,  \n",".................................................................adapt model (with source) last loss:  0.1055208221077919\n","\n","knn_loss 0.4966442953020134\n","retrieval_loss 0.5234899328859061\n","adapt with source 0.5100671140939598\n","adapt without source 0.4966442953020134\n","\n","Epoch: 0, accuracy:0.4820,  loss:1.3934,  val_accuracy:0.5401,  val_loss:1.1893,  \n","...........................................................................adapt model (without source) last loss:  0.05307392030954361\n","\n","Epoch: 0, accuracy:0.4845,  loss:1.3736,  val_accuracy:0.5468,  val_loss:1.1751,  \n","..........................................................................adapt model (with source) last loss:  0.05946654826402664\n","\n","knn_loss 0.47651006711409394\n","retrieval_loss 0.4966442953020134\n","adapt with source 0.5100671140939598\n","adapt without source 0.5503355704697986\n","\n","Epoch: 0, accuracy:0.4799,  loss:1.3978,  val_accuracy:0.5303,  val_loss:1.2188,  \n","...............................................................adapt model (without source) last loss:  0.04230448976159096\n","\n","Epoch: 0, accuracy:0.4786,  loss:1.4059,  val_accuracy:0.5655,  val_loss:1.1894,  \n","......................................................................adapt model (with source) last loss:  0.08785133808851242\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.44966442953020136\n","retrieval_loss 0.5369127516778524\n","adapt with source 0.5838926174496645\n","adapt without source 0.5503355704697986\n","\n","Epoch: 0, accuracy:0.4774,  loss:1.3982,  val_accuracy:0.5408,  val_loss:1.1914,  \n","......................................................adapt model (without source) last loss:  0.066810742020607\n","\n","Epoch: 0, accuracy:0.4846,  loss:1.3799,  val_accuracy:0.5311,  val_loss:1.1982,  \n","..............................................................................................adapt model (with source) last loss:  0.06992741674184799\n","\n","knn_loss 0.5704697986577181\n","retrieval_loss 0.5838926174496645\n","adapt with source 0.5637583892617449\n","adapt without source 0.5637583892617449\n","\n","Epoch: 0, accuracy:0.4736,  loss:1.3912,  val_accuracy:0.5494,  val_loss:1.1858,  \n","....................................................................adapt model (without source) last loss:  0.07320612668991089\n","\n","Epoch: 0, accuracy:0.4707,  loss:1.3877,  val_accuracy:0.5232,  val_loss:1.1916,  \n",".........................................................................adapt model (with source) last loss:  0.07083016633987427\n","\n","knn_loss 0.5202702702702703\n","retrieval_loss 0.5\n","adapt with source 0.46621621621621623\n","adapt without source 0.49324324324324326\n","\n","Epoch: 0, accuracy:0.4767,  loss:1.4093,  val_accuracy:0.5711,  val_loss:1.1609,  \n",".............................................................................adapt model (without source) last loss:  0.06906093657016754\n","\n","Epoch: 0, accuracy:0.4826,  loss:1.3811,  val_accuracy:0.5359,  val_loss:1.2315,  \n","...................................................................................adapt model (with source) last loss:  0.05360889434814453\n","\n","knn_loss 0.49324324324324326\n","retrieval_loss 0.5540540540540541\n","adapt with source 0.5\n","adapt without source 0.527027027027027\n","\n","Epoch: 0, accuracy:0.4783,  loss:1.4128,  val_accuracy:0.5494,  val_loss:1.1745,  \n",".....................................................................................adapt model (without source) last loss:  0.04660388082265854\n","\n","Epoch: 0, accuracy:0.4787,  loss:1.3954,  val_accuracy:0.5284,  val_loss:1.2269,  \n","...................................................adapt model (with source) last loss:  0.10484503209590912\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5472972972972973\n","retrieval_loss 0.5405405405405406\n","adapt with source 0.5540540540540541\n","adapt without source 0.5\n","\n","Epoch: 0, accuracy:0.4883,  loss:1.3683,  val_accuracy:0.5569,  val_loss:1.1743,  \n",".......................................................................adapt model (without source) last loss:  0.08516941219568253\n","\n","Epoch: 0, accuracy:0.4752,  loss:1.3975,  val_accuracy:0.5449,  val_loss:1.1927,  \n","....................................................................................adapt model (with source) last loss:  0.10571889579296112\n","\n","knn_loss 0.4864864864864865\n","retrieval_loss 0.5540540540540541\n","adapt with source 0.4797297297297297\n","adapt without source 0.5\n","\n","Epoch: 0, accuracy:0.4875,  loss:1.3488,  val_accuracy:0.5644,  val_loss:1.1330,  \n","..................................................................adapt model (without source) last loss:  0.10699906200170517\n","\n","Epoch: 0, accuracy:0.4866,  loss:1.3675,  val_accuracy:0.5472,  val_loss:1.1809,  \n","....................................................................................................adapt model (with source) last loss:  0.05655393376946449\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.43243243243243246\n","retrieval_loss 0.5202702702702703\n","adapt with source 0.4594594594594595\n","adapt without source 0.4797297297297297\n","\n","Epoch: 0, accuracy:0.4707,  loss:1.4077,  val_accuracy:0.5262,  val_loss:1.2205,  \n","..........................................................................................adapt model (without source) last loss:  0.40494707226753235\n","\n","Epoch: 0, accuracy:0.4687,  loss:1.4026,  val_accuracy:0.5277,  val_loss:1.2135,  \n","..........................................................................................adapt model (with source) last loss:  0.03259292617440224\n","\n","knn_loss 0.5\n","retrieval_loss 0.5067567567567568\n","adapt with source 0.5337837837837838\n","adapt without source 0.5337837837837838\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.5001487393433702\n","np.mean(retrieval_loss_es) =  0.5329022310901506\n","np.mean(without_source_loss_es) =  0.5218293125340105\n","np.mean(with_source_loss_es) =  0.517662797025213\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.03784396232280964\n","np.std(retrieval_loss_es) =  0.030248335102016945\n","np.std(without_source_loss_es) =  0.03446784956764354\n","np.std(with_source_loss_es) =  0.04024521859587347\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.5031629811821006\n","np.mean(retrieval_loss_es) =  0.503377359433579\n","np.mean(without_source_loss_es) =  0.473162395636289\n","np.mean(with_source_loss_es) =  0.4671051937289704\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.04815145795431105\n","np.std(retrieval_loss_es) =  0.04738097658943402\n","np.std(without_source_loss_es) =  0.05939904402482415\n","np.std(with_source_loss_es) =  0.06868272794752545\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vYxHEfA53ooJ"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.5001487393433702\r\n","np.mean(retrieval_loss_es) =  0.5329022310901506\r\n","np.mean(without_source_loss_es) =  0.5218293125340105\r\n","np.mean(with_source_loss_es) =  0.517662797025213\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.03784396232280964\r\n","np.std(retrieval_loss_es) =  0.030248335102016945\r\n","np.std(without_source_loss_es) =  0.03446784956764354\r\n","np.std(with_source_loss_es) =  0.04024521859587347\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.5031629811821006\r\n","np.mean(retrieval_loss_es) =  0.503377359433579\r\n","np.mean(without_source_loss_es) =  0.473162395636289\r\n","np.mean(with_source_loss_es) =  0.4671051937289704\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.04815145795431105\r\n","np.std(retrieval_loss_es) =  0.04738097658943402\r\n","np.std(without_source_loss_es) =  0.05939904402482415\r\n","np.std(with_source_loss_es) =  0.06868272794752545\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"6Un46B__wbNI"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.5787729004171958\r\n","np.mean(arr_knn) =  0.5019907491384001\r\n","np.mean(arr_retrieval_loss) =  0.519485760928714\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.4629920188645021\r\n","np.mean(arr_normal_cdh_loss) =  0.4009341556321422\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.4960003627788863\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.6081081081081081\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.497038232059322\r\n","np.mean(arr_knn) =  0.4899373868630107\r\n","np.mean(arr_retrieval_loss) =  0.48990861672406955\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.41667873642559367\r\n","np.mean(arr_normal_cdh_loss) =  0.36369741344219764\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.4607537585037126\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.4867682562262906\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"Nb3qaZW2Tf0T"},"source":["multi runs\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.596252494104843\r\n","np.mean(arr_knn) =  0.5028369308906221\r\n","np.mean(arr_retrieval_loss) =  0.5350562307273716\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.47281516415744596\r\n","np.mean(arr_normal_cdh_loss) =  0.41957826954471245\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.49868764737892257\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.5833085434427716\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.041162097045133426\r\n","np.std(arr_knn) =  0.044034608484149425\r\n","np.std(arr_retrieval_loss) =  0.042307874841011034\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.03892795817498548\r\n","np.std(arr_normal_cdh_loss) =  0.04360502350468035\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.03727221642946003\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.0402225769494696\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.5413748609381609\r\n","np.mean(arr_knn) =  0.5076535748654931\r\n","np.mean(arr_retrieval_loss) =  0.5126662977566607\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.44937894844298165\r\n","np.mean(arr_normal_cdh_loss) =  0.4060282335696581\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.4831764787878637\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.5510401752285099\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.07455598914503703\r\n","np.std(arr_knn) =  0.06258286037550173\r\n","np.std(arr_retrieval_loss) =  0.06872053852069726\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.06714262135835385\r\n","np.std(arr_normal_cdh_loss) =  0.08040804958316043\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.06759348735481192\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.06323182419886726\r\n","\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"7L5OxMeuxEDs"},"source":["# Dataset: Seeds"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rd8l12egxI0p","executionInfo":{"elapsed":28162375,"status":"ok","timestamp":1611039197390,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"90372111-fc2c-4855-f8e3-009cfad24f3e"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/seeds_dataset.txt'\r\n","nominalCols = [] \r\n","numericCols = [0,1,2,3,4,5,6]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,6,),delim_whitespace=True);\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(7,),delim_whitespace=True);\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False, columns=[7])\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5, 6]\n","Index: []\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","5    0\n","6    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"rbDV0yGxxoZ7","executionInfo":{"elapsed":28162367,"status":"ok","timestamp":1611039197391,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"2826d348-3745-4305-e2bd-585b691de0d8"},"source":["X.head(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27</th>\n","      <td>-0.726041</td>\n","      <td>-0.682572</td>\n","      <td>-0.619290</td>\n","      <td>-0.528347</td>\n","      <td>-0.803061</td>\n","      <td>-0.797482</td>\n","      <td>-1.099453</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>0.245448</td>\n","      <td>0.253840</td>\n","      <td>0.479421</td>\n","      <td>0.333629</td>\n","      <td>0.396469</td>\n","      <td>0.847881</td>\n","      <td>0.895208</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.465927</td>\n","      <td>0.545509</td>\n","      <td>0.101872</td>\n","      <td>0.446750</td>\n","      <td>0.545084</td>\n","      <td>-0.584811</td>\n","      <td>0.242558</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            0         1         2         3         4         5         6\n","27  -0.726041 -0.682572 -0.619290 -0.528347 -0.803061 -0.797482 -1.099453\n","134  0.245448  0.253840  0.479421  0.333629  0.396469  0.847881  0.895208\n","36   0.465927  0.545509  0.101872  0.446750  0.545084 -0.584811  0.242558"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYZeTvI3xqLn","executionInfo":{"elapsed":28162360,"status":"ok","timestamp":1611039197392,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"f6600873-a842-4faf-c6f9-90ac72d367cc"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(210, 7)"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"markdown","metadata":{"id":"9eZpfdApxlTo"},"source":["# Trying 10 fold: Seeds"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMWcExu9xmnP","executionInfo":{"elapsed":30085195,"status":"ok","timestamp":1611041120236,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"fe273afe-030a-4a2e-a5ad-0650df2ca984"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.7982,  loss:0.4840,  val_accuracy:0.9512,  val_loss:0.1936,  \n","..............................................adapt model (without source) last loss:  0.011587092652916908\n","\n","Epoch: 0, accuracy:0.8106,  loss:0.4460,  val_accuracy:0.9268,  val_loss:0.2116,  \n","...........................................adapt model (with source) last loss:  0.004469115287065506\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8308,  loss:0.3871,  val_accuracy:0.9268,  val_loss:0.2162,  \n","...............................................................adapt model (without source) last loss:  0.001122248126193881\n","\n","Epoch: 0, accuracy:0.8192,  loss:0.4241,  val_accuracy:0.9024,  val_loss:0.2370,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..........................................................adapt model (with source) last loss:  0.0001325747143710032\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.8571428571428571\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8475,  loss:0.3745,  val_accuracy:0.9106,  val_loss:0.2323,  \n",".....................................adapt model (without source) last loss:  0.04175125062465668\n","\n","Epoch: 0, accuracy:0.8269,  loss:0.4049,  val_accuracy:0.9268,  val_loss:0.2005,  \n",".....................................................................................adapt model (with source) last loss:  0.0003079972229897976\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8278,  loss:0.4037,  val_accuracy:0.8943,  val_loss:0.2599,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0002,  \n",".........................................................adapt model (without source) last loss:  0.00018749186710920185\n","\n","Epoch: 0, accuracy:0.8333,  loss:0.3955,  val_accuracy:0.8780,  val_loss:0.2295,  \n","....................................adapt model (with source) last loss:  0.026986142620444298\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9523809523809523\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8608,  loss:0.3580,  val_accuracy:0.9268,  val_loss:0.2271,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0003,  \n","............................................................adapt model (without source) last loss:  4.956790871801786e-05\n","\n","Epoch: 0, accuracy:0.8702,  loss:0.3205,  val_accuracy:0.9106,  val_loss:0.2083,  \n","..................................................adapt model (with source) last loss:  0.016550865024328232\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.9523809523809523\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8222,  loss:0.4463,  val_accuracy:0.9187,  val_loss:0.2128,  \n","...................................adapt model (without source) last loss:  0.0039025696460157633\n","\n","Epoch: 0, accuracy:0.8518,  loss:0.3726,  val_accuracy:0.9024,  val_loss:0.2285,  \n","................................................adapt model (with source) last loss:  0.03274107351899147\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8312,  loss:0.4149,  val_accuracy:0.8943,  val_loss:0.2838,  \n","...........................................................adapt model (without source) last loss:  0.0051280660554766655\n","\n","Epoch: 0, accuracy:0.8235,  loss:0.4124,  val_accuracy:0.8862,  val_loss:0.2499,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0004,  \n","....................................................................................adapt model (with source) last loss:  5.9124737163074315e-05\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 1.0\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8338,  loss:0.4141,  val_accuracy:0.9106,  val_loss:0.2152,  \n","...................................................................................................adapt model (without source) last loss:  0.0013759213034063578\n","\n","Epoch: 0, accuracy:0.8201,  loss:0.4413,  val_accuracy:0.8862,  val_loss:0.2908,  \n","......................................................................................adapt model (with source) last loss:  0.01515144668519497\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 1.0\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8539,  loss:0.3533,  val_accuracy:0.9350,  val_loss:0.1604,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0002,  \n","......................adapt model (without source) last loss:  0.00013729413331020623\n","\n","Epoch: 0, accuracy:0.8346,  loss:0.3999,  val_accuracy:0.8537,  val_loss:0.2873,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0056,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0008,  \n","....................................................................................................\n","Epoch: 300, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","...............adapt model (with source) last loss:  0.00010384691995568573\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.8571428571428571\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8316,  loss:0.4152,  val_accuracy:0.9512,  val_loss:0.1902,  \n","..................................................................adapt model (without source) last loss:  0.0018432637443765998\n","\n","Epoch: 0, accuracy:0.8115,  loss:0.4389,  val_accuracy:0.9024,  val_loss:0.2346,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0007,  \n",".......................adapt model (with source) last loss:  0.0005765881505794823\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8068,  loss:0.4437,  val_accuracy:0.9187,  val_loss:0.2107,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0004,  \n","...adapt model (without source) last loss:  0.0002966039173770696\n","\n","Epoch: 0, accuracy:0.8162,  loss:0.4227,  val_accuracy:0.8780,  val_loss:0.2959,  \n","....................................................adapt model (with source) last loss:  0.00515333516523242\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.8571428571428571\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.7883,  loss:0.5090,  val_accuracy:0.8293,  val_loss:0.3569,  \n","..................................................adapt model (without source) last loss:  0.026923667639493942\n","\n","Epoch: 0, accuracy:0.8445,  loss:0.3737,  val_accuracy:0.9024,  val_loss:0.2246,  \n","..............................................................................................adapt model (with source) last loss:  0.002732194261625409\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8350,  loss:0.3763,  val_accuracy:0.8943,  val_loss:0.2547,  \n",".................................................adapt model (without source) last loss:  0.013640936464071274\n","\n","Epoch: 0, accuracy:0.8033,  loss:0.4554,  val_accuracy:0.8862,  val_loss:0.2643,  \n",".................................adapt model (with source) last loss:  0.04127003625035286\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.7982,  loss:0.4536,  val_accuracy:0.9350,  val_loss:0.2034,  \n","......................................adapt model (without source) last loss:  0.02616596221923828\n","\n","Epoch: 0, accuracy:0.8256,  loss:0.4143,  val_accuracy:0.8699,  val_loss:0.2711,  \n","......................................adapt model (with source) last loss:  0.015200825408101082\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.7695,  loss:0.4998,  val_accuracy:0.9187,  val_loss:0.2685,  \n","......................................................................adapt model (without source) last loss:  0.0015119471354410052\n","\n","Epoch: 0, accuracy:0.8183,  loss:0.4137,  val_accuracy:0.9268,  val_loss:0.2034,  \n","...........................................adapt model (with source) last loss:  0.02694648504257202\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 1.0\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8012,  loss:0.4455,  val_accuracy:0.8699,  val_loss:0.2512,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0001,  val_accuracy:1.0000,  val_loss:0.0001,  \n","...................................................................adapt model (without source) last loss:  2.485500772309024e-05\n","\n","Epoch: 0, accuracy:0.8243,  loss:0.4012,  val_accuracy:0.9593,  val_loss:0.1712,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0002,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..........adapt model (with source) last loss:  6.313315680017695e-06\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8466,  loss:0.4029,  val_accuracy:0.8699,  val_loss:0.2412,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0001,  val_accuracy:1.0000,  val_loss:0.0001,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 300, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","......................adapt model (without source) last loss:  2.558602147928468e-07\n","\n","Epoch: 0, accuracy:0.8389,  loss:0.3928,  val_accuracy:0.8943,  val_loss:0.2838,  \n","....................................adapt model (with source) last loss:  0.04592066630721092\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8415,  loss:0.3811,  val_accuracy:0.9106,  val_loss:0.2143,  \n","......................................................................adapt model (without source) last loss:  0.006568305194377899\n","\n","Epoch: 0, accuracy:0.8231,  loss:0.4180,  val_accuracy:0.9512,  val_loss:0.1855,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 300, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 400, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","......................................................adapt model (with source) last loss:  8.141103080561152e-08\n","\n","knn_loss 0.8095238095238095\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.8571428571428571\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8252,  loss:0.4083,  val_accuracy:0.7967,  val_loss:0.3962,  \n",".......................................................................adapt model (without source) last loss:  0.0028119483031332493\n","\n","Epoch: 0, accuracy:0.8655,  loss:0.3956,  val_accuracy:0.8862,  val_loss:0.2952,  \n","...........................................................adapt model (with source) last loss:  0.004500743933022022\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 1.0\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8539,  loss:0.3740,  val_accuracy:0.9106,  val_loss:0.2208,  \n","..........................................................adapt model (without source) last loss:  0.0016696684760972857\n","\n","Epoch: 0, accuracy:0.8543,  loss:0.3725,  val_accuracy:0.8862,  val_loss:0.3007,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0001,  val_accuracy:1.0000,  val_loss:0.0016,  \n","........adapt model (with source) last loss:  0.010006367228925228\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8252,  loss:0.4340,  val_accuracy:0.8780,  val_loss:0.2263,  \n",".........................adapt model (without source) last loss:  0.07660999149084091\n","\n","Epoch: 0, accuracy:0.8269,  loss:0.4272,  val_accuracy:0.9431,  val_loss:0.1781,  \n","..............................adapt model (with source) last loss:  0.03332408890128136\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8312,  loss:0.3817,  val_accuracy:0.8780,  val_loss:0.3016,  \n","..............................................................................................adapt model (without source) last loss:  0.008835342712700367\n","\n","Epoch: 0, accuracy:0.8106,  loss:0.4170,  val_accuracy:0.8293,  val_loss:0.3221,  \n","...................................................................adapt model (with source) last loss:  0.026374945417046547\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8239,  loss:0.3946,  val_accuracy:0.8537,  val_loss:0.3097,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0011,  \n","..........................................adapt model (without source) last loss:  0.0050788763910532\n","\n","Epoch: 0, accuracy:0.8025,  loss:0.4639,  val_accuracy:0.9024,  val_loss:0.2557,  \n","........................................................................................adapt model (with source) last loss:  0.0009908294305205345\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.8571428571428571\n","adapt without source 0.8571428571428571\n","\n","Epoch: 0, accuracy:0.8081,  loss:0.4462,  val_accuracy:0.8943,  val_loss:0.2176,  \n",".................................adapt model (without source) last loss:  0.028991660103201866\n","\n","Epoch: 0, accuracy:0.8282,  loss:0.4057,  val_accuracy:0.8943,  val_loss:0.2418,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0003,  \n","..........................................adapt model (with source) last loss:  8.24273083708249e-05\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8393,  loss:0.3737,  val_accuracy:0.8537,  val_loss:0.2815,  \n","..........................................................................adapt model (without source) last loss:  0.00922122411429882\n","\n","Epoch: 0, accuracy:0.8205,  loss:0.4295,  val_accuracy:0.8455,  val_loss:0.3228,  \n","...........................adapt model (with source) last loss:  0.04680265486240387\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8269,  loss:0.4275,  val_accuracy:0.8699,  val_loss:0.2897,  \n","..........................................................adapt model (without source) last loss:  0.00875720102339983\n","\n","Epoch: 0, accuracy:0.8295,  loss:0.3928,  val_accuracy:0.9024,  val_loss:0.2759,  \n",".......................................................adapt model (with source) last loss:  0.008310153149068356\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 1.0\n","adapt with source 0.9523809523809523\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8445,  loss:0.3753,  val_accuracy:0.8862,  val_loss:0.2619,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0001,  val_accuracy:0.9919,  val_loss:0.0116,  \n",".....adapt model (without source) last loss:  0.012418923899531364\n","\n","Epoch: 0, accuracy:0.8590,  loss:0.3322,  val_accuracy:0.9024,  val_loss:0.2286,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","................................................adapt model (with source) last loss:  1.2998307283851318e-05\n","\n","knn_loss 0.8095238095238095\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8316,  loss:0.4064,  val_accuracy:0.9268,  val_loss:0.2051,  \n","..................................................................................adapt model (without source) last loss:  0.0008617056300863624\n","\n","Epoch: 0, accuracy:0.8783,  loss:0.3345,  val_accuracy:0.9106,  val_loss:0.1881,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0002,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 300, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".................................................................................adapt model (with source) last loss:  9.594849359473301e-08\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8243,  loss:0.4277,  val_accuracy:0.8374,  val_loss:0.3082,  \n","....................................................................adapt model (without source) last loss:  0.001258977921679616\n","\n","Epoch: 0, accuracy:0.7819,  loss:0.4851,  val_accuracy:0.9024,  val_loss:0.2444,  \n","..................................................................adapt model (with source) last loss:  0.0023777359165251255\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8085,  loss:0.4919,  val_accuracy:0.9268,  val_loss:0.2627,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0016,  \n","........adapt model (without source) last loss:  0.0018782851984724402\n","\n","Epoch: 0, accuracy:0.8612,  loss:0.3644,  val_accuracy:0.8537,  val_loss:0.3290,  \n","........................................................................................adapt model (with source) last loss:  0.007324269041419029\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.7969,  loss:0.4500,  val_accuracy:0.8780,  val_loss:0.2500,  \n","...............................................adapt model (without source) last loss:  0.03541320189833641\n","\n","Epoch: 0, accuracy:0.8290,  loss:0.3997,  val_accuracy:0.9106,  val_loss:0.2447,  \n","...............................................................................adapt model (with source) last loss:  0.001757979509420693\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8488,  loss:0.3723,  val_accuracy:0.8943,  val_loss:0.2608,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n",".....................................................................................adapt model (without source) last loss:  1.7222419046447612e-05\n","\n","Epoch: 0, accuracy:0.8021,  loss:0.4639,  val_accuracy:0.8862,  val_loss:0.2612,  \n",".........................................................adapt model (with source) last loss:  0.021139249205589294\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.8571428571428571\n","adapt with source 1.0\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8440,  loss:0.3674,  val_accuracy:0.8780,  val_loss:0.2837,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0063,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0010,  \n","....................................................................................................\n","Epoch: 300, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0001,  \n","..adapt model (without source) last loss:  0.00015577352314721793\n","\n","Epoch: 0, accuracy:0.8346,  loss:0.3967,  val_accuracy:0.9268,  val_loss:0.1944,  \n","...................................................................................adapt model (with source) last loss:  0.003421815112233162\n","\n","knn_loss 0.7619047619047619\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9523809523809523\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8038,  loss:0.4434,  val_accuracy:0.8862,  val_loss:0.2679,  \n",".............................................................................................adapt model (without source) last loss:  0.001151715638116002\n","\n","Epoch: 0, accuracy:0.8385,  loss:0.3801,  val_accuracy:0.8780,  val_loss:0.2654,  \n","...................................................adapt model (with source) last loss:  0.024201326072216034\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8201,  loss:0.4106,  val_accuracy:0.8699,  val_loss:0.2936,  \n","..........................................................................adapt model (without source) last loss:  0.028920724987983704\n","\n","Epoch: 0, accuracy:0.7995,  loss:0.4340,  val_accuracy:0.9431,  val_loss:0.1842,  \n","........................................adapt model (with source) last loss:  0.018091140314936638\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 1.0\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8166,  loss:0.4217,  val_accuracy:0.9106,  val_loss:0.2239,  \n","...........................................................................................adapt model (without source) last loss:  0.0006250409060157835\n","\n","Epoch: 0, accuracy:0.8141,  loss:0.4228,  val_accuracy:0.8699,  val_loss:0.2710,  \n","...................................................adapt model (with source) last loss:  0.009434123523533344\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.7901,  loss:0.4562,  val_accuracy:0.9187,  val_loss:0.2037,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0005,  \n","...adapt model (without source) last loss:  0.000570421339944005\n","\n","Epoch: 0, accuracy:0.8033,  loss:0.4566,  val_accuracy:0.9106,  val_loss:0.2470,  \n",".............................adapt model (with source) last loss:  0.021049635484814644\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 1.0\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.7956,  loss:0.4809,  val_accuracy:0.8943,  val_loss:0.2599,  \n",".....................................adapt model (without source) last loss:  0.018511369824409485\n","\n","Epoch: 0, accuracy:0.8033,  loss:0.4318,  val_accuracy:0.8943,  val_loss:0.2492,  \n","............................................................................adapt model (with source) last loss:  0.0003179129562340677\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8265,  loss:0.4121,  val_accuracy:0.8699,  val_loss:0.2773,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0005,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","..........................................adapt model (without source) last loss:  6.520791430375539e-06\n","\n","Epoch: 0, accuracy:0.8175,  loss:0.4333,  val_accuracy:0.8862,  val_loss:0.2584,  \n",".................................................adapt model (with source) last loss:  0.015255400910973549\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 1.0\n","adapt with source 0.8571428571428571\n","adapt without source 0.8571428571428571\n","\n","Epoch: 0, accuracy:0.7982,  loss:0.4948,  val_accuracy:0.9268,  val_loss:0.2245,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0001,  val_accuracy:1.0000,  val_loss:0.0003,  \n","....................................................................................................\n","Epoch: 200, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n","....................................................................................................\n","Epoch: 300, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0000,  \n",".........................................................................................adapt model (without source) last loss:  2.674918277989491e-07\n","\n","Epoch: 0, accuracy:0.8166,  loss:0.4329,  val_accuracy:0.9106,  val_loss:0.2404,  \n","........................adapt model (with source) last loss:  0.03270123526453972\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.9047619047619048\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8252,  loss:0.4197,  val_accuracy:0.8374,  val_loss:0.3209,  \n","....................................adapt model (without source) last loss:  0.034923162311315536\n","\n","Epoch: 0, accuracy:0.8239,  loss:0.4217,  val_accuracy:0.9024,  val_loss:0.2653,  \n","..................................................adapt model (with source) last loss:  0.010016088373959064\n","\n","knn_loss 0.9523809523809523\n","retrieval_loss 0.9523809523809523\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8325,  loss:0.4043,  val_accuracy:0.9187,  val_loss:0.2186,  \n",".............................................adapt model (without source) last loss:  0.01892084814608097\n","\n","Epoch: 0, accuracy:0.8055,  loss:0.4560,  val_accuracy:0.9024,  val_loss:0.2408,  \n","...........................................adapt model (with source) last loss:  0.09846116602420807\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9047619047619048\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.7725,  loss:0.5356,  val_accuracy:0.8943,  val_loss:0.2359,  \n",".............................................................................adapt model (without source) last loss:  0.004777366761118174\n","\n","Epoch: 0, accuracy:0.8565,  loss:0.3725,  val_accuracy:0.8699,  val_loss:0.3296,  \n","............................adapt model (with source) last loss:  0.17479069530963898\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8179,  loss:0.4402,  val_accuracy:0.8943,  val_loss:0.2947,  \n",".........................................................adapt model (without source) last loss:  0.0174595694988966\n","\n","Epoch: 0, accuracy:0.8488,  loss:0.3625,  val_accuracy:0.9187,  val_loss:0.2413,  \n","...............................................adapt model (with source) last loss:  0.03803485631942749\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","Epoch: 0, accuracy:0.8192,  loss:0.4235,  val_accuracy:0.8455,  val_loss:0.3484,  \n","..............................................adapt model (without source) last loss:  0.036638252437114716\n","\n","Epoch: 0, accuracy:0.8265,  loss:0.4156,  val_accuracy:0.9268,  val_loss:0.2245,  \n","..............................................................adapt model (with source) last loss:  0.004002935718744993\n","\n","knn_loss 0.8571428571428571\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8171,  loss:0.4245,  val_accuracy:0.8943,  val_loss:0.2358,  \n","..........................................adapt model (without source) last loss:  0.012254505418241024\n","\n","Epoch: 0, accuracy:0.8201,  loss:0.4083,  val_accuracy:0.8943,  val_loss:0.2229,  \n","...............................adapt model (with source) last loss:  0.01736604981124401\n","\n","knn_loss 1.0\n","retrieval_loss 1.0\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8389,  loss:0.3781,  val_accuracy:0.8943,  val_loss:0.2382,  \n","....................................................adapt model (without source) last loss:  0.007776092737913132\n","\n","Epoch: 0, accuracy:0.8676,  loss:0.3476,  val_accuracy:0.8862,  val_loss:0.2298,  \n","..............................adapt model (with source) last loss:  0.023184802383184433\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9523809523809523\n","adapt with source 0.9523809523809523\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8350,  loss:0.4270,  val_accuracy:0.8862,  val_loss:0.2746,  \n",".........................................adapt model (without source) last loss:  0.025795020163059235\n","\n","Epoch: 0, accuracy:0.8350,  loss:0.4076,  val_accuracy:0.8862,  val_loss:0.2944,  \n","...................................................adapt model (with source) last loss:  0.028155656531453133\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 1.0\n","adapt without source 1.0\n","\n","Epoch: 0, accuracy:0.8295,  loss:0.3909,  val_accuracy:0.8862,  val_loss:0.2538,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0000,  val_accuracy:1.0000,  val_loss:0.0006,  \n","..................................adapt model (without source) last loss:  0.00021503154130186886\n","\n","Epoch: 0, accuracy:0.8252,  loss:0.4350,  val_accuracy:0.9024,  val_loss:0.2329,  \n",".......................................................................................adapt model (with source) last loss:  0.0006294353515841067\n","\n","knn_loss 0.8095238095238095\n","retrieval_loss 0.8095238095238095\n","adapt with source 0.8571428571428571\n","adapt without source 0.9047619047619048\n","\n","Epoch: 0, accuracy:0.8552,  loss:0.3523,  val_accuracy:0.8699,  val_loss:0.2447,  \n","........................................adapt model (without source) last loss:  0.02550526335835457\n","\n","Epoch: 0, accuracy:0.8153,  loss:0.4438,  val_accuracy:0.9024,  val_loss:0.2449,  \n","...........................................................adapt model (with source) last loss:  0.008844861760735512\n","\n","knn_loss 0.9047619047619048\n","retrieval_loss 0.9047619047619048\n","adapt with source 0.9523809523809523\n","adapt without source 0.9523809523809523\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.9152380952380953\n","np.mean(retrieval_loss_es) =  0.9352380952380953\n","np.mean(without_source_loss_es) =  0.9533333333333335\n","np.mean(with_source_loss_es) =  0.9533333333333333\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.05576920370269467\n","np.std(retrieval_loss_es) =  0.055336529700319805\n","np.std(without_source_loss_es) =  0.04516535505287382\n","np.std(with_source_loss_es) =  0.04311036303907153\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.9170184445184445\n","np.mean(retrieval_loss_es) =  0.9391534391534391\n","np.mean(without_source_loss_es) =  0.9543791208791209\n","np.mean(with_source_loss_es) =  0.9544554334554334\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.05750194746924557\n","np.std(retrieval_loss_es) =  0.05448333538284092\n","np.std(without_source_loss_es) =  0.045989718353213895\n","np.std(with_source_loss_es) =  0.044442472696180145\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2UBCWu0537rB"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.9152380952380953\r\n","np.mean(retrieval_loss_es) =  0.9352380952380953\r\n","np.mean(without_source_loss_es) =  0.9533333333333335\r\n","np.mean(with_source_loss_es) =  0.9533333333333333\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.05576920370269467\r\n","np.std(retrieval_loss_es) =  0.055336529700319805\r\n","np.std(without_source_loss_es) =  0.04516535505287382\r\n","np.std(with_source_loss_es) =  0.04311036303907153\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.9170184445184445\r\n","np.mean(retrieval_loss_es) =  0.9391534391534391\r\n","np.mean(without_source_loss_es) =  0.9543791208791209\r\n","np.mean(with_source_loss_es) =  0.9544554334554334\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.05750194746924557\r\n","np.std(retrieval_loss_es) =  0.05448333538284092\r\n","np.std(without_source_loss_es) =  0.045989718353213895\r\n","np.std(with_source_loss_es) =  0.044442472696180145\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"TsmLgV4LzpP1"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.8952380952380953\r\n","np.mean(arr_knn) =  0.880952380952381\r\n","np.mean(arr_retrieval_loss) =  0.8904761904761905\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9\r\n","np.mean(arr_normal_cdh_loss) =  0.8857142857142858\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9523809523809523\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.8982647907647909\r\n","np.mean(arr_knn) =  0.8878270803270801\r\n","np.mean(arr_retrieval_loss) =  0.89241822991823\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9047462722462722\r\n","np.mean(arr_normal_cdh_loss) =  0.8898785473785473\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9039526214526215\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9444444444444445\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"KHGc58y_DKVA"},"source":["Multi runs\r\n","\r\n","\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9495238095238094\r\n","np.mean(arr_knn) =  0.9209523809523809\r\n","np.mean(arr_retrieval_loss) =  0.9333333333333331\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9428571428571427\r\n","np.mean(arr_normal_cdh_loss) =  0.8638095238095239\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9533333333333333\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9485714285714285\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.04986148614365114\r\n","np.std(arr_knn) =  0.053545496369030846\r\n","np.std(arr_retrieval_loss) =  0.04761904761904762\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.05387480237611791\r\n","np.std(arr_normal_cdh_loss) =  0.0719094921181435\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.049934197062546024\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.05114560602703829\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.9531132756132756\r\n","np.mean(arr_knn) =  0.9259126244126245\r\n","np.mean(arr_retrieval_loss) =  0.9365227735227737\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9475553150553152\r\n","np.mean(arr_normal_cdh_loss) =  0.8667980722980723\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9563701298701298\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9527435527435528\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.045773947048098146\r\n","np.std(arr_knn) =  0.05110608134934581\r\n","np.std(arr_retrieval_loss) =  0.048890137004640136\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.0483200172401884\r\n","np.std(arr_normal_cdh_loss) =  0.0728159002043527\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.04645073407012013\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.04559015734843396\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"MHE8m6yJHbJi"},"source":["# Dataset: Pima\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5NBpSlZHe_d","executionInfo":{"elapsed":30085818,"status":"ok","timestamp":1611041120868,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"41623d29-867f-4b81-901f-7707af4f7001"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/pima-indians-diabetes.csv'\r\n","nominalCols = [] \r\n","numericCols = [0,1,2,3,4,5,6,7]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,6,7,));\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(8,));\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False, columns=[8])\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5, 6, 7]\n","Index: []\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","5    0\n","6    0\n","7    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"7Ww6lRSqHvAY","executionInfo":{"elapsed":30085799,"status":"ok","timestamp":1611041120868,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"22425a71-d1fa-45b1-a7fd-6c480076b2ce"},"source":["X.head(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>133</th>\n","      <td>1.233880</td>\n","      <td>-1.154694</td>\n","      <td>0.253036</td>\n","      <td>0.656358</td>\n","      <td>-0.692891</td>\n","      <td>0.800533</td>\n","      <td>-0.044928</td>\n","      <td>0.490030</td>\n","    </tr>\n","    <tr>\n","      <th>722</th>\n","      <td>-0.844885</td>\n","      <td>0.879621</td>\n","      <td>-0.057150</td>\n","      <td>0.530902</td>\n","      <td>0.409837</td>\n","      <td>-0.341740</td>\n","      <td>-0.371101</td>\n","      <td>0.745293</td>\n","    </tr>\n","    <tr>\n","      <th>393</th>\n","      <td>0.046014</td>\n","      <td>-0.153185</td>\n","      <td>0.149641</td>\n","      <td>-0.535475</td>\n","      <td>0.062521</td>\n","      <td>-1.255559</td>\n","      <td>-0.026807</td>\n","      <td>0.319855</td>\n","    </tr>\n","    <tr>\n","      <th>643</th>\n","      <td>0.046014</td>\n","      <td>-0.966911</td>\n","      <td>-3.572597</td>\n","      <td>-1.288212</td>\n","      <td>-0.692891</td>\n","      <td>-0.506735</td>\n","      <td>0.417150</td>\n","      <td>-0.190672</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            0         1         2  ...         5         6         7\n","133  1.233880 -1.154694  0.253036  ...  0.800533 -0.044928  0.490030\n","722 -0.844885  0.879621 -0.057150  ... -0.341740 -0.371101  0.745293\n","393  0.046014 -0.153185  0.149641  ... -1.255559 -0.026807  0.319855\n","643  0.046014 -0.966911 -3.572597  ... -0.506735  0.417150 -0.190672\n","\n","[4 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"1tZ10HSTH25e","executionInfo":{"elapsed":30085786,"status":"ok","timestamp":1611041120869,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"a11ad41e-be25-4225-a262-cb522325ef96"},"source":["y.head(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>8_0</th>\n","      <th>8_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>133</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>722</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>393</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>643</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     8_0  8_1\n","133    1    0\n","722    0    1\n","393    1    0\n","643    1    0"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"markdown","metadata":{"id":"7YKedqQEH6Xv"},"source":["# Trying 10 fold: Pima"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXZcsSiRH9Wa","executionInfo":{"elapsed":33209485,"status":"ok","timestamp":1611044244579,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"ec2be644-fca4-410f-82ee-331ddbd4a991"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.7147,  loss:0.5346,  val_accuracy:0.7494,  val_loss:0.4976,  \n","......................................................adapt model (without source) last loss:  0.2958773970603943\n","\n","Epoch: 0, accuracy:0.7235,  loss:0.5421,  val_accuracy:0.7108,  val_loss:0.5432,  \n","...........................................adapt model (with source) last loss:  0.32708248496055603\n","\n","knn_loss 0.6753246753246753\n","retrieval_loss 0.6623376623376623\n","adapt with source 0.6883116883116883\n","adapt without source 0.6883116883116883\n","\n","Epoch: 0, accuracy:0.7174,  loss:0.5479,  val_accuracy:0.7253,  val_loss:0.5185,  \n","............................................................................adapt model (without source) last loss:  0.14192257821559906\n","\n","Epoch: 0, accuracy:0.7286,  loss:0.5390,  val_accuracy:0.7373,  val_loss:0.5291,  \n","......................................adapt model (with source) last loss:  0.32913151383399963\n","\n","knn_loss 0.7662337662337663\n","retrieval_loss 0.7402597402597403\n","adapt with source 0.7662337662337663\n","adapt without source 0.6493506493506493\n","\n","Epoch: 0, accuracy:0.7281,  loss:0.5282,  val_accuracy:0.7470,  val_loss:0.4941,  \n","...........................................................adapt model (without source) last loss:  0.12420815229415894\n","\n","Epoch: 0, accuracy:0.7311,  loss:0.5290,  val_accuracy:0.7398,  val_loss:0.4836,  \n","..........................................................adapt model (with source) last loss:  0.2857646048069\n","\n","knn_loss 0.7532467532467533\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.6883116883116883\n","adapt without source 0.6623376623376623\n","\n","Epoch: 0, accuracy:0.7060,  loss:0.5593,  val_accuracy:0.6988,  val_loss:0.5443,  \n","........................................adapt model (without source) last loss:  0.2297254055738449\n","\n","Epoch: 0, accuracy:0.7117,  loss:0.5470,  val_accuracy:0.7470,  val_loss:0.5027,  \n","........................................adapt model (with source) last loss:  0.28049540519714355\n","\n","knn_loss 0.7662337662337663\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.7532467532467533\n","adapt without source 0.7792207792207793\n","\n","Epoch: 0, accuracy:0.7126,  loss:0.5502,  val_accuracy:0.7831,  val_loss:0.4624,  \n","......................................adapt model (without source) last loss:  0.30217787623405457\n","\n","Epoch: 0, accuracy:0.7329,  loss:0.5204,  val_accuracy:0.7253,  val_loss:0.5151,  \n","...................................adapt model (with source) last loss:  0.34675487875938416\n","\n","knn_loss 0.6883116883116883\n","retrieval_loss 0.7272727272727273\n","adapt with source 0.6233766233766234\n","adapt without source 0.6233766233766234\n","\n","Epoch: 0, accuracy:0.7271,  loss:0.5435,  val_accuracy:0.7012,  val_loss:0.5871,  \n","......................................................................adapt model (without source) last loss:  0.7157052755355835\n","\n","Epoch: 0, accuracy:0.7292,  loss:0.5442,  val_accuracy:0.7229,  val_loss:0.5205,  \n",".........................................adapt model (with source) last loss:  0.33007267117500305\n","\n","knn_loss 0.7142857142857143\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.6623376623376623\n","adapt without source 0.6753246753246753\n","\n","Epoch: 0, accuracy:0.7224,  loss:0.5451,  val_accuracy:0.7301,  val_loss:0.5195,  \n","............................................adapt model (without source) last loss:  0.36762672662734985\n","\n","Epoch: 0, accuracy:0.7187,  loss:0.5441,  val_accuracy:0.7422,  val_loss:0.5213,  \n","...........................................adapt model (with source) last loss:  0.4110279083251953\n","\n","knn_loss 0.7532467532467533\n","retrieval_loss 0.7662337662337663\n","adapt with source 0.7142857142857143\n","adapt without source 0.7142857142857143\n","\n","Epoch: 0, accuracy:0.7255,  loss:0.5383,  val_accuracy:0.7157,  val_loss:0.5284,  \n","..................................adapt model (without source) last loss:  0.3033379018306732\n","\n","Epoch: 0, accuracy:0.7316,  loss:0.5294,  val_accuracy:0.7831,  val_loss:0.4838,  \n","..............................adapt model (with source) last loss:  0.3269990086555481\n","\n","knn_loss 0.7012987012987013\n","retrieval_loss 0.6493506493506493\n","adapt with source 0.7272727272727273\n","adapt without source 0.6493506493506493\n","\n","Epoch: 0, accuracy:0.7140,  loss:0.5614,  val_accuracy:0.7115,  val_loss:0.5577,  \n","....................................................................adapt model (without source) last loss:  0.14202038943767548\n","\n","Epoch: 0, accuracy:0.7305,  loss:0.5336,  val_accuracy:0.8077,  val_loss:0.4518,  \n",".......................................adapt model (with source) last loss:  0.2371578961610794\n","\n","knn_loss 0.7236842105263158\n","retrieval_loss 0.6710526315789473\n","adapt with source 0.631578947368421\n","adapt without source 0.6842105263157895\n","\n","Epoch: 0, accuracy:0.7273,  loss:0.5416,  val_accuracy:0.7284,  val_loss:0.5062,  \n","...................................................................adapt model (without source) last loss:  0.20665191113948822\n","\n","Epoch: 0, accuracy:0.7126,  loss:0.5578,  val_accuracy:0.7452,  val_loss:0.5230,  \n","................................................adapt model (with source) last loss:  0.3025446832180023\n","\n","knn_loss 0.8026315789473685\n","retrieval_loss 0.7631578947368421\n","adapt with source 0.7368421052631579\n","adapt without source 0.75\n","\n","Epoch: 0, accuracy:0.7197,  loss:0.5446,  val_accuracy:0.7639,  val_loss:0.4776,  \n","...................................................................adapt model (without source) last loss:  0.1635829210281372\n","\n","Epoch: 0, accuracy:0.7182,  loss:0.5403,  val_accuracy:0.7639,  val_loss:0.4861,  \n",".....................................adapt model (with source) last loss:  0.2870892584323883\n","\n","knn_loss 0.6883116883116883\n","retrieval_loss 0.6103896103896104\n","adapt with source 0.5324675324675324\n","adapt without source 0.5584415584415584\n","\n","Epoch: 0, accuracy:0.7255,  loss:0.5341,  val_accuracy:0.7422,  val_loss:0.4949,  \n",".................................................adapt model (without source) last loss:  0.21453197300434113\n","\n","Epoch: 0, accuracy:0.7284,  loss:0.5564,  val_accuracy:0.7373,  val_loss:0.5226,  \n","...........................................................adapt model (with source) last loss:  0.26693251729011536\n","\n","knn_loss 0.6883116883116883\n","retrieval_loss 0.7142857142857143\n","adapt with source 0.7402597402597403\n","adapt without source 0.6623376623376623\n","\n","Epoch: 0, accuracy:0.7307,  loss:0.5343,  val_accuracy:0.7807,  val_loss:0.4527,  \n","......................................................adapt model (without source) last loss:  0.27946823835372925\n","\n","Epoch: 0, accuracy:0.7268,  loss:0.5315,  val_accuracy:0.7494,  val_loss:0.5096,  \n",".................................................adapt model (with source) last loss:  0.29282376170158386\n","\n","knn_loss 0.7402597402597403\n","retrieval_loss 0.7662337662337663\n","adapt with source 0.6883116883116883\n","adapt without source 0.7532467532467533\n","\n","Epoch: 0, accuracy:0.7194,  loss:0.5436,  val_accuracy:0.7349,  val_loss:0.4934,  \n","........................................................adapt model (without source) last loss:  0.2533753216266632\n","\n","Epoch: 0, accuracy:0.7281,  loss:0.5465,  val_accuracy:0.7325,  val_loss:0.5283,  \n","........................................adapt model (with source) last loss:  0.3341037333011627\n","\n","knn_loss 0.7402597402597403\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.7012987012987013\n","adapt without source 0.7402597402597403\n","\n","Epoch: 0, accuracy:0.7207,  loss:0.5393,  val_accuracy:0.7301,  val_loss:0.5172,  \n","...............................................................................adapt model (without source) last loss:  0.16287364065647125\n","\n","Epoch: 0, accuracy:0.7133,  loss:0.5646,  val_accuracy:0.7446,  val_loss:0.5377,  \n","................................................adapt model (with source) last loss:  0.4010597765445709\n","\n","knn_loss 0.7012987012987013\n","retrieval_loss 0.6363636363636364\n","adapt with source 0.6753246753246753\n","adapt without source 0.6883116883116883\n","\n","Epoch: 0, accuracy:0.7232,  loss:0.5492,  val_accuracy:0.7470,  val_loss:0.5222,  \n","...........................................................adapt model (without source) last loss:  0.1411730945110321\n","\n","Epoch: 0, accuracy:0.7174,  loss:0.5448,  val_accuracy:0.7349,  val_loss:0.5041,  \n","...........................................................adapt model (with source) last loss:  0.22606538236141205\n","\n","knn_loss 0.7142857142857143\n","retrieval_loss 0.6883116883116883\n","adapt with source 0.6233766233766234\n","adapt without source 0.7272727272727273\n","\n","Epoch: 0, accuracy:0.7207,  loss:0.5448,  val_accuracy:0.8000,  val_loss:0.4802,  \n","..........................................adapt model (without source) last loss:  0.2866460680961609\n","\n","Epoch: 0, accuracy:0.7178,  loss:0.5470,  val_accuracy:0.7422,  val_loss:0.5054,  \n","...............................adapt model (with source) last loss:  0.4458179473876953\n","\n","knn_loss 0.7012987012987013\n","retrieval_loss 0.7532467532467533\n","adapt with source 0.7272727272727273\n","adapt without source 0.8181818181818182\n","\n","Epoch: 0, accuracy:0.7149,  loss:0.5523,  val_accuracy:0.7301,  val_loss:0.4994,  \n","..........................................adapt model (without source) last loss:  0.2460823357105255\n","\n","Epoch: 0, accuracy:0.7144,  loss:0.5527,  val_accuracy:0.7494,  val_loss:0.5451,  \n","............................................................adapt model (with source) last loss:  0.21329551935195923\n","\n","knn_loss 0.6753246753246753\n","retrieval_loss 0.6883116883116883\n","adapt with source 0.6883116883116883\n","adapt without source 0.5844155844155844\n","\n","Epoch: 0, accuracy:0.7246,  loss:0.5378,  val_accuracy:0.7596,  val_loss:0.4732,  \n","..................................................................................adapt model (without source) last loss:  0.22930921614170074\n","\n","Epoch: 0, accuracy:0.7343,  loss:0.5271,  val_accuracy:0.7284,  val_loss:0.5076,  \n",".........................................adapt model (with source) last loss:  0.3498634994029999\n","\n","knn_loss 0.7368421052631579\n","retrieval_loss 0.7763157894736842\n","adapt with source 0.6842105263157895\n","adapt without source 0.618421052631579\n","\n","Epoch: 0, accuracy:0.7058,  loss:0.5639,  val_accuracy:0.7812,  val_loss:0.4664,  \n",".....................................................adapt model (without source) last loss:  0.1944570690393448\n","\n","Epoch: 0, accuracy:0.7155,  loss:0.5462,  val_accuracy:0.7380,  val_loss:0.5211,  \n",".........................................adapt model (with source) last loss:  0.3512202799320221\n","\n","knn_loss 0.8421052631578947\n","retrieval_loss 0.8157894736842105\n","adapt with source 0.6973684210526315\n","adapt without source 0.75\n","\n","Epoch: 0, accuracy:0.7199,  loss:0.5545,  val_accuracy:0.7494,  val_loss:0.4719,  \n","...................................................adapt model (without source) last loss:  0.22687126696109772\n","\n","Epoch: 0, accuracy:0.7194,  loss:0.5548,  val_accuracy:0.7639,  val_loss:0.4837,  \n","..........................................adapt model (with source) last loss:  0.2784407138824463\n","\n","knn_loss 0.7402597402597403\n","retrieval_loss 0.6493506493506493\n","adapt with source 0.7402597402597403\n","adapt without source 0.7272727272727273\n","\n","Epoch: 0, accuracy:0.7183,  loss:0.5425,  val_accuracy:0.7494,  val_loss:0.5027,  \n","....................................................adapt model (without source) last loss:  0.387310266494751\n","\n","Epoch: 0, accuracy:0.7136,  loss:0.5517,  val_accuracy:0.7663,  val_loss:0.4769,  \n","...........................................adapt model (with source) last loss:  0.2659877836704254\n","\n","knn_loss 0.7662337662337663\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.7792207792207793\n","adapt without source 0.7662337662337663\n","\n","Epoch: 0, accuracy:0.7201,  loss:0.5506,  val_accuracy:0.7542,  val_loss:0.5027,  \n",".....................................adapt model (without source) last loss:  0.22521518170833588\n","\n","Epoch: 0, accuracy:0.7238,  loss:0.5300,  val_accuracy:0.7398,  val_loss:0.4884,  \n","................................................adapt model (with source) last loss:  0.41683128476142883\n","\n","knn_loss 0.7922077922077922\n","retrieval_loss 0.7402597402597403\n","adapt with source 0.7402597402597403\n","adapt without source 0.7012987012987013\n","\n","Epoch: 0, accuracy:0.7324,  loss:0.5396,  val_accuracy:0.7831,  val_loss:0.4576,  \n","............................................................................adapt model (without source) last loss:  0.12507490813732147\n","\n","Epoch: 0, accuracy:0.7301,  loss:0.5372,  val_accuracy:0.7614,  val_loss:0.5053,  \n","..........................................adapt model (with source) last loss:  0.23175790905952454\n","\n","knn_loss 0.7012987012987013\n","retrieval_loss 0.7272727272727273\n","adapt with source 0.6623376623376623\n","adapt without source 0.6233766233766234\n","\n","Epoch: 0, accuracy:0.7094,  loss:0.5559,  val_accuracy:0.7205,  val_loss:0.5325,  \n","...................................................adapt model (without source) last loss:  0.4614661931991577\n","\n","Epoch: 0, accuracy:0.7139,  loss:0.5482,  val_accuracy:0.7542,  val_loss:0.5047,  \n",".......................................................................adapt model (with source) last loss:  0.19087539613246918\n","\n","knn_loss 0.7792207792207793\n","retrieval_loss 0.6753246753246753\n","adapt with source 0.6883116883116883\n","adapt without source 0.7012987012987013\n","\n","Epoch: 0, accuracy:0.7163,  loss:0.5486,  val_accuracy:0.7590,  val_loss:0.4915,  \n",".......................................................................adapt model (without source) last loss:  0.24074140191078186\n","\n","Epoch: 0, accuracy:0.7210,  loss:0.5393,  val_accuracy:0.7711,  val_loss:0.4628,  \n","..................................adapt model (with source) last loss:  0.3509659469127655\n","\n","knn_loss 0.7662337662337663\n","retrieval_loss 0.7662337662337663\n","adapt with source 0.7012987012987013\n","adapt without source 0.7272727272727273\n","\n","Epoch: 0, accuracy:0.7406,  loss:0.5216,  val_accuracy:0.7446,  val_loss:0.4974,  \n",".....................................................................................adapt model (without source) last loss:  0.2739075720310211\n","\n","Epoch: 0, accuracy:0.7279,  loss:0.5261,  val_accuracy:0.7711,  val_loss:0.4650,  \n",".....................................adapt model (with source) last loss:  0.2659911513328552\n","\n","knn_loss 0.7142857142857143\n","retrieval_loss 0.6883116883116883\n","adapt with source 0.6233766233766234\n","adapt without source 0.6363636363636364\n","\n","Epoch: 0, accuracy:0.7175,  loss:0.5610,  val_accuracy:0.6964,  val_loss:0.5403,  \n","...................................adapt model (without source) last loss:  0.3530782163143158\n","\n","Epoch: 0, accuracy:0.7315,  loss:0.5392,  val_accuracy:0.7470,  val_loss:0.4802,  \n","...............................................adapt model (with source) last loss:  0.22408324480056763\n","\n","knn_loss 0.6883116883116883\n","retrieval_loss 0.6623376623376623\n","adapt with source 0.7012987012987013\n","adapt without source 0.6883116883116883\n","\n","Epoch: 0, accuracy:0.7140,  loss:0.5437,  val_accuracy:0.7740,  val_loss:0.4621,  \n","..................................................adapt model (without source) last loss:  0.1762263923883438\n","\n","Epoch: 0, accuracy:0.7315,  loss:0.5369,  val_accuracy:0.7308,  val_loss:0.4848,  \n","...........................................adapt model (with source) last loss:  0.324753075838089\n","\n","knn_loss 0.6842105263157895\n","retrieval_loss 0.6578947368421053\n","adapt with source 0.6710526315789473\n","adapt without source 0.6710526315789473\n","\n","Epoch: 0, accuracy:0.7287,  loss:0.5413,  val_accuracy:0.7764,  val_loss:0.4731,  \n","...........................................adapt model (without source) last loss:  0.2236628383398056\n","\n","Epoch: 0, accuracy:0.7262,  loss:0.5415,  val_accuracy:0.7404,  val_loss:0.5433,  \n",".......................................................adapt model (with source) last loss:  0.17696227133274078\n","\n","knn_loss 0.75\n","retrieval_loss 0.7368421052631579\n","adapt with source 0.6578947368421053\n","adapt without source 0.631578947368421\n","\n","Epoch: 0, accuracy:0.7282,  loss:0.5412,  val_accuracy:0.7108,  val_loss:0.5167,  \n","........................................................adapt model (without source) last loss:  0.24832430481910706\n","\n","Epoch: 0, accuracy:0.7239,  loss:0.5484,  val_accuracy:0.7349,  val_loss:0.5170,  \n","......................................................................adapt model (with source) last loss:  0.24390216171741486\n","\n","knn_loss 0.8181818181818182\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.7272727272727273\n","adapt without source 0.7142857142857143\n","\n","Epoch: 0, accuracy:0.7311,  loss:0.5362,  val_accuracy:0.7325,  val_loss:0.5332,  \n","..............................................adapt model (without source) last loss:  0.20863860845565796\n","\n","Epoch: 0, accuracy:0.7243,  loss:0.5419,  val_accuracy:0.7590,  val_loss:0.4745,  \n",".......................................adapt model (with source) last loss:  0.3096889853477478\n","\n","knn_loss 0.7272727272727273\n","retrieval_loss 0.7142857142857143\n","adapt with source 0.6493506493506493\n","adapt without source 0.7272727272727273\n","\n","Epoch: 0, accuracy:0.7123,  loss:0.5570,  val_accuracy:0.7229,  val_loss:0.5117,  \n","..............................................adapt model (without source) last loss:  0.19314490258693695\n","\n","Epoch: 0, accuracy:0.7437,  loss:0.5257,  val_accuracy:0.7614,  val_loss:0.4830,  \n",".............................................adapt model (with source) last loss:  0.18394704163074493\n","\n","knn_loss 0.7922077922077922\n","retrieval_loss 0.7272727272727273\n","adapt with source 0.7532467532467533\n","adapt without source 0.7532467532467533\n","\n","Epoch: 0, accuracy:0.7259,  loss:0.5266,  val_accuracy:0.7566,  val_loss:0.4751,  \n","..............................................................adapt model (without source) last loss:  0.2278055101633072\n","\n","Epoch: 0, accuracy:0.7243,  loss:0.5273,  val_accuracy:0.7349,  val_loss:0.5035,  \n","...............................................................adapt model (with source) last loss:  0.21473589539527893\n","\n","knn_loss 0.7142857142857143\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.6363636363636364\n","adapt without source 0.6623376623376623\n","\n","Epoch: 0, accuracy:0.7394,  loss:0.5206,  val_accuracy:0.7349,  val_loss:0.4949,  \n","...................................................................adapt model (without source) last loss:  0.25300103425979614\n","\n","Epoch: 0, accuracy:0.7370,  loss:0.5222,  val_accuracy:0.8000,  val_loss:0.4222,  \n","...............................................adapt model (with source) last loss:  0.27458518743515015\n","\n","knn_loss 0.6883116883116883\n","retrieval_loss 0.6623376623376623\n","adapt with source 0.7012987012987013\n","adapt without source 0.6753246753246753\n","\n","Epoch: 0, accuracy:0.7141,  loss:0.5424,  val_accuracy:0.7494,  val_loss:0.4829,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0007,  val_accuracy:0.9542,  val_loss:0.1734,  \n","..adapt model (without source) last loss:  0.17212142050266266\n","\n","Epoch: 0, accuracy:0.7151,  loss:0.5487,  val_accuracy:0.7566,  val_loss:0.4904,  \n","............................................adapt model (with source) last loss:  0.3103741705417633\n","\n","knn_loss 0.7142857142857143\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.7142857142857143\n","adapt without source 0.7532467532467533\n","\n","Epoch: 0, accuracy:0.7029,  loss:0.5712,  val_accuracy:0.7518,  val_loss:0.5257,  \n",".........................................adapt model (without source) last loss:  0.21483948826789856\n","\n","Epoch: 0, accuracy:0.7085,  loss:0.5721,  val_accuracy:0.7253,  val_loss:0.5161,  \n",".................................................................adapt model (with source) last loss:  0.3640294373035431\n","\n","knn_loss 0.7142857142857143\n","retrieval_loss 0.7532467532467533\n","adapt with source 0.6493506493506493\n","adapt without source 0.6623376623376623\n","\n","Epoch: 0, accuracy:0.7141,  loss:0.5471,  val_accuracy:0.7783,  val_loss:0.4858,  \n","..................................................................adapt model (without source) last loss:  0.19947105646133423\n","\n","Epoch: 0, accuracy:0.7189,  loss:0.5438,  val_accuracy:0.7446,  val_loss:0.5023,  \n",".................................................adapt model (with source) last loss:  0.23818716406822205\n","\n","knn_loss 0.6883116883116883\n","retrieval_loss 0.7402597402597403\n","adapt with source 0.6493506493506493\n","adapt without source 0.7012987012987013\n","\n","Epoch: 0, accuracy:0.7189,  loss:0.5506,  val_accuracy:0.7572,  val_loss:0.4813,  \n","....................................adapt model (without source) last loss:  0.2974071204662323\n","\n","Epoch: 0, accuracy:0.7344,  loss:0.5287,  val_accuracy:0.7620,  val_loss:0.4876,  \n","...................................................adapt model (with source) last loss:  0.24572603404521942\n","\n","knn_loss 0.6973684210526315\n","retrieval_loss 0.618421052631579\n","adapt with source 0.6973684210526315\n","adapt without source 0.7236842105263158\n","\n","Epoch: 0, accuracy:0.7220,  loss:0.5501,  val_accuracy:0.7668,  val_loss:0.4756,  \n","....................................................................................................\n","Epoch: 100, accuracy:1.0000,  loss:0.0006,  val_accuracy:0.9760,  val_loss:0.0907,  \n","..........................adapt model (without source) last loss:  0.09260273724794388\n","\n","Epoch: 0, accuracy:0.7292,  loss:0.5351,  val_accuracy:0.7404,  val_loss:0.5107,  \n","...........................................adapt model (with source) last loss:  0.27073734998703003\n","\n","knn_loss 0.7894736842105263\n","retrieval_loss 0.7105263157894737\n","adapt with source 0.7763157894736842\n","adapt without source 0.7105263157894737\n","\n","Epoch: 0, accuracy:0.7193,  loss:0.5496,  val_accuracy:0.7566,  val_loss:0.4811,  \n","..................................................................adapt model (without source) last loss:  0.3331155478954315\n","\n","Epoch: 0, accuracy:0.7320,  loss:0.5307,  val_accuracy:0.7133,  val_loss:0.5191,  \n",".........................................................adapt model (with source) last loss:  0.20815645158290863\n","\n","knn_loss 0.7012987012987013\n","retrieval_loss 0.7012987012987013\n","adapt with source 0.7142857142857143\n","adapt without source 0.7012987012987013\n","\n","Epoch: 0, accuracy:0.7258,  loss:0.5420,  val_accuracy:0.7349,  val_loss:0.5370,  \n","............................................adapt model (without source) last loss:  0.34629684686660767\n","\n","Epoch: 0, accuracy:0.7197,  loss:0.5415,  val_accuracy:0.7639,  val_loss:0.4970,  \n","......................................adapt model (with source) last loss:  0.3119150698184967\n","\n","knn_loss 0.7532467532467533\n","retrieval_loss 0.6753246753246753\n","adapt with source 0.7792207792207793\n","adapt without source 0.7012987012987013\n","\n","Epoch: 0, accuracy:0.7199,  loss:0.5431,  val_accuracy:0.7036,  val_loss:0.5414,  \n","..................................adapt model (without source) last loss:  0.3555791974067688\n","\n","Epoch: 0, accuracy:0.7230,  loss:0.5486,  val_accuracy:0.7422,  val_loss:0.5013,  \n","........................................................adapt model (with source) last loss:  0.20606714487075806\n","\n","knn_loss 0.7272727272727273\n","retrieval_loss 0.7922077922077922\n","adapt with source 0.7272727272727273\n","adapt without source 0.7272727272727273\n","\n","Epoch: 0, accuracy:0.7357,  loss:0.5185,  val_accuracy:0.7687,  val_loss:0.4627,  \n",".............................................................adapt model (without source) last loss:  0.24127714335918427\n","\n","Epoch: 0, accuracy:0.7348,  loss:0.5255,  val_accuracy:0.7446,  val_loss:0.5050,  \n","............................................adapt model (with source) last loss:  0.3164806365966797\n","\n","knn_loss 0.7272727272727273\n","retrieval_loss 0.6493506493506493\n","adapt with source 0.6883116883116883\n","adapt without source 0.7402597402597403\n","\n","Epoch: 0, accuracy:0.7349,  loss:0.5190,  val_accuracy:0.7181,  val_loss:0.5318,  \n",".........................................................adapt model (without source) last loss:  0.2897292673587799\n","\n","Epoch: 0, accuracy:0.7269,  loss:0.5336,  val_accuracy:0.7639,  val_loss:0.4629,  \n","..........................................adapt model (with source) last loss:  0.2561423182487488\n","\n","knn_loss 0.6623376623376623\n","retrieval_loss 0.7272727272727273\n","adapt with source 0.6103896103896104\n","adapt without source 0.6883116883116883\n","\n","Epoch: 0, accuracy:0.7154,  loss:0.5483,  val_accuracy:0.7422,  val_loss:0.5250,  \n","................................................................adapt model (without source) last loss:  0.2727773189544678\n","\n","Epoch: 0, accuracy:0.7105,  loss:0.5475,  val_accuracy:0.7422,  val_loss:0.5307,  \n","..................................................adapt model (with source) last loss:  0.21102206408977509\n","\n","knn_loss 0.7402597402597403\n","retrieval_loss 0.6623376623376623\n","adapt with source 0.7792207792207793\n","adapt without source 0.7272727272727273\n","\n","Epoch: 0, accuracy:0.7465,  loss:0.5127,  val_accuracy:0.7518,  val_loss:0.4853,  \n",".................................adapt model (without source) last loss:  0.29993441700935364\n","\n","Epoch: 0, accuracy:0.7500,  loss:0.5115,  val_accuracy:0.7687,  val_loss:0.4610,  \n","....................................................adapt model (with source) last loss:  0.21904033422470093\n","\n","knn_loss 0.7012987012987013\n","retrieval_loss 0.6753246753246753\n","adapt with source 0.7012987012987013\n","adapt without source 0.6753246753246753\n","\n","Epoch: 0, accuracy:0.7273,  loss:0.5358,  val_accuracy:0.7301,  val_loss:0.5108,  \n","..........................................adapt model (without source) last loss:  0.3226412236690521\n","\n","Epoch: 0, accuracy:0.7342,  loss:0.5384,  val_accuracy:0.7470,  val_loss:0.5040,  \n","................................................adapt model (with source) last loss:  0.2913302779197693\n","\n","knn_loss 0.7662337662337663\n","retrieval_loss 0.6883116883116883\n","adapt with source 0.7012987012987013\n","adapt without source 0.6363636363636364\n","\n","Epoch: 0, accuracy:0.7192,  loss:0.5343,  val_accuracy:0.7212,  val_loss:0.5168,  \n","................................................................adapt model (without source) last loss:  0.1152549460530281\n","\n","Epoch: 0, accuracy:0.7046,  loss:0.5640,  val_accuracy:0.7115,  val_loss:0.5134,  \n","...................................................adapt model (with source) last loss:  0.2431432604789734\n","\n","knn_loss 0.8026315789473685\n","retrieval_loss 0.6973684210526315\n","adapt with source 0.7236842105263158\n","adapt without source 0.6578947368421053\n","\n","Epoch: 0, accuracy:0.7215,  loss:0.5403,  val_accuracy:0.7212,  val_loss:0.5305,  \n",".....................................................adapt model (without source) last loss:  0.2191326767206192\n","\n","Epoch: 0, accuracy:0.7201,  loss:0.5385,  val_accuracy:0.7452,  val_loss:0.5094,  \n","....................................................adapt model (with source) last loss:  0.23703017830848694\n","\n","knn_loss 0.7236842105263158\n","retrieval_loss 0.7368421052631579\n","adapt with source 0.6842105263157895\n","adapt without source 0.7105263157894737\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.7320915926179085\n","np.mean(retrieval_loss_es) =  0.7055023923444976\n","np.mean(without_source_loss_es) =  0.694002050580998\n","np.mean(with_source_loss_es) =  0.6955741626794257\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.04101238891965368\n","np.std(retrieval_loss_es) =  0.044095769833236556\n","np.std(without_source_loss_es) =  0.05017062856948604\n","np.std(with_source_loss_es) =  0.04932233746049432\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.695799438665365\n","np.mean(retrieval_loss_es) =  0.6692398639974324\n","np.mean(without_source_loss_es) =  0.6673054518745868\n","np.mean(with_source_loss_es) =  0.6701881500726156\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.04857703501098704\n","np.std(retrieval_loss_es) =  0.04908010944173277\n","np.std(without_source_loss_es) =  0.05354246634228911\n","np.std(with_source_loss_es) =  0.055620892268099985\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JJwWSWOZ4Ypo"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.7320915926179085\r\n","np.mean(retrieval_loss_es) =  0.7055023923444976\r\n","np.mean(without_source_loss_es) =  0.694002050580998\r\n","np.mean(with_source_loss_es) =  0.6955741626794257\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.04101238891965368\r\n","np.std(retrieval_loss_es) =  0.044095769833236556\r\n","np.std(without_source_loss_es) =  0.05017062856948604\r\n","np.std(with_source_loss_es) =  0.04932233746049432\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.695799438665365\r\n","np.mean(retrieval_loss_es) =  0.6692398639974324\r\n","np.mean(without_source_loss_es) =  0.6673054518745868\r\n","np.mean(with_source_loss_es) =  0.6701881500726156\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.04857703501098704\r\n","np.std(retrieval_loss_es) =  0.04908010944173277\r\n","np.std(without_source_loss_es) =  0.05354246634228911\r\n","np.std(with_source_loss_es) =  0.055620892268099985\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"5AAIlGayKELv"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.5536397812713602\r\n","np.mean(arr_knn) =  0.6849794941900205\r\n","np.mean(arr_retrieval_loss) =  0.6706425153793576\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.5987696514012303\r\n","np.mean(arr_normal_cdh_loss) =  0.6042207792207792\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.583116883116883\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.6842105263157895\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.5916919162258714\r\n","np.mean(arr_knn) =  0.6463337392668883\r\n","np.mean(arr_retrieval_loss) =  0.6444572815245712\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.5808719461296186\r\n","np.mean(arr_normal_cdh_loss) =  0.5773530645523316\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.5613729885269192\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.7043478260869566\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"ErDkaFx7PvbY"},"source":["multi runs\r\n","\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.7616814764183185\r\n","np.mean(arr_knn) =  0.7388072453861928\r\n","np.mean(arr_retrieval_loss) =  0.7039131920710866\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.687758031442242\r\n","np.mean(arr_normal_cdh_loss) =  0.6458612440191388\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.694788106630212\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.7216370471633629\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.0453517428900051\r\n","np.std(arr_knn) =  0.04288425528615694\r\n","np.std(arr_retrieval_loss) =  0.0483295310141565\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.04834789886788082\r\n","np.std(arr_normal_cdh_loss) =  0.045993851832649944\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.05250339747400515\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.050103082605795816\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.7300267664938329\r\n","np.mean(arr_knn) =  0.7030537273011396\r\n","np.mean(arr_retrieval_loss) =  0.6656147236655896\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.6565536802548944\r\n","np.mean(arr_normal_cdh_loss) =  0.6130391237107407\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.6660781715675492\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.6974413636611423\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.04704098129329441\r\n","np.std(arr_knn) =  0.04668937207540498\r\n","np.std(arr_retrieval_loss) =  0.05305052625028058\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.055723330990326\r\n","np.std(arr_normal_cdh_loss) =  0.05135387729815293\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.05806275201335232\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.05060338898805063\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"MG6SVR2bP4-N"},"source":["# Dataset: Page-blocks"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6YCYoeMEP-NL","executionInfo":{"elapsed":2115,"status":"ok","timestamp":1611060110753,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"dd7287b8-d91b-4d69-ab66-7faf40fefc1b"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/page-blocks.data'\r\n","nominalCols = [] \r\n","numericCols = [0,1,2,3,4,5,6,7,8,9]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,6,7,8,9,),delim_whitespace=True);\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(10,),delim_whitespace=True);\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False, columns=[10])\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","Index: []\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","5    0\n","6    0\n","7    0\n","8    0\n","9    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eJmNsmEWP1NK","executionInfo":{"elapsed":2105,"status":"ok","timestamp":1611060110753,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"147fd59c-ee1c-4f15-c565-b7d48cf4ff4c"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5473, 10)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"fF8YCaQXRBKb"},"source":["# Trying 10 fold: Page-blocks"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fja8XdQHRFtU","executionInfo":{"elapsed":13329574,"status":"ok","timestamp":1611073438236,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"25ef2699-82a6-4dfa-f205-4e7b28e090bd"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.8945,  loss:0.3187,  val_accuracy:0.9272,  val_loss:0.2181,  \n","................................................adapt model (without source) last loss:  0.05031164735555649\n","\n","Epoch: 0, accuracy:0.9012,  loss:0.2996,  val_accuracy:0.9475,  val_loss:0.1678,  \n",".......................................adapt model (with source) last loss:  0.03699607774615288\n","\n","knn_loss 0.958029197080292\n","retrieval_loss 0.958029197080292\n","adapt with source 0.9416058394160584\n","adapt without source 0.9379562043795621\n","\n","Epoch: 0, accuracy:0.8999,  loss:0.3043,  val_accuracy:0.9402,  val_loss:0.1929,  \n","................................................adapt model (without source) last loss:  0.04621150717139244\n","\n","Epoch: 0, accuracy:0.9074,  loss:0.2769,  val_accuracy:0.9396,  val_loss:0.1713,  \n","...............................................................adapt model (with source) last loss:  0.03652339056134224\n","\n","knn_loss 0.9598540145985401\n","retrieval_loss 0.9635036496350365\n","adapt with source 0.948905109489051\n","adapt without source 0.9598540145985401\n","\n","Epoch: 0, accuracy:0.8874,  loss:0.3408,  val_accuracy:0.9394,  val_loss:0.1810,  \n","............................adapt model (without source) last loss:  0.051658786833286285\n","\n","Epoch: 0, accuracy:0.8958,  loss:0.3155,  val_accuracy:0.9245,  val_loss:0.2014,  \n","...........................................adapt model (with source) last loss:  0.048253048211336136\n","\n","knn_loss 0.9781021897810219\n","retrieval_loss 0.9744525547445255\n","adapt with source 0.9543795620437956\n","adapt without source 0.968978102189781\n","\n","Epoch: 0, accuracy:0.8941,  loss:0.3255,  val_accuracy:0.9321,  val_loss:0.2057,  \n","................................................adapt model (without source) last loss:  0.04810661822557449\n","\n","Epoch: 0, accuracy:0.8918,  loss:0.3271,  val_accuracy:0.9394,  val_loss:0.1825,  \n","...........................................adapt model (with source) last loss:  0.04829782247543335\n","\n","knn_loss 0.9689213893967094\n","retrieval_loss 0.9652650822669104\n","adapt with source 0.9634369287020109\n","adapt without source 0.9670932358318098\n","\n","Epoch: 0, accuracy:0.9033,  loss:0.3074,  val_accuracy:0.9516,  val_loss:0.1591,  \n","...........................................adapt model (without source) last loss:  0.050742924213409424\n","\n","Epoch: 0, accuracy:0.9003,  loss:0.3094,  val_accuracy:0.9461,  val_loss:0.1643,  \n",".......................................adapt model (with source) last loss:  0.04051445052027702\n","\n","knn_loss 0.9634369287020109\n","retrieval_loss 0.9579524680073126\n","adapt with source 0.9579524680073126\n","adapt without source 0.9524680073126143\n","\n","Epoch: 0, accuracy:0.8951,  loss:0.3209,  val_accuracy:0.9269,  val_loss:0.2379,  \n","..............................................................adapt model (without source) last loss:  0.05622312054038048\n","\n","Epoch: 0, accuracy:0.8989,  loss:0.3038,  val_accuracy:0.9380,  val_loss:0.1810,  \n",".............................................adapt model (with source) last loss:  0.04621434956789017\n","\n","knn_loss 0.9652650822669104\n","retrieval_loss 0.9744058500914077\n","adapt with source 0.9524680073126143\n","adapt without source 0.9597806215722121\n","\n","Epoch: 0, accuracy:0.8875,  loss:0.3404,  val_accuracy:0.9356,  val_loss:0.1951,  \n",".............................................................adapt model (without source) last loss:  0.024881284683942795\n","\n","Epoch: 0, accuracy:0.8960,  loss:0.3112,  val_accuracy:0.9315,  val_loss:0.2008,  \n",".....................................adapt model (with source) last loss:  0.046410128474235535\n","\n","knn_loss 0.9634369287020109\n","retrieval_loss 0.9707495429616088\n","adapt with source 0.9561243144424132\n","adapt without source 0.9689213893967094\n","\n","Epoch: 0, accuracy:0.8895,  loss:0.3436,  val_accuracy:0.9337,  val_loss:0.2260,  \n","......................................................adapt model (without source) last loss:  0.03010653890669346\n","\n","Epoch: 0, accuracy:0.9034,  loss:0.3001,  val_accuracy:0.9440,  val_loss:0.1785,  \n","............................................adapt model (with source) last loss:  0.054258912801742554\n","\n","knn_loss 0.9744058500914077\n","retrieval_loss 0.9744058500914077\n","adapt with source 0.9634369287020109\n","adapt without source 0.9744058500914077\n","\n","Epoch: 0, accuracy:0.8897,  loss:0.3386,  val_accuracy:0.9323,  val_loss:0.1920,  \n","..................................................................adapt model (without source) last loss:  0.029978791251778603\n","\n","Epoch: 0, accuracy:0.8973,  loss:0.3143,  val_accuracy:0.9405,  val_loss:0.1778,  \n","....................................adapt model (with source) last loss:  0.04190990701317787\n","\n","knn_loss 0.9616087751371115\n","retrieval_loss 0.9579524680073126\n","adapt with source 0.943327239488117\n","adapt without source 0.9524680073126143\n","\n","Epoch: 0, accuracy:0.8864,  loss:0.3409,  val_accuracy:0.9185,  val_loss:0.2249,  \n",".................................................................................adapt model (without source) last loss:  0.044981054961681366\n","\n","Epoch: 0, accuracy:0.8857,  loss:0.3394,  val_accuracy:0.9237,  val_loss:0.2163,  \n","..................................adapt model (with source) last loss:  0.05639660730957985\n","\n","knn_loss 0.9725776965265083\n","retrieval_loss 0.9652650822669104\n","adapt with source 0.9744058500914077\n","adapt without source 0.9689213893967094\n","\n","Epoch: 0, accuracy:0.9002,  loss:0.3152,  val_accuracy:0.9507,  val_loss:0.1818,  \n","................................................................adapt model (without source) last loss:  0.039368655532598495\n","\n","Epoch: 0, accuracy:0.9006,  loss:0.3031,  val_accuracy:0.9502,  val_loss:0.1591,  \n",".................................................adapt model (with source) last loss:  0.03959451615810394\n","\n","knn_loss 0.9708029197080292\n","retrieval_loss 0.9635036496350365\n","adapt with source 0.948905109489051\n","adapt without source 0.9525547445255474\n","\n","Epoch: 0, accuracy:0.8907,  loss:0.3386,  val_accuracy:0.9299,  val_loss:0.2236,  \n","..............................................adapt model (without source) last loss:  0.05823924392461777\n","\n","Epoch: 0, accuracy:0.8953,  loss:0.3150,  val_accuracy:0.9234,  val_loss:0.2639,  \n","...............................................adapt model (with source) last loss:  0.07674000412225723\n","\n","knn_loss 0.968978102189781\n","retrieval_loss 0.958029197080292\n","adapt with source 0.9635036496350365\n","adapt without source 0.9562043795620438\n","\n","Epoch: 0, accuracy:0.8932,  loss:0.3287,  val_accuracy:0.9315,  val_loss:0.2062,  \n",".............................................................................adapt model (without source) last loss:  0.030233729630708694\n","\n","Epoch: 0, accuracy:0.8930,  loss:0.3217,  val_accuracy:0.9380,  val_loss:0.1887,  \n","....................................................adapt model (with source) last loss:  0.037175655364990234\n","\n","knn_loss 0.9543795620437956\n","retrieval_loss 0.9543795620437956\n","adapt with source 0.9525547445255474\n","adapt without source 0.9507299270072993\n","\n","Epoch: 0, accuracy:0.8905,  loss:0.3351,  val_accuracy:0.9310,  val_loss:0.2011,  \n",".............................................................adapt model (without source) last loss:  0.0409776009619236\n","\n","Epoch: 0, accuracy:0.8922,  loss:0.3265,  val_accuracy:0.9415,  val_loss:0.1774,  \n","...............................................adapt model (with source) last loss:  0.03221616894006729\n","\n","knn_loss 0.9616087751371115\n","retrieval_loss 0.9634369287020109\n","adapt with source 0.9488117001828154\n","adapt without source 0.9542961608775137\n","\n","Epoch: 0, accuracy:0.8969,  loss:0.3168,  val_accuracy:0.9413,  val_loss:0.1732,  \n","..........................................................adapt model (without source) last loss:  0.03743022307753563\n","\n","Epoch: 0, accuracy:0.8993,  loss:0.3058,  val_accuracy:0.9367,  val_loss:0.1844,  \n",".....................................................adapt model (with source) last loss:  0.03696361929178238\n","\n","knn_loss 0.9616087751371115\n","retrieval_loss 0.9652650822669104\n","adapt with source 0.9707495429616088\n","adapt without source 0.9616087751371115\n","\n","Epoch: 0, accuracy:0.8976,  loss:0.3167,  val_accuracy:0.9386,  val_loss:0.2128,  \n",".....................................adapt model (without source) last loss:  0.055307786911726\n","\n","Epoch: 0, accuracy:0.8996,  loss:0.3086,  val_accuracy:0.9442,  val_loss:0.1831,  \n","...................................................adapt model (with source) last loss:  0.04048030078411102\n","\n","knn_loss 0.9616087751371115\n","retrieval_loss 0.9579524680073126\n","adapt with source 0.9652650822669104\n","adapt without source 0.946983546617916\n","\n","Epoch: 0, accuracy:0.8961,  loss:0.3134,  val_accuracy:0.9407,  val_loss:0.1956,  \n","................................................................adapt model (without source) last loss:  0.02740204520523548\n","\n","Epoch: 0, accuracy:0.8962,  loss:0.3161,  val_accuracy:0.9467,  val_loss:0.1690,  \n","...........................................................adapt model (with source) last loss:  0.030852051451802254\n","\n","knn_loss 0.9670932358318098\n","retrieval_loss 0.9689213893967094\n","adapt with source 0.9542961608775137\n","adapt without source 0.9579524680073126\n","\n","Epoch: 0, accuracy:0.8928,  loss:0.3313,  val_accuracy:0.9361,  val_loss:0.1969,  \n",".............................................adapt model (without source) last loss:  0.0394432507455349\n","\n","Epoch: 0, accuracy:0.8932,  loss:0.3191,  val_accuracy:0.9356,  val_loss:0.1897,  \n","......................................................adapt model (with source) last loss:  0.03494420275092125\n","\n","knn_loss 0.9597806215722121\n","retrieval_loss 0.9652650822669104\n","adapt with source 0.9488117001828154\n","adapt without source 0.9561243144424132\n","\n","Epoch: 0, accuracy:0.8966,  loss:0.3224,  val_accuracy:0.9342,  val_loss:0.1880,  \n",".............................................adapt model (without source) last loss:  0.04056854546070099\n","\n","Epoch: 0, accuracy:0.8955,  loss:0.3120,  val_accuracy:0.9372,  val_loss:0.1909,  \n","......................................................................adapt model (with source) last loss:  0.04522710293531418\n","\n","knn_loss 0.9725776965265083\n","retrieval_loss 0.9707495429616088\n","adapt with source 0.9634369287020109\n","adapt without source 0.9744058500914077\n","\n","Epoch: 0, accuracy:0.8935,  loss:0.3242,  val_accuracy:0.9321,  val_loss:0.2103,  \n","................................................................adapt model (without source) last loss:  0.04009705409407616\n","\n","Epoch: 0, accuracy:0.8928,  loss:0.3194,  val_accuracy:0.9264,  val_loss:0.2082,  \n","..............................................adapt model (with source) last loss:  0.04418674111366272\n","\n","knn_loss 0.9817184643510055\n","retrieval_loss 0.9853747714808044\n","adapt with source 0.9616087751371115\n","adapt without source 0.9689213893967094\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.9662897489958497\n","np.mean(retrieval_loss_es) =  0.9657429709497057\n","np.mean(without_source_loss_es) =  0.9595314188873617\n","np.mean(with_source_loss_es) =  0.9566992820827606\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.006915719838279902\n","np.std(retrieval_loss_es) =  0.0074768215454557195\n","np.std(without_source_loss_es) =  0.009379114775681959\n","np.std(with_source_loss_es) =  0.008635922698243611\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.8226838376003235\n","np.mean(retrieval_loss_es) =  0.8393836583993203\n","np.mean(without_source_loss_es) =  0.7914096566971669\n","np.mean(with_source_loss_es) =  0.7933965308252512\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.05430783017630601\n","np.std(retrieval_loss_es) =  0.06599388413844692\n","np.std(without_source_loss_es) =  0.07485115955068486\n","np.std(with_source_loss_es) =  0.05765763301777416\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P7gJaiJdEh-r"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.9662897489958497\r\n","np.mean(retrieval_loss_es) =  0.9657429709497057\r\n","np.mean(without_source_loss_es) =  0.9595314188873617\r\n","np.mean(with_source_loss_es) =  0.9566992820827606\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.006915719838279902\r\n","np.std(retrieval_loss_es) =  0.0074768215454557195\r\n","np.std(without_source_loss_es) =  0.009379114775681959\r\n","np.std(with_source_loss_es) =  0.008635922698243611\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.8226838376003235\r\n","np.mean(retrieval_loss_es) =  0.8393836583993203\r\n","np.mean(without_source_loss_es) =  0.7914096566971669\r\n","np.mean(with_source_loss_es) =  0.7933965308252512\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.05430783017630601\r\n","np.std(retrieval_loss_es) =  0.06599388413844692\r\n","np.std(without_source_loss_es) =  0.07485115955068486\r\n","np.std(with_source_loss_es) =  0.05765763301777416\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"VK1-nupjgNoW"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9539538824910927\r\n","np.mean(arr_knn) =  0.956696112838442\r\n","np.mean(arr_retrieval_loss) =  0.9579738187058808\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9349567648353995\r\n","np.mean(arr_normal_cdh_loss) =  0.9422583701410481\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9395231454916665\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9414990859232175\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.712117232970063\r\n","np.mean(arr_knn) =  0.7138370403732355\r\n","np.mean(arr_retrieval_loss) =  0.7633803995289032\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.6307572269922996\r\n","np.mean(arr_normal_cdh_loss) =  0.6442186052273662\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.7034092808757572\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.8771153846153845\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"nOmnWraawrhi"},"source":["2 times 10 fold\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.9685731061263159\r\n","np.mean(arr_knn) =  0.9665633048212545\r\n","np.mean(arr_retrieval_loss) =  0.9646435767757776\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.9489289622226076\r\n","np.mean(arr_normal_cdh_loss) =  0.9473763661111038\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.9515787840777165\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.9675647860259678\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.007996656107944169\r\n","np.std(arr_knn) =  0.007818635769009496\r\n","np.std(arr_retrieval_loss) =  0.008161736488200913\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.011805093942928934\r\n","np.std(arr_normal_cdh_loss) =  0.009689588811481999\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.010289273047720357\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.007179361150150107\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.8100202967765615\r\n","np.mean(arr_knn) =  0.8269490132087848\r\n","np.mean(arr_retrieval_loss) =  0.8404361865499871\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.7361241938606605\r\n","np.mean(arr_normal_cdh_loss) =  0.7320485782912092\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.8012843396089165\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.8565965349436047\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.07519104176013881\r\n","np.std(arr_knn) =  0.061361255634633245\r\n","np.std(arr_retrieval_loss) =  0.05321437240986915\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.0985919717981357\r\n","np.std(arr_normal_cdh_loss) =  0.10249295752673333\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.072499686661438\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.06065210656000591\r\n","\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"Uu5XQf0a1EI5"},"source":["# Dataset: Contraceptive Method Choice Data Set"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Eh1JPZm1Mi1","executionInfo":{"elapsed":1519,"status":"ok","timestamp":1611075310904,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"4d6a2977-b100-4cb0-86e1-dda689d24014"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/cmc.data'\r\n","nominalCols = [1,2,6,7] \r\n","numericCols = [0,3,4,5,8]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,6,7,8,),sep=',');\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(9,),sep=',');\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False, columns=[9])\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","Index: []\n","0      0\n","3      0\n","4      0\n","5      0\n","8      0\n","1_1    0\n","1_2    0\n","1_3    0\n","1_4    0\n","2_1    0\n","2_2    0\n","2_3    0\n","2_4    0\n","6_1    0\n","6_2    0\n","6_3    0\n","6_4    0\n","7_1    0\n","7_2    0\n","7_3    0\n","7_4    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"Yl7EFGT72Kfd","executionInfo":{"elapsed":13330363,"status":"ok","timestamp":1611073439037,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"47e205eb-db0b-4756-bdd4-7c3d199cf1c0"},"source":["X.head(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>8</th>\n","      <th>1_1</th>\n","      <th>1_2</th>\n","      <th>1_3</th>\n","      <th>1_4</th>\n","      <th>2_1</th>\n","      <th>2_2</th>\n","      <th>2_3</th>\n","      <th>2_4</th>\n","      <th>6_1</th>\n","      <th>6_2</th>\n","      <th>6_3</th>\n","      <th>6_4</th>\n","      <th>7_1</th>\n","      <th>7_2</th>\n","      <th>7_3</th>\n","      <th>7_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49</th>\n","      <td>-0.794990</td>\n","      <td>-1.383257</td>\n","      <td>0.419021</td>\n","      <td>-1.729702</td>\n","      <td>-0.282687</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1075</th>\n","      <td>1.515194</td>\n","      <td>-1.383257</td>\n","      <td>0.419021</td>\n","      <td>0.578134</td>\n","      <td>-0.282687</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>659</th>\n","      <td>-0.673401</td>\n","      <td>-0.959123</td>\n","      <td>0.419021</td>\n","      <td>-1.729702</td>\n","      <td>-0.282687</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>-0.551813</td>\n","      <td>-0.534990</td>\n","      <td>0.419021</td>\n","      <td>-1.729702</td>\n","      <td>-0.282687</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             0         3         4         5         8  ...  6_4  7_1  7_2  7_3  7_4\n","49   -0.794990 -1.383257  0.419021 -1.729702 -0.282687  ...    0    0    0    0    1\n","1075  1.515194 -1.383257  0.419021  0.578134 -0.282687  ...    0    0    0    1    0\n","659  -0.673401 -0.959123  0.419021 -1.729702 -0.282687  ...    0    0    0    1    0\n","316  -0.551813 -0.534990  0.419021 -1.729702 -0.282687  ...    0    0    0    1    0\n","\n","[4 rows x 21 columns]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZNR7l3_wzJw","executionInfo":{"elapsed":13330360,"status":"ok","timestamp":1611073439038,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"e6c92de3-02b4-40d9-e0da-c685956e36de"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1473, 21)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"lXxxLw1J2MSJ","executionInfo":{"elapsed":13330357,"status":"ok","timestamp":1611073439039,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"7d5b8bc1-fef2-4c48-83df-f240af4575a8"},"source":["y.head(4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>9_1</th>\n","      <th>9_2</th>\n","      <th>9_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1075</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>659</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      9_1  9_2  9_3\n","49      1    0    0\n","1075    1    0    0\n","659     0    0    1\n","316     1    0    0"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"q8BlF8HP1KN5"},"source":["# Trying 10 fold: Contraceptive"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Q4GI_cR92Rdu","executionInfo":{"elapsed":3127640,"status":"ok","timestamp":1611079962520,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"},"user_tz":300},"outputId":"5cb219f9-f2a1-4475-bf73-ad5268967e84"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.5084,  loss:0.9738,  val_accuracy:0.5093,  val_loss:0.9567,  \n",".......................................................adapt model (without source) last loss:  0.43175217509269714\n","\n","Epoch: 0, accuracy:0.5117,  loss:0.9751,  val_accuracy:0.5012,  val_loss:0.9688,  \n","...............................................adapt model (with source) last loss:  0.47198253870010376\n","\n","knn_loss 0.40540540540540543\n","retrieval_loss 0.4594594594594595\n","adapt with source 0.527027027027027\n","adapt without source 0.5202702702702703\n","\n","Epoch: 0, accuracy:0.4991,  loss:0.9830,  val_accuracy:0.4965,  val_loss:0.9824,  \n","................................................adapt model (without source) last loss:  0.44167575240135193\n","\n","Epoch: 0, accuracy:0.5129,  loss:0.9697,  val_accuracy:0.5371,  val_loss:0.9494,  \n","....................................................adapt model (with source) last loss:  0.5776523351669312\n","\n","knn_loss 0.4391891891891892\n","retrieval_loss 0.44594594594594594\n","adapt with source 0.46621621621621623\n","adapt without source 0.5067567567567568\n","\n","Epoch: 0, accuracy:0.5090,  loss:0.9757,  val_accuracy:0.5487,  val_loss:0.8946,  \n","......................................................................adapt model (without source) last loss:  0.36826804280281067\n","\n","Epoch: 0, accuracy:0.4977,  loss:0.9859,  val_accuracy:0.5290,  val_loss:0.9422,  \n","..............................................adapt model (with source) last loss:  0.48530158400535583\n","\n","knn_loss 0.39864864864864863\n","retrieval_loss 0.43243243243243246\n","adapt with source 0.5\n","adapt without source 0.5202702702702703\n","\n","Epoch: 0, accuracy:0.5032,  loss:0.9812,  val_accuracy:0.5545,  val_loss:0.9185,  \n","............................................adapt model (without source) last loss:  0.3750416338443756\n","\n","Epoch: 0, accuracy:0.5127,  loss:0.9693,  val_accuracy:0.5777,  val_loss:0.8859,  \n","...........................................adapt model (with source) last loss:  0.3963788151741028\n","\n","knn_loss 0.40816326530612246\n","retrieval_loss 0.4897959183673469\n","adapt with source 0.5034013605442177\n","adapt without source 0.4557823129251701\n","\n","Epoch: 0, accuracy:0.5011,  loss:0.9859,  val_accuracy:0.5487,  val_loss:0.9343,  \n","................................................adapt model (without source) last loss:  0.42535778880119324\n","\n","Epoch: 0, accuracy:0.5173,  loss:0.9754,  val_accuracy:0.5615,  val_loss:0.9129,  \n","....................................................adapt model (with source) last loss:  0.5336663126945496\n","\n","knn_loss 0.3741496598639456\n","retrieval_loss 0.4013605442176871\n","adapt with source 0.47619047619047616\n","adapt without source 0.4557823129251701\n","\n","Epoch: 0, accuracy:0.4994,  loss:0.9796,  val_accuracy:0.5278,  val_loss:0.9479,  \n",".....................................adapt model (without source) last loss:  0.3907065987586975\n","\n","Epoch: 0, accuracy:0.5087,  loss:0.9723,  val_accuracy:0.5255,  val_loss:0.9416,  \n","............................................adapt model (with source) last loss:  0.46808314323425293\n","\n","knn_loss 0.40816326530612246\n","retrieval_loss 0.40816326530612246\n","adapt with source 0.5238095238095238\n","adapt without source 0.43537414965986393\n","\n","Epoch: 0, accuracy:0.5089,  loss:0.9724,  val_accuracy:0.5360,  val_loss:0.9331,  \n","..................................................adapt model (without source) last loss:  0.38064712285995483\n","\n","Epoch: 0, accuracy:0.5154,  loss:0.9606,  val_accuracy:0.5731,  val_loss:0.9143,  \n","......................................adapt model (with source) last loss:  0.611171543598175\n","\n","knn_loss 0.3673469387755102\n","retrieval_loss 0.36054421768707484\n","adapt with source 0.40816326530612246\n","adapt without source 0.4013605442176871\n","\n","Epoch: 0, accuracy:0.4957,  loss:0.9849,  val_accuracy:0.5070,  val_loss:0.9812,  \n","......................................................adapt model (without source) last loss:  0.4560122489929199\n","\n","Epoch: 0, accuracy:0.5002,  loss:0.9839,  val_accuracy:0.5267,  val_loss:0.9373,  \n","............................................adapt model (with source) last loss:  0.568798303604126\n","\n","knn_loss 0.40816326530612246\n","retrieval_loss 0.46258503401360546\n","adapt with source 0.5034013605442177\n","adapt without source 0.46938775510204084\n","\n","Epoch: 0, accuracy:0.5034,  loss:0.9820,  val_accuracy:0.5719,  val_loss:0.9162,  \n","................................................adapt model (without source) last loss:  0.5117014646530151\n","\n","Epoch: 0, accuracy:0.5093,  loss:0.9712,  val_accuracy:0.5545,  val_loss:0.9433,  \n","............................................adapt model (with source) last loss:  0.5741084814071655\n","\n","knn_loss 0.4421768707482993\n","retrieval_loss 0.47619047619047616\n","adapt with source 0.5238095238095238\n","adapt without source 0.54421768707483\n","\n","Epoch: 0, accuracy:0.5056,  loss:0.9709,  val_accuracy:0.5046,  val_loss:0.9481,  \n","................................................adapt model (without source) last loss:  0.4254681169986725\n","\n","Epoch: 0, accuracy:0.5111,  loss:0.9751,  val_accuracy:0.5522,  val_loss:0.9203,  \n","......................................adapt model (with source) last loss:  0.5212153196334839\n","\n","knn_loss 0.4421768707482993\n","retrieval_loss 0.43537414965986393\n","adapt with source 0.4557823129251701\n","adapt without source 0.46938775510204084\n","\n","Epoch: 0, accuracy:0.4979,  loss:0.9817,  val_accuracy:0.5348,  val_loss:0.9278,  \n","...............................................adapt model (without source) last loss:  0.41257309913635254\n","\n","Epoch: 0, accuracy:0.5057,  loss:0.9811,  val_accuracy:0.5592,  val_loss:0.9141,  \n","...........................................adapt model (with source) last loss:  0.514801561832428\n","\n","knn_loss 0.4189189189189189\n","retrieval_loss 0.5135135135135135\n","adapt with source 0.4391891891891892\n","adapt without source 0.44594594594594594\n","\n","Epoch: 0, accuracy:0.5020,  loss:0.9857,  val_accuracy:0.5209,  val_loss:0.9628,  \n","...................................................adapt model (without source) last loss:  0.4480081796646118\n","\n","Epoch: 0, accuracy:0.5000,  loss:0.9848,  val_accuracy:0.5441,  val_loss:0.9280,  \n","............................................adapt model (with source) last loss:  0.547196090221405\n","\n","knn_loss 0.3581081081081081\n","retrieval_loss 0.43243243243243246\n","adapt with source 0.5067567567567568\n","adapt without source 0.4864864864864865\n","\n","Epoch: 0, accuracy:0.4983,  loss:0.9778,  val_accuracy:0.5186,  val_loss:0.9366,  \n","....................................................adapt model (without source) last loss:  0.4233902096748352\n","\n","Epoch: 0, accuracy:0.5081,  loss:0.9760,  val_accuracy:0.5093,  val_loss:0.9440,  \n","...............................................adapt model (with source) last loss:  0.5645613074302673\n","\n","knn_loss 0.38513513513513514\n","retrieval_loss 0.3716216216216216\n","adapt with source 0.47297297297297297\n","adapt without source 0.4527027027027027\n","\n","Epoch: 0, accuracy:0.5000,  loss:0.9778,  val_accuracy:0.5452,  val_loss:0.9272,  \n","..................................................adapt model (without source) last loss:  0.4475115239620209\n","\n","Epoch: 0, accuracy:0.5031,  loss:0.9817,  val_accuracy:0.5510,  val_loss:0.9173,  \n",".............................................adapt model (with source) last loss:  0.45675402879714966\n","\n","knn_loss 0.4557823129251701\n","retrieval_loss 0.4489795918367347\n","adapt with source 0.5306122448979592\n","adapt without source 0.4897959183673469\n","\n","Epoch: 0, accuracy:0.5012,  loss:0.9770,  val_accuracy:0.5290,  val_loss:0.9382,  \n","........................................................adapt model (without source) last loss:  0.4647427201271057\n","\n","Epoch: 0, accuracy:0.5072,  loss:0.9715,  val_accuracy:0.5151,  val_loss:0.9663,  \n","........................................adapt model (with source) last loss:  0.5607683658599854\n","\n","knn_loss 0.3333333333333333\n","retrieval_loss 0.41496598639455784\n","adapt with source 0.4013605442176871\n","adapt without source 0.43537414965986393\n","\n","Epoch: 0, accuracy:0.4991,  loss:0.9861,  val_accuracy:0.5244,  val_loss:0.9608,  \n","............................................adapt model (without source) last loss:  0.4817293584346771\n","\n","Epoch: 0, accuracy:0.4963,  loss:0.9883,  val_accuracy:0.5429,  val_loss:0.9431,  \n",".........................................adapt model (with source) last loss:  0.5687580108642578\n","\n","knn_loss 0.48299319727891155\n","retrieval_loss 0.4217687074829932\n","adapt with source 0.5510204081632653\n","adapt without source 0.48299319727891155\n","\n","Epoch: 0, accuracy:0.5153,  loss:0.9596,  val_accuracy:0.5510,  val_loss:0.9128,  \n","................................................adapt model (without source) last loss:  0.3721296489238739\n","\n","Epoch: 0, accuracy:0.5103,  loss:0.9698,  val_accuracy:0.5615,  val_loss:0.9210,  \n",".......................................adapt model (with source) last loss:  0.524512529373169\n","\n","knn_loss 0.42857142857142855\n","retrieval_loss 0.43537414965986393\n","adapt with source 0.46258503401360546\n","adapt without source 0.43537414965986393\n","\n","Epoch: 0, accuracy:0.4904,  loss:0.9887,  val_accuracy:0.5371,  val_loss:0.9161,  \n",".........................................................adapt model (without source) last loss:  0.44536083936691284\n","\n","Epoch: 0, accuracy:0.4884,  loss:0.9955,  val_accuracy:0.5626,  val_loss:0.9383,  \n",".................................................adapt model (with source) last loss:  0.5587607622146606\n","\n","knn_loss 0.46258503401360546\n","retrieval_loss 0.4557823129251701\n","adapt with source 0.48299319727891155\n","adapt without source 0.46938775510204084\n","\n","Epoch: 0, accuracy:0.5121,  loss:0.9786,  val_accuracy:0.5766,  val_loss:0.9246,  \n",".........................................................adapt model (without source) last loss:  0.4755284786224365\n","\n","Epoch: 0, accuracy:0.5119,  loss:0.9723,  val_accuracy:0.5476,  val_loss:0.9421,  \n",".....................................adapt model (with source) last loss:  0.6097332835197449\n","\n","knn_loss 0.42857142857142855\n","retrieval_loss 0.46258503401360546\n","adapt with source 0.5374149659863946\n","adapt without source 0.43537414965986393\n","\n","Epoch: 0, accuracy:0.5105,  loss:0.9733,  val_accuracy:0.5557,  val_loss:0.9397,  \n","............................................adapt model (without source) last loss:  0.4534584879875183\n","\n","Epoch: 0, accuracy:0.5156,  loss:0.9639,  val_accuracy:0.5441,  val_loss:0.9306,  \n","......................................................adapt model (with source) last loss:  0.4612903296947479\n","\n","knn_loss 0.3741496598639456\n","retrieval_loss 0.46938775510204084\n","adapt with source 0.4557823129251701\n","adapt without source 0.5170068027210885\n","\n","Epoch: 0, accuracy:0.5068,  loss:0.9818,  val_accuracy:0.5325,  val_loss:0.9628,  \n","...........................................................adapt model (without source) last loss:  0.4405990242958069\n","\n","Epoch: 0, accuracy:0.5016,  loss:0.9872,  val_accuracy:0.5360,  val_loss:0.9429,  \n","..........................................adapt model (with source) last loss:  0.46008193492889404\n","\n","knn_loss 0.3716216216216216\n","retrieval_loss 0.4189189189189189\n","adapt with source 0.41216216216216217\n","adapt without source 0.4189189189189189\n","\n","Epoch: 0, accuracy:0.4901,  loss:0.9922,  val_accuracy:0.5406,  val_loss:0.9413,  \n","..........................................adapt model (without source) last loss:  0.4639287292957306\n","\n","Epoch: 0, accuracy:0.4940,  loss:0.9896,  val_accuracy:0.5360,  val_loss:0.9546,  \n",".....................................................adapt model (with source) last loss:  0.4253561198711395\n","\n","knn_loss 0.4864864864864865\n","retrieval_loss 0.5675675675675675\n","adapt with source 0.4527027027027027\n","adapt without source 0.47297297297297297\n","\n","Epoch: 0, accuracy:0.5031,  loss:0.9795,  val_accuracy:0.5012,  val_loss:0.9655,  \n","..........................................................adapt model (without source) last loss:  0.4008021652698517\n","\n","Epoch: 0, accuracy:0.5066,  loss:0.9771,  val_accuracy:0.5522,  val_loss:0.9109,  \n","...................................................adapt model (with source) last loss:  0.4746848940849304\n","\n","knn_loss 0.41216216216216217\n","retrieval_loss 0.4594594594594595\n","adapt with source 0.5\n","adapt without source 0.47297297297297297\n","\n","Epoch: 0, accuracy:0.5146,  loss:0.9664,  val_accuracy:0.5429,  val_loss:0.9141,  \n","..........................................................adapt model (without source) last loss:  0.4851784408092499\n","\n","Epoch: 0, accuracy:0.5141,  loss:0.9637,  val_accuracy:0.5545,  val_loss:0.9042,  \n",".........................................adapt model (with source) last loss:  0.5065975785255432\n","\n","knn_loss 0.3945578231292517\n","retrieval_loss 0.40816326530612246\n","adapt with source 0.4217687074829932\n","adapt without source 0.4421768707482993\n","\n","Epoch: 0, accuracy:0.5111,  loss:0.9705,  val_accuracy:0.5487,  val_loss:0.9222,  \n","...................................................adapt model (without source) last loss:  0.420790433883667\n","\n","Epoch: 0, accuracy:0.5179,  loss:0.9682,  val_accuracy:0.5302,  val_loss:0.9524,  \n",".......................................adapt model (with source) last loss:  0.545365035533905\n","\n","knn_loss 0.3673469387755102\n","retrieval_loss 0.35374149659863946\n","adapt with source 0.46938775510204084\n","adapt without source 0.47619047619047616\n","\n","Epoch: 0, accuracy:0.5112,  loss:0.9680,  val_accuracy:0.5325,  val_loss:0.9492,  \n",".........................................adapt model (without source) last loss:  0.5128438472747803\n","\n","Epoch: 0, accuracy:0.5089,  loss:0.9736,  val_accuracy:0.5278,  val_loss:0.9527,  \n","................................adapt model (with source) last loss:  0.5083685517311096\n","\n","knn_loss 0.3673469387755102\n","retrieval_loss 0.43537414965986393\n","adapt with source 0.4557823129251701\n","adapt without source 0.5102040816326531\n","\n","Epoch: 0, accuracy:0.5058,  loss:0.9732,  val_accuracy:0.5313,  val_loss:0.9483,  \n","..........................................adapt model (without source) last loss:  0.4642358720302582\n","\n","Epoch: 0, accuracy:0.5064,  loss:0.9781,  val_accuracy:0.5777,  val_loss:0.9055,  \n",".................................adapt model (with source) last loss:  0.4781727194786072\n","\n","knn_loss 0.4489795918367347\n","retrieval_loss 0.48299319727891155\n","adapt with source 0.4557823129251701\n","adapt without source 0.564625850340136\n","\n","Epoch: 0, accuracy:0.4960,  loss:0.9854,  val_accuracy:0.5534,  val_loss:0.9153,  \n","...............................................adapt model (without source) last loss:  0.3763639032840729\n","\n","Epoch: 0, accuracy:0.5023,  loss:0.9797,  val_accuracy:0.5348,  val_loss:0.9390,  \n","...............................................adapt model (with source) last loss:  0.5473054647445679\n","\n","knn_loss 0.3945578231292517\n","retrieval_loss 0.4217687074829932\n","adapt with source 0.46258503401360546\n","adapt without source 0.46258503401360546\n","\n","Epoch: 0, accuracy:0.5002,  loss:0.9806,  val_accuracy:0.5336,  val_loss:0.9313,  \n","..................................................adapt model (without source) last loss:  0.34578126668930054\n","\n","Epoch: 0, accuracy:0.5085,  loss:0.9771,  val_accuracy:0.5220,  val_loss:0.9506,  \n","................................................adapt model (with source) last loss:  0.520301103591919\n","\n","knn_loss 0.40816326530612246\n","retrieval_loss 0.4421768707482993\n","adapt with source 0.48299319727891155\n","adapt without source 0.4897959183673469\n","\n","Epoch: 0, accuracy:0.5021,  loss:0.9772,  val_accuracy:0.5545,  val_loss:0.9386,  \n","..........................................................adapt model (without source) last loss:  0.4307728707790375\n","\n","Epoch: 0, accuracy:0.4997,  loss:0.9837,  val_accuracy:0.5510,  val_loss:0.9243,  \n",".....................................adapt model (with source) last loss:  0.5654876232147217\n","\n","knn_loss 0.47619047619047616\n","retrieval_loss 0.4965986394557823\n","adapt with source 0.4897959183673469\n","adapt without source 0.5034013605442177\n","\n","Epoch: 0, accuracy:0.5003,  loss:0.9817,  val_accuracy:0.5441,  val_loss:0.9190,  \n","..........................................adapt model (without source) last loss:  0.44339293241500854\n","\n","Epoch: 0, accuracy:0.4988,  loss:0.9864,  val_accuracy:0.5452,  val_loss:0.9308,  \n","............................................adapt model (with source) last loss:  0.5764116644859314\n","\n","knn_loss 0.3918918918918919\n","retrieval_loss 0.47297297297297297\n","adapt with source 0.4797297297297297\n","adapt without source 0.5067567567567568\n","\n","Epoch: 0, accuracy:0.5116,  loss:0.9714,  val_accuracy:0.5696,  val_loss:0.8945,  \n","...............................................adapt model (without source) last loss:  0.4398142695426941\n","\n","Epoch: 0, accuracy:0.5300,  loss:0.9553,  val_accuracy:0.5742,  val_loss:0.9054,  \n",".......................................................adapt model (with source) last loss:  0.5556927919387817\n","\n","knn_loss 0.3716216216216216\n","retrieval_loss 0.3918918918918919\n","adapt with source 0.4391891891891892\n","adapt without source 0.42567567567567566\n","\n","Epoch: 0, accuracy:0.5086,  loss:0.9747,  val_accuracy:0.5603,  val_loss:0.9280,  \n","...................................................adapt model (without source) last loss:  0.4453093707561493\n","\n","Epoch: 0, accuracy:0.5159,  loss:0.9673,  val_accuracy:0.5406,  val_loss:0.9331,  \n","..................................adapt model (with source) last loss:  0.521086573600769\n","\n","knn_loss 0.4864864864864865\n","retrieval_loss 0.46621621621621623\n","adapt with source 0.5\n","adapt without source 0.49324324324324326\n","\n","Epoch: 0, accuracy:0.5040,  loss:0.9775,  val_accuracy:0.5406,  val_loss:0.9191,  \n","..................................................adapt model (without source) last loss:  0.4790538251399994\n","\n","Epoch: 0, accuracy:0.5035,  loss:0.9781,  val_accuracy:0.5534,  val_loss:0.9125,  \n","............................................................adapt model (with source) last loss:  0.5373496413230896\n","\n","knn_loss 0.40816326530612246\n","retrieval_loss 0.47619047619047616\n","adapt with source 0.5238095238095238\n","adapt without source 0.47619047619047616\n","\n","Epoch: 0, accuracy:0.4957,  loss:0.9822,  val_accuracy:0.5186,  val_loss:0.9617,  \n","..................................................adapt model (without source) last loss:  0.45269855856895447\n","\n","Epoch: 0, accuracy:0.5014,  loss:0.9825,  val_accuracy:0.5278,  val_loss:0.9298,  \n",".....................................................adapt model (with source) last loss:  0.479979544878006\n","\n","knn_loss 0.4421768707482993\n","retrieval_loss 0.4421768707482993\n","adapt with source 0.4897959183673469\n","adapt without source 0.48299319727891155\n","\n","Epoch: 0, accuracy:0.5076,  loss:0.9735,  val_accuracy:0.5336,  val_loss:0.9345,  \n",".......................................................adapt model (without source) last loss:  0.4983968138694763\n","\n","Epoch: 0, accuracy:0.5069,  loss:0.9729,  val_accuracy:0.5162,  val_loss:0.9602,  \n",".............................................adapt model (with source) last loss:  0.462874174118042\n","\n","knn_loss 0.43537414965986393\n","retrieval_loss 0.43537414965986393\n","adapt with source 0.4489795918367347\n","adapt without source 0.4217687074829932\n","\n","Epoch: 0, accuracy:0.5112,  loss:0.9708,  val_accuracy:0.5139,  val_loss:0.9525,  \n","................................................adapt model (without source) last loss:  0.43053245544433594\n","\n","Epoch: 0, accuracy:0.5100,  loss:0.9755,  val_accuracy:0.5406,  val_loss:0.9488,  \n",".......................................adapt model (with source) last loss:  0.4671369194984436\n","\n","knn_loss 0.3673469387755102\n","retrieval_loss 0.40816326530612246\n","adapt with source 0.42857142857142855\n","adapt without source 0.43537414965986393\n","\n","Epoch: 0, accuracy:0.4946,  loss:0.9898,  val_accuracy:0.5673,  val_loss:0.9234,  \n","....................................................adapt model (without source) last loss:  0.45250803232192993\n","\n","Epoch: 0, accuracy:0.5103,  loss:0.9718,  val_accuracy:0.5394,  val_loss:0.9436,  \n","........................................adapt model (with source) last loss:  0.5954067707061768\n","\n","knn_loss 0.4421768707482993\n","retrieval_loss 0.4489795918367347\n","adapt with source 0.5578231292517006\n","adapt without source 0.5578231292517006\n","\n","Epoch: 0, accuracy:0.4947,  loss:0.9842,  val_accuracy:0.5371,  val_loss:0.9286,  \n","..................................................adapt model (without source) last loss:  0.4641331136226654\n","\n","Epoch: 0, accuracy:0.5112,  loss:0.9704,  val_accuracy:0.5360,  val_loss:0.9331,  \n","..........................................adapt model (with source) last loss:  0.5283854007720947\n","\n","knn_loss 0.35374149659863946\n","retrieval_loss 0.3673469387755102\n","adapt with source 0.47619047619047616\n","adapt without source 0.4557823129251701\n","\n","Epoch: 0, accuracy:0.5074,  loss:0.9750,  val_accuracy:0.5464,  val_loss:0.9253,  \n",".....................................................adapt model (without source) last loss:  0.40020275115966797\n","\n","Epoch: 0, accuracy:0.5127,  loss:0.9754,  val_accuracy:0.5534,  val_loss:0.9261,  \n",".....................................adapt model (with source) last loss:  0.4835071265697479\n","\n","knn_loss 0.3401360544217687\n","retrieval_loss 0.4217687074829932\n","adapt with source 0.4897959183673469\n","adapt without source 0.47619047619047616\n","\n","Epoch: 0, accuracy:0.5017,  loss:0.9795,  val_accuracy:0.4814,  val_loss:0.9812,  \n","...........................................adapt model (without source) last loss:  0.44894111156463623\n","\n","Epoch: 0, accuracy:0.5085,  loss:0.9803,  val_accuracy:0.5429,  val_loss:0.9314,  \n",".........................................adapt model (with source) last loss:  0.5141105055809021\n","\n","knn_loss 0.4189189189189189\n","retrieval_loss 0.4189189189189189\n","adapt with source 0.4797297297297297\n","adapt without source 0.43243243243243246\n","\n","Epoch: 0, accuracy:0.5052,  loss:0.9807,  val_accuracy:0.5371,  val_loss:0.9377,  \n",".....................................................adapt model (without source) last loss:  0.4061740040779114\n","\n","Epoch: 0, accuracy:0.5105,  loss:0.9759,  val_accuracy:0.5360,  val_loss:0.9524,  \n",".......................................adapt model (with source) last loss:  0.497814804315567\n","\n","knn_loss 0.47297297297297297\n","retrieval_loss 0.4189189189189189\n","adapt with source 0.4864864864864865\n","adapt without source 0.5135135135135135\n","\n","Epoch: 0, accuracy:0.5020,  loss:0.9774,  val_accuracy:0.5522,  val_loss:0.9246,  \n",".................................................adapt model (without source) last loss:  0.4519806504249573\n","\n","Epoch: 0, accuracy:0.5125,  loss:0.9745,  val_accuracy:0.5313,  val_loss:0.9060,  \n","............................................adapt model (with source) last loss:  0.5090960264205933\n","\n","knn_loss 0.36486486486486486\n","retrieval_loss 0.4527027027027027\n","adapt with source 0.4797297297297297\n","adapt without source 0.47297297297297297\n","\n","Epoch: 0, accuracy:0.5046,  loss:0.9789,  val_accuracy:0.5290,  val_loss:0.9436,  \n","...................................................adapt model (without source) last loss:  0.4801492393016815\n","\n","Epoch: 0, accuracy:0.5043,  loss:0.9790,  val_accuracy:0.5290,  val_loss:0.9587,  \n","...........................................adapt model (with source) last loss:  0.5897722840309143\n","\n","knn_loss 0.46938775510204084\n","retrieval_loss 0.5034013605442177\n","adapt with source 0.43537414965986393\n","adapt without source 0.5374149659863946\n","\n","Epoch: 0, accuracy:0.5050,  loss:0.9706,  val_accuracy:0.5151,  val_loss:0.9585,  \n","....................................................adapt model (without source) last loss:  0.41878411173820496\n","\n","Epoch: 0, accuracy:0.5065,  loss:0.9740,  val_accuracy:0.5452,  val_loss:0.9300,  \n","...................................adapt model (with source) last loss:  0.6087709665298462\n","\n","knn_loss 0.3469387755102041\n","retrieval_loss 0.4217687074829932\n","adapt with source 0.48299319727891155\n","adapt without source 0.4897959183673469\n","\n","Epoch: 0, accuracy:0.4974,  loss:0.9851,  val_accuracy:0.5151,  val_loss:0.9534,  \n","..................................................adapt model (without source) last loss:  0.39668068289756775\n","\n","Epoch: 0, accuracy:0.5054,  loss:0.9840,  val_accuracy:0.5360,  val_loss:0.9429,  \n","........................................adapt model (with source) last loss:  0.5354995727539062\n","\n","knn_loss 0.40816326530612246\n","retrieval_loss 0.4489795918367347\n","adapt with source 0.4965986394557823\n","adapt without source 0.4421768707482993\n","\n","Epoch: 0, accuracy:0.5082,  loss:0.9809,  val_accuracy:0.5418,  val_loss:0.9474,  \n",".................................................adapt model (without source) last loss:  0.4324621260166168\n","\n","Epoch: 0, accuracy:0.5062,  loss:0.9815,  val_accuracy:0.5290,  val_loss:0.9458,  \n","..........................................adapt model (with source) last loss:  0.5030938386917114\n","\n","knn_loss 0.4421768707482993\n","retrieval_loss 0.46258503401360546\n","adapt with source 0.46258503401360546\n","adapt without source 0.4965986394557823\n","\n","Epoch: 0, accuracy:0.5025,  loss:0.9787,  val_accuracy:0.5464,  val_loss:0.9274,  \n","...................................................................adapt model (without source) last loss:  0.30791130661964417\n","\n","Epoch: 0, accuracy:0.5077,  loss:0.9777,  val_accuracy:0.5568,  val_loss:0.9264,  \n","......................................................adapt model (with source) last loss:  0.5589078664779663\n","\n","knn_loss 0.35374149659863946\n","retrieval_loss 0.3741496598639456\n","adapt with source 0.4897959183673469\n","adapt without source 0.41496598639455784\n","\n","Epoch: 0, accuracy:0.5137,  loss:0.9680,  val_accuracy:0.5360,  val_loss:0.9469,  \n",".........................................................adapt model (without source) last loss:  0.37997549772262573\n","\n","Epoch: 0, accuracy:0.5183,  loss:0.9621,  val_accuracy:0.5487,  val_loss:0.9043,  \n","..............................................adapt model (with source) last loss:  0.5132416486740112\n","\n","knn_loss 0.36054421768707484\n","retrieval_loss 0.4217687074829932\n","adapt with source 0.4557823129251701\n","adapt without source 0.46938775510204084\n","\n","Epoch: 0, accuracy:0.5074,  loss:0.9754,  val_accuracy:0.5336,  val_loss:0.9320,  \n","......................................................adapt model (without source) last loss:  0.40223902463912964\n","\n","Epoch: 0, accuracy:0.5208,  loss:0.9680,  val_accuracy:0.5510,  val_loss:0.9245,  \n","..........................................adapt model (with source) last loss:  0.4927437901496887\n","\n","knn_loss 0.43537414965986393\n","retrieval_loss 0.41496598639455784\n","adapt with source 0.4557823129251701\n","adapt without source 0.47619047619047616\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.40922687994116563\n","np.mean(retrieval_loss_es) =  0.4390853097995956\n","np.mean(without_source_loss_es) =  0.47440246368817796\n","np.mean(with_source_loss_es) =  0.4778038242323956\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.041485142642806054\n","np.std(retrieval_loss_es) =  0.04019213237825082\n","np.std(without_source_loss_es) =  0.03706487925061137\n","np.std(with_source_loss_es) =  0.03528413502726544\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.43909295789697667\n","np.mean(retrieval_loss_es) =  0.4217047652843515\n","np.mean(without_source_loss_es) =  0.4502074492215723\n","np.mean(with_source_loss_es) =  0.4547961071894228\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.044559776740538175\n","np.std(retrieval_loss_es) =  0.04310613765723291\n","np.std(without_source_loss_es) =  0.041952139290926026\n","np.std(with_source_loss_es) =  0.03979575980737271\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jIc-_7ye6BMb"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.40922687994116563\r\n","np.mean(retrieval_loss_es) =  0.4390853097995956\r\n","np.mean(without_source_loss_es) =  0.47440246368817796\r\n","np.mean(with_source_loss_es) =  0.4778038242323956\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.041485142642806054\r\n","np.std(retrieval_loss_es) =  0.04019213237825082\r\n","np.std(without_source_loss_es) =  0.03706487925061137\r\n","np.std(with_source_loss_es) =  0.03528413502726544\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.43909295789697667\r\n","np.mean(retrieval_loss_es) =  0.4217047652843515\r\n","np.mean(without_source_loss_es) =  0.4502074492215723\r\n","np.mean(with_source_loss_es) =  0.4547961071894228\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.044559776740538175\r\n","np.std(retrieval_loss_es) =  0.04310613765723291\r\n","np.std(without_source_loss_es) =  0.041952139290926026\r\n","np.std(with_source_loss_es) =  0.03979575980737271\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"z2BNtjoe8RGG"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.5288656002941717\r\n","np.mean(arr_knn) =  0.4256894649751793\r\n","np.mean(arr_retrieval_loss) =  0.4500873322301894\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.49218606361463496\r\n","np.mean(arr_normal_cdh_loss) =  0.39440614083471226\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.49153337010479864\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.54421768707483\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.49578508188150217\r\n","np.mean(arr_knn) =  0.44855540994875354\r\n","np.mean(arr_retrieval_loss) =  0.43454317477251464\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.4699601045679717\r\n","np.mean(arr_normal_cdh_loss) =  0.3871058606330141\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.47140368648915293\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.5100198412698412\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"V3a7Jl-0D8F2"},"source":["Multi run\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.547317521603236\r\n","np.mean(arr_knn) =  0.4096240117668689\r\n","np.mean(arr_retrieval_loss) =  0.4347416804559661\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.4794392351535209\r\n","np.mean(arr_normal_cdh_loss) =  0.3880400808972238\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.47820922963780105\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.513914322485751\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.03810123623451787\r\n","np.std(arr_knn) =  0.03750680710336985\r\n","np.std(arr_retrieval_loss) =  0.03741967681925101\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.04098959878103348\r\n","np.std(arr_normal_cdh_loss) =  0.03614251947842028\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.04481613497029232\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.043132229423507876\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.5229381141508201\r\n","np.mean(arr_knn) =  0.43883572984731123\r\n","np.mean(arr_retrieval_loss) =  0.4178267704715454\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.4548793652709406\r\n","np.mean(arr_normal_cdh_loss) =  0.3839333954072596\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.45469448089499553\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.4969222855097253\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.038280534421347635\r\n","np.std(arr_knn) =  0.033924939097700425\r\n","np.std(arr_retrieval_loss) =  0.03649325651929315\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.041709425475082475\r\n","np.std(arr_normal_cdh_loss) =  0.03847498751013724\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.04518575093262454\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.04314633544083794\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"WZJMDB6O-a94"},"source":["# Dataset: Abalone"]},{"cell_type":"code","metadata":{"id":"tbX_vFc4-2vg"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/abalone.data'\r\n","nominalCols = [0] \r\n","numericCols = [1,2,3,4,5,6,7]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=None, usecols=(0,1,2,3,4,5,6,7,),sep=',');\r\n","\r\n","    y = pd.read_csv(filename,header=None, usecols=(8,),sep=',');\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False, columns=[8])\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8bbPkuDAdI9"},"source":["# Trying 10 fold: Abalone"]},{"cell_type":"code","metadata":{"id":"lC1at1fYAfUr"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjbIcYRpImuQ"},"source":["# Dataset: Wine-white"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPI8Cq5SRdZe","executionInfo":{"status":"ok","timestamp":1611081114223,"user_tz":300,"elapsed":16782,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"f5e28c36-2e31-4720-9f76-0ea5d5190e83"},"source":["filename = '/content/drive/My Drive/2020 Summer Assistantship CBR+Deep Learning/DL-CDH for classification/winequality-white.csv'\r\n","nominalCols = [] \r\n","numericCols = [0,1,2,3,4,5,6,7,8,9,10]\r\n","def GetDataMatrix():\r\n","    \r\n","    # Data frame with make and model\r\n","    X = pd.read_csv(filename,header=0, names=[0,1,2,3,4,5,6,7,8,9,10,11], usecols=(0,1,2,3,4,5,6,7,8,9,10,),sep=';');\r\n","\r\n","    y = pd.read_csv(filename,header=0, names=[0,1,2,3,4,5,6,7,8,9,10,11], usecols=(11,),sep=';');\r\n","\r\n","    #no missing values\r\n","    #remove rows with ? values\r\n","    # if(X.values == '?'):\r\n","    #   rows_with_na = (X.values == '?').any(1)\r\n","    #   X = X[~rows_with_na]\r\n","    #   y = y[~rows_with_na]\r\n","\r\n","    X, y = shuffle(X, y)\r\n","    print(X.head(0))\r\n","    # Turns categorical data into binary values across many columns\r\n","    #special one hot encoding with multiple values\r\n","    # market_category_dummies = X['Market Category'].str.get_dummies(sep=',')\r\n","    # X = pd.concat([X, market_category_dummies], axis=1)\r\n","    # X = X.drop(columns=['Market Category'])\r\n","    #normal one hot encoding\r\n","    X = pd.get_dummies(X, dummy_na = False, columns=nominalCols );\r\n","    y = pd.get_dummies(y, dummy_na=False, columns=[11])\r\n","    # Fill the null values with zeros\r\n","    # X.fillna(0, inplace=True);\r\n","    #there shouldn't be null, since it's already cleaned.\r\n","    print(X.isnull().sum())\r\n","    X = scaleX(X,numericCols)\r\n","\r\n","    return (X, y)\r\n","\r\n","##########\r\n","\r\n","(X, y) = GetDataMatrix() #Gets the X,Y\r\n","num_classes = len(y.columns)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Empty DataFrame\n","Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","Index: []\n","0     0\n","1     0\n","2     0\n","3     0\n","4     0\n","5     0\n","6     0\n","7     0\n","8     0\n","9     0\n","10    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aghM5mSuEFD-"},"source":["X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"etT0Wa8_UZoz"},"source":["# Trying 10 fold: Wine-white"]},{"cell_type":"code","metadata":{"id":"TDijcUt3Uz-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611090039847,"user_tz":300,"elapsed":8940251,"user":{"displayName":"Xiaomeng Ye","photoUrl":"","userId":"18382757014859054157"}},"outputId":"79856e9f-852a-47cc-ebce-9fb58891ac3a"},"source":["from sklearn.model_selection import KFold\r\n","\r\n","#ALL PARAMETERS HERE\r\n","#0, no EAC\r\n","#1, adapt from multiple neighbors\r\n","#2, adapt from multiple neighbors, each from a different class.\r\n","EAC_adapt = \"12\"\r\n","#1, rules from nearest pairs\r\n","#2, rules from random pairs\r\n","#12, rules from both nearest pairs and random pairs\r\n","#124, rules from both nearest pairs and random pairs, with designated number of random pairs\r\n","pair_selection = \"145\"\r\n","# random_pairs_count = 6000\r\n","#1, pair from partial knowledge\r\n","#2, pair from full knowledge\r\n","pair_knowledge = 1\r\n","\r\n","kFoldExperiment(X,y,2)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0, accuracy:0.4970,  loss:1.1949,  val_accuracy:0.5653,  val_loss:0.9986,  \n","...........................................................................................adapt model (without source) last loss:  0.014275607652962208\n","\n","Epoch: 0, accuracy:0.5054,  loss:1.1880,  val_accuracy:0.5546,  val_loss:1.0093,  \n","..........................................................adapt model (with source) last loss:  0.07762566208839417\n","\n","knn_loss 0.5673469387755102\n","retrieval_loss 0.6510204081632653\n","adapt with source 0.6204081632653061\n","adapt without source 0.6326530612244898\n","\n","Epoch: 0, accuracy:0.5023,  loss:1.1710,  val_accuracy:0.5767,  val_loss:0.9854,  \n",".....................................................adapt model (without source) last loss:  0.03174590691924095\n","\n","Epoch: 0, accuracy:0.4979,  loss:1.1936,  val_accuracy:0.5671,  val_loss:1.0006,  \n","....................................................................adapt model (with source) last loss:  0.03917575627565384\n","\n","knn_loss 0.5428571428571428\n","retrieval_loss 0.6673469387755102\n","adapt with source 0.6163265306122448\n","adapt without source 0.6265306122448979\n","\n","Epoch: 0, accuracy:0.4988,  loss:1.1850,  val_accuracy:0.5719,  val_loss:0.9848,  \n","...........................................................................................adapt model (without source) last loss:  0.032596245408058167\n","\n","Epoch: 0, accuracy:0.5047,  loss:1.1770,  val_accuracy:0.5677,  val_loss:1.0068,  \n",".................................................................................adapt model (with source) last loss:  0.020246582105755806\n","\n","knn_loss 0.5244897959183673\n","retrieval_loss 0.6346938775510204\n","adapt with source 0.6510204081632653\n","adapt without source 0.6142857142857143\n","\n","Epoch: 0, accuracy:0.5022,  loss:1.1661,  val_accuracy:0.5476,  val_loss:1.0269,  \n","....................................................................adapt model (without source) last loss:  0.06053810194134712\n","\n","Epoch: 0, accuracy:0.4990,  loss:1.1913,  val_accuracy:0.5594,  val_loss:1.0253,  \n",".............................................................adapt model (with source) last loss:  0.04934634640812874\n","\n","knn_loss 0.5591836734693878\n","retrieval_loss 0.6693877551020408\n","adapt with source 0.6061224489795919\n","adapt without source 0.6204081632653061\n","\n","Epoch: 0, accuracy:0.5131,  loss:1.1476,  val_accuracy:0.5610,  val_loss:0.9911,  \n","...............................................................................adapt model (without source) last loss:  0.019856814295053482\n","\n","Epoch: 0, accuracy:0.5049,  loss:1.1675,  val_accuracy:0.5631,  val_loss:1.0097,  \n","...................................................................................................adapt model (with source) last loss:  0.028560148552060127\n","\n","knn_loss 0.5204081632653061\n","retrieval_loss 0.6428571428571429\n","adapt with source 0.6204081632653061\n","adapt without source 0.6387755102040816\n","\n","Epoch: 0, accuracy:0.4964,  loss:1.1890,  val_accuracy:0.5629,  val_loss:1.0207,  \n","......................................................................adapt model (without source) last loss:  0.03911338746547699\n","\n","Epoch: 0, accuracy:0.5002,  loss:1.1814,  val_accuracy:0.5599,  val_loss:0.9938,  \n","..............................................................adapt model (with source) last loss:  0.0322127640247345\n","\n","knn_loss 0.5224489795918368\n","retrieval_loss 0.6285714285714286\n","adapt with source 0.636734693877551\n","adapt without source 0.6040816326530613\n","\n","Epoch: 0, accuracy:0.4982,  loss:1.1862,  val_accuracy:0.5842,  val_loss:0.9636,  \n","..................................................................adapt model (without source) last loss:  0.02786363661289215\n","\n","Epoch: 0, accuracy:0.5041,  loss:1.1770,  val_accuracy:0.5650,  val_loss:0.9928,  \n","...................................................................adapt model (with source) last loss:  0.021878916770219803\n","\n","knn_loss 0.5306122448979592\n","retrieval_loss 0.6448979591836734\n","adapt with source 0.6591836734693878\n","adapt without source 0.6653061224489796\n","\n","Epoch: 0, accuracy:0.4959,  loss:1.2003,  val_accuracy:0.5623,  val_loss:1.0094,  \n","...................................................................adapt model (without source) last loss:  0.03956393525004387\n","\n","Epoch: 0, accuracy:0.4985,  loss:1.1942,  val_accuracy:0.5607,  val_loss:1.0122,  \n",".............................................................................adapt model (with source) last loss:  0.04674109071493149\n","\n","knn_loss 0.5346938775510204\n","retrieval_loss 0.6591836734693878\n","adapt with source 0.6510204081632653\n","adapt without source 0.6714285714285714\n","\n","Epoch: 0, accuracy:0.4980,  loss:1.1783,  val_accuracy:0.5680,  val_loss:1.0014,  \n",".....................................................................adapt model (without source) last loss:  0.060658831149339676\n","\n","Epoch: 0, accuracy:0.4926,  loss:1.1935,  val_accuracy:0.5616,  val_loss:1.0081,  \n","............................................................adapt model (with source) last loss:  0.04324960336089134\n","\n","knn_loss 0.5460122699386503\n","retrieval_loss 0.689161554192229\n","adapt with source 0.656441717791411\n","adapt without source 0.6482617586912065\n","\n","Epoch: 0, accuracy:0.4950,  loss:1.1971,  val_accuracy:0.5438,  val_loss:1.0363,  \n","..........................................adapt model (without source) last loss:  0.04481606185436249\n","\n","Epoch: 0, accuracy:0.4988,  loss:1.1829,  val_accuracy:0.5747,  val_loss:0.9878,  \n",".........................................................................adapt model (with source) last loss:  0.055063433945178986\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5480572597137015\n","retrieval_loss 0.6646216768916156\n","adapt with source 0.6359918200408998\n","adapt without source 0.6625766871165644\n","\n","Epoch: 0, accuracy:0.5081,  loss:1.1749,  val_accuracy:0.5671,  val_loss:1.0003,  \n",".........................................................adapt model (without source) last loss:  0.02944169007241726\n","\n","Epoch: 0, accuracy:0.5047,  loss:1.1845,  val_accuracy:0.5671,  val_loss:1.0027,  \n","............................................................adapt model (with source) last loss:  0.07129369676113129\n","\n","knn_loss 0.5163265306122449\n","retrieval_loss 0.6408163265306123\n","adapt with source 0.5857142857142857\n","adapt without source 0.6183673469387755\n","\n","Epoch: 0, accuracy:0.4984,  loss:1.1852,  val_accuracy:0.5743,  val_loss:0.9831,  \n",".................................................................adapt model (without source) last loss:  0.0754113718867302\n","\n","Epoch: 0, accuracy:0.4971,  loss:1.1894,  val_accuracy:0.5620,  val_loss:1.0090,  \n","......................................................adapt model (with source) last loss:  0.026910269632935524\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.563265306122449\n","retrieval_loss 0.6510204081632653\n","adapt with source 0.6469387755102041\n","adapt without source 0.6183673469387755\n","\n","Epoch: 0, accuracy:0.4933,  loss:1.2013,  val_accuracy:0.5751,  val_loss:0.9920,  \n",".......................................................adapt model (without source) last loss:  0.0357719287276268\n","\n","Epoch: 0, accuracy:0.4923,  loss:1.1984,  val_accuracy:0.5466,  val_loss:1.0109,  \n",".....................................................adapt model (with source) last loss:  0.06344885379076004\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5224489795918368\n","retrieval_loss 0.6632653061224489\n","adapt with source 0.6265306122448979\n","adapt without source 0.6306122448979592\n","\n","Epoch: 0, accuracy:0.4926,  loss:1.1932,  val_accuracy:0.5658,  val_loss:0.9941,  \n","...................................................................adapt model (without source) last loss:  0.05222926661372185\n","\n","Epoch: 0, accuracy:0.4978,  loss:1.1868,  val_accuracy:0.5564,  val_loss:1.0040,  \n",".....................................................adapt model (with source) last loss:  0.08285044878721237\n","\n","knn_loss 0.5346938775510204\n","retrieval_loss 0.6612244897959184\n","adapt with source 0.636734693877551\n","adapt without source 0.6306122448979592\n","\n","Epoch: 0, accuracy:0.5055,  loss:1.1719,  val_accuracy:0.5714,  val_loss:0.9789,  \n",".............................................adapt model (without source) last loss:  0.05219528079032898\n","\n","Epoch: 0, accuracy:0.5063,  loss:1.1566,  val_accuracy:0.5404,  val_loss:1.0023,  \n",".................................................adapt model (with source) last loss:  0.034666188061237335\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5530612244897959\n","retrieval_loss 0.6612244897959184\n","adapt with source 0.6571428571428571\n","adapt without source 0.6591836734693878\n","\n","Epoch: 0, accuracy:0.4998,  loss:1.1858,  val_accuracy:0.5487,  val_loss:1.0026,  \n",".........................................................................adapt model (without source) last loss:  0.03058667853474617\n","\n","Epoch: 0, accuracy:0.4982,  loss:1.1868,  val_accuracy:0.5450,  val_loss:1.0236,  \n",".......................................................adapt model (with source) last loss:  0.025437848642468452\n","\n","knn_loss 0.5448979591836735\n","retrieval_loss 0.6551020408163265\n","adapt with source 0.6469387755102041\n","adapt without source 0.6510204081632653\n","\n","Epoch: 0, accuracy:0.4969,  loss:1.1911,  val_accuracy:0.5567,  val_loss:1.0118,  \n","..........................................................................adapt model (without source) last loss:  0.030393466353416443\n","\n","Epoch: 0, accuracy:0.4993,  loss:1.1804,  val_accuracy:0.5527,  val_loss:1.0136,  \n","..............................................................adapt model (with source) last loss:  0.06393133848905563\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5346938775510204\n","retrieval_loss 0.6693877551020408\n","adapt with source 0.6061224489795919\n","adapt without source 0.6142857142857143\n","\n","Epoch: 0, accuracy:0.5024,  loss:1.1794,  val_accuracy:0.5634,  val_loss:0.9828,  \n","....................................................adapt model (without source) last loss:  0.04554031789302826\n","\n","Epoch: 0, accuracy:0.4957,  loss:1.2003,  val_accuracy:0.5564,  val_loss:1.0081,  \n","..................................................................adapt model (with source) last loss:  0.07996558398008347\n","\n","knn_loss 0.5755102040816327\n","retrieval_loss 0.6816326530612244\n","adapt with source 0.6306122448979592\n","adapt without source 0.6183673469387755\n","\n","Epoch: 0, accuracy:0.4911,  loss:1.2038,  val_accuracy:0.5542,  val_loss:1.0170,  \n",".........................................................................adapt model (without source) last loss:  0.038963500410318375\n","\n","Epoch: 0, accuracy:0.4937,  loss:1.1948,  val_accuracy:0.5566,  val_loss:1.0129,  \n",".............................................................adapt model (with source) last loss:  0.034444112330675125\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn('y_pred contains classes not in y_true')\n"],"name":"stderr"},{"output_type":"stream","text":["\n","knn_loss 0.5276073619631901\n","retrieval_loss 0.6441717791411042\n","adapt with source 0.6625766871165644\n","adapt without source 0.6319018404907976\n","\n","Epoch: 0, accuracy:0.5028,  loss:1.1763,  val_accuracy:0.5792,  val_loss:0.9689,  \n","..................................................................adapt model (without source) last loss:  0.04017262905836105\n","\n","Epoch: 0, accuracy:0.5036,  loss:1.1761,  val_accuracy:0.5550,  val_loss:0.9997,  \n","...............................................................adapt model (with source) last loss:  0.10610046982765198\n","\n","knn_loss 0.5541922290388548\n","retrieval_loss 0.6503067484662577\n","adapt with source 0.6359918200408998\n","adapt without source 0.6503067484662577\n","\n","reporting k Folds average\n","np.mean(knn_loss_es) =  0.5411403948082301\n","np.mean(retrieval_loss_es) =  0.6564947205876217\n","np.mean(without_source_loss_es) =  0.6353666374525271\n","np.mean(with_source_loss_es) =  0.6344480614331622\n","\n","reporting std average\n","np.std(knn_loss_es) =  0.01661991426408846\n","np.std(retrieval_loss_es) =  0.014809487167621104\n","np.std(without_source_loss_es) =  0.01904143347537029\n","np.std(with_source_loss_es) =  0.02007246638036271\n","\n","reporting k Folds balanced\n","np.mean(knn_loss_es) =  0.3262180696407081\n","np.mean(retrieval_loss_es) =  0.4397147835716151\n","np.mean(without_source_loss_es) =  0.4200064497200807\n","np.mean(with_source_loss_es) =  0.4207293535305513\n","\n","reporting std balanced\n","np.std(knn_loss_es) =  0.04398173874075522\n","np.std(retrieval_loss_es) =  0.03173939894707622\n","np.std(without_source_loss_es) =  0.033550358122329496\n","np.std(with_source_loss_es) =  0.0505880233812723\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iAr6g7sFdAzM"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(knn_loss_es) =  0.5411403948082301\r\n","np.mean(retrieval_loss_es) =  0.6564947205876217\r\n","np.mean(without_source_loss_es) =  0.6353666374525271\r\n","np.mean(with_source_loss_es) =  0.6344480614331622\r\n","\r\n","reporting std average\r\n","np.std(knn_loss_es) =  0.01661991426408846\r\n","np.std(retrieval_loss_es) =  0.014809487167621104\r\n","np.std(without_source_loss_es) =  0.01904143347537029\r\n","np.std(with_source_loss_es) =  0.02007246638036271\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(knn_loss_es) =  0.3262180696407081\r\n","np.mean(retrieval_loss_es) =  0.4397147835716151\r\n","np.mean(without_source_loss_es) =  0.4200064497200807\r\n","np.mean(with_source_loss_es) =  0.4207293535305513\r\n","\r\n","reporting std balanced\r\n","np.std(knn_loss_es) =  0.04398173874075522\r\n","np.std(retrieval_loss_es) =  0.03173939894707622\r\n","np.std(without_source_loss_es) =  0.033550358122329496\r\n","np.std(with_source_loss_es) =  0.0505880233812723\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"6TNYwXIipSIr"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.4665381244522349\r\n","np.mean(arr_knn) =  0.4697909102291223\r\n","np.mean(arr_retrieval_loss) =  0.5979950753307457\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.31564959726221775\r\n","np.mean(arr_normal_cdh_loss) =  0.41343766954634614\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.3760782104252744\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.523517382413088\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.23369949465188347\r\n","np.mean(arr_knn) =  0.29233955656831256\r\n","np.mean(arr_retrieval_loss) =  0.41643922242289994\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.22825821933393803\r\n","np.mean(arr_normal_cdh_loss) =  0.26221174928319757\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.2924976075057458\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.23889882416820804\r\n","```\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"d6k9njQguSb4"},"source":["\r\n","\r\n","```\r\n","reporting k Folds average\r\n","np.mean(arr_dl) =  0.5763580401485748\r\n","np.mean(arr_knn) =  0.5425783564959727\r\n","np.mean(arr_retrieval_loss) =  0.6569103960602646\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.5504342473185594\r\n","np.mean(arr_normal_cdh_loss) =  0.46938107758440795\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.6035167563958099\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.6354741037519303\r\n","\r\n","reporting std average\r\n","np.std(arr_dl) =  0.02179267686442935\r\n","np.std(arr_knn) =  0.02165176555679546\r\n","np.std(arr_retrieval_loss) =  0.022611759724934604\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.024432698325331216\r\n","np.std(arr_normal_cdh_loss) =  0.01985915156665192\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.018426137178453882\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.026971598082991023\r\n","\r\n","reporting k Folds balanced\r\n","np.mean(arr_dl) =  0.3205154850474546\r\n","np.mean(arr_knn) =  0.3526121897166673\r\n","np.mean(arr_retrieval_loss) =  0.45766137146761016\r\n","np.mean(arr_retrieval_N_adapt_loss) =  0.3313981687459058\r\n","np.mean(arr_normal_cdh_loss) =  0.29467081156585084\r\n","np.mean(retrieval_N_EAC_adapt_loss) =  0.43030951394650324\r\n","np.mean(C2C_EAC_NN_CDH_loss) =  0.43502942456604626\r\n","\r\n","reporting std balanced\r\n","np.std(arr_dl) =  0.03753660412843252\r\n","np.std(arr_knn) =  0.07687480684309066\r\n","np.std(arr_retrieval_loss) =  0.0630762456599508\r\n","np.std(arr_retrieval_N_adapt_loss) =  0.04080097523486786\r\n","np.std(arr_normal_cdh_loss) =  0.02631982162006131\r\n","np.std(retrieval_N_EAC_adapt_loss) =  0.06001922188242892\r\n","np.std(C2C_EAC_NN_CDH_loss) =  0.054356441048081613\r\n","```\r\n","\r\n"]}]}